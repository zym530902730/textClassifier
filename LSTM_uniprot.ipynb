{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib2 import Request, urlopen, URLError\n",
    "import numpy as np\n",
    "from skimage.util import view_as_windows as vaw\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "import tensorflow as tf\n",
    "import os, sys\n",
    "from scipy.stats import mode\n",
    "import glob\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have a single sequence you want to test,\n",
    "# put it here between the quotes.\n",
    "binding = 'MEFRMKVFKDVFTNDEVCSDSYVQQDPFEVPEFREIAFEVKSNKRIKGNEDYGIADNSEDAVEGMGADVEHVIDIVDSFQLTSTAFSKKEYSAYIKNYMQKVAKYLEEKKPDRVEIFKTKAQPFIKHILTNFDDFEFYMGESLDMEAGIIYSYYKGEEITPRFVYISDGLFEEKYLEHHHHHH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lstm_proteins:\n",
    "    def __init__(self, kw, test_len, Train, \n",
    "                 num_examples, data=None, test_seq=None):\n",
    "        '''Args:\n",
    "                kw: uniprot keyword\n",
    "                    \n",
    "                test_len: amino acid sequence fragment length\n",
    "                \n",
    "                Train: whether to train a model or load one and test.\n",
    "                \n",
    "                num_examples: the number of proteins to pull from uniprot\n",
    "                \n",
    "                data: provided data not from uniprot. Should be in a \n",
    "                      dictionary structure with positive examples in \n",
    "                      data[1] and negative ones in data[0]\n",
    "        '''\n",
    "        \n",
    "        assert((data is None) ^ (kw == 'User_Data')),'provide data or uniprot keyword, not both'\n",
    "        self.test = test_seq\n",
    "        self.test_len = test_len\n",
    "        self.numxs = num_examples \n",
    "        self.kw = kw\n",
    "        self.data = data\n",
    "        self.X, self.Y = self.compile_data()\n",
    "        \n",
    "        if Train:\n",
    "            self.train_network()     \n",
    "            self.test_network()\n",
    "        else:\n",
    "            self.test_network()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def get_uniprot_data(self):\n",
    "        '''Goes to the uniprot website and searches for \n",
    "           data with the keyword given. Returns the data \n",
    "           found up to limit elements.'''\n",
    "\n",
    "        kws = [self.kw, 'NOT+' + self.kw]\n",
    "        Protein_data = {}\n",
    "            \n",
    "        for i in range(2):\n",
    "            kw = kws[i]\n",
    "            url1 = 'http://www.uniprot.org/uniprot/?query='\n",
    "            url2 = '&columns=sequence&format=tab&limit='+str(self.numxs)\n",
    "            query_complete = url1 + kw + url2\n",
    "            request = Request(query_complete)\n",
    "            response = urlopen(request)\n",
    "            data = response.read()\n",
    "            data = data.split('\\n')\n",
    "            data = data[1:]\n",
    "            Protein_data[str(i)] = map(lambda x:x.lower(),data)\n",
    "            \n",
    "        x1 = Protein_data['0']\n",
    "        x0 = Protein_data['1']    \n",
    "        \n",
    "        return x1, x0\n",
    "    \n",
    "    \n",
    "    \n",
    "    def letter2num(self, c):\n",
    "        '''Assigns each letter in the amino acid code c\n",
    "            a unique integer and chops the sequence into\n",
    "            shorter sequences.'''\n",
    "        \n",
    "        if len(c[0]) > 1:\n",
    "            X = np.zeros([0, self.test_len])\n",
    "            pbar = ProgressBar()\n",
    "            \n",
    "            for seq in pbar(c):\n",
    "                x = []\n",
    "                \n",
    "                for letter in seq:\n",
    "                    x.append(max(ord(letter)-97, 0))\n",
    "                    \n",
    "                x = np.asarray(x)\n",
    "                \n",
    "                if x.size < self.test_len:\n",
    "                    x = np.pad(x, self.test_len-x.size, \n",
    "                               'constant', constant_values=22.)\n",
    "                    \n",
    "                x = vaw(x, (self.test_len,))\n",
    "                X = np.concatenate((X, x), 0)\n",
    "                \n",
    "                \n",
    "        elif len(c[0]) == 1:\n",
    "            X = []\n",
    "            for i in c:\n",
    "                X.append(ord(i)-97)\n",
    "            X = np.asarray(X)\n",
    "            \n",
    "            if X.size < self.test_len:\n",
    "                X = np.pad(X, self.test_len-X.size, 'constant',\n",
    "                           constant_values=22.)\n",
    "                \n",
    "            X = vaw(X, (self.test_len))\n",
    "            #X = X[::self.test_len - 10, :]\n",
    "            \n",
    "        return X\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    def compile_data(self):\n",
    "        '''Gets protein sequence data from get_uniprot_data\n",
    "           and sends it to letter2num() to transform the \n",
    "           amino acid letters into numbers. Labels are then\n",
    "           made for each example.'''\n",
    "\n",
    "        if self.kw != 'User_Data':\n",
    "            self.epochs = 6\n",
    "            print('Getting data from uniprot...')\n",
    "            self.x1, self.x0 = self.get_uniprot_data()\n",
    "            \n",
    "            self.x1 = self.letter2num(self.x1)\n",
    "            self.x0 = self.letter2num(self.x0)\n",
    "        \n",
    "            len_diff = self.x1.shape[0] - self.x0.shape[0]\n",
    "\n",
    "            if len_diff > 0:\n",
    "                self.x1 = self.x1[:self.x1.shape[0]-len_diff, :]\n",
    "            else:\n",
    "                self.x0 = self.x0[:self.x0.shape[0] + len_diff, :]\n",
    "    \n",
    "            assert(self.x1.shape[0] == self.x0.shape[0]),'number of examples not equal'\n",
    "        \n",
    "        else:\n",
    "            self.x1 = self.letter2num(self.data[1])\n",
    "            self.x0 = self.letter2num(self.data[0])\n",
    "            self.epochs = 50\n",
    "        \n",
    "        # compile data and make labels\n",
    "        X = np.concatenate((self.x1, self.x0), 0)\n",
    "        Y = np.zeros([self.x1.shape[0]+self.x0.shape[0], ])\n",
    "        Y[:self.x1.shape[0]] = 1.0\n",
    "        Y = to_categorical(Y, 2)\n",
    "        \n",
    "        return X, Y\n",
    "\n",
    "\n",
    "\n",
    "    def LSTM(self, net, d_prob):\n",
    "        '''The LSTM model used for training'''\n",
    "    \n",
    "        net = tflearn.embedding(net, input_dim=25, output_dim=25)\n",
    "        net = tflearn.lstm(net, 300, dropout=d_prob, dynamic=False, return_seq=True)\n",
    "        net = tflearn.lstm(net, 300, dropout=d_prob, dynamic=False, return_seq=True)\n",
    "        net = tflearn.lstm(net, 300)\n",
    "        net = tflearn.fully_connected(net, 150, activation='relu')\n",
    "        net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "        return net\n",
    "\n",
    "    \n",
    "\n",
    "    def num2letter(self, seq):\n",
    "        '''Takes in a seq of amino acids composed of numbers \n",
    "           and transforms them into the respective letters.'''\n",
    "    \n",
    "        letters = []\n",
    "    \n",
    "        for i in xrange(len(seq)):\n",
    "            letters.append(chr(int(seq[i]+97)))\n",
    "        \n",
    "        return letters\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_network(self):\n",
    "        \n",
    "        # send the input placeholder to the lstm \n",
    "        net = tflearn.input_data([None, self.test_len])\n",
    "        net = self.LSTM(net, 0.5) # get the output of the network\n",
    "        \n",
    "        # define optimizer, learning rate, and objective function\n",
    "        net = tflearn.regression(net, optimizer='adam',\n",
    "                                 learning_rate=0.00001,\n",
    "                                 loss='categorical_crossentropy')\n",
    "    \n",
    "        # instantiate the model\n",
    "        self.model = tflearn.DNN(net, tensorboard_verbose=1)\n",
    "        \n",
    "        # start tensorboard to visualize training \n",
    "        os.system('tensorboard --logdir=/tmp/tflearn_logs/ &')\n",
    "    \n",
    "        # call the training method with its parameters\n",
    "        self.model.fit(self.X, self.Y,  # data and labels\n",
    "                  n_epoch=self.epochs,  # number of times to loop through dataset\n",
    "                  validation_set=0.2, # proportion of data for validation\n",
    "                  shuffle=True,  # shuffle the data randomly\n",
    "                  show_metric=True,\n",
    "                  batch_size=150,  # number to train on each iteration\n",
    "                  snapshot_step=5000,  # how often to test validation set\n",
    "                  run_id='ProteinNet_' + str(self.test_len) + '_' + '_LSTM_' + self.kw)\n",
    "        \n",
    "        self.model.save('lstm' + str(self.test_len) + self.kw)  # save the model and its parameters\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def test_network(self):\n",
    "        fnames = glob.glob('*.index')\n",
    "        \n",
    "        try:\n",
    "            self.model.predict((np.zeros([1, self.test_len])))\n",
    "            self.test_seq = self.x1.tolist()\n",
    "            \n",
    "        except AttributeError:\n",
    "            # send the input placeholder to the lstm \n",
    "            net = tflearn.input_data([None, self.test_len])\n",
    "            net = self.LSTM(net, 1.0) # get the output of the network\n",
    "\n",
    "            # instantiate the model\n",
    "            self.model = tflearn.DNN(net, tensorboard_verbose=1)\n",
    "\n",
    "            # load the saved model you want to test\n",
    "            self.model.load('lstm' + str(self.test_len) + self.kw,\n",
    "                            weights_only=True)\n",
    "        \n",
    "        best = np.zeros([0, self.test_len])\n",
    "        best_out = []\n",
    "        bestexs = []\n",
    "        bestouts = []\n",
    "        \n",
    "        # go through the data again and find the sequence fragment\n",
    "        # with the highest activation from each protein\n",
    "        if self.test is not None:\n",
    "            self.test_seq = map(lambda x:x.lower(), list(self.test))\n",
    "            self.test_seq = np.asarray(self.test_seq)\n",
    "            self.test_seq = self.test_seq[None, :].tolist()\n",
    "        else: \n",
    "            if self.kw == 'User_Data':\n",
    "                self.test_seq = self.data[1]\n",
    "            else:\n",
    "                self.test_seq, _ = self.get_uniprot_data()\n",
    "            \n",
    "        print('Finding consensus sequences in your data...')\n",
    "        pbar = ProgressBar()\n",
    "        \n",
    "        for X1 in pbar(self.test_seq):\n",
    "            X1 = self.letter2num(X1)\n",
    "            x1out = np.asarray(self.model.predict(X1))\n",
    "            highest_out = np.argmax(x1out[:, 1])\n",
    "            best_out.append(x1out[highest_out, :])\n",
    "            best_ex = X1[highest_out, :]\n",
    "            \n",
    "            if len(self.test_seq) == 1:\n",
    "                print('This is the sequence found by the network.')\n",
    "                print(self.num2letter(best_ex))\n",
    "                sys.exit(0)\n",
    "            \n",
    "            best = np.concatenate((best, best_ex[None, :]), 0)\n",
    "        best_out = np.asarray(best_out)\n",
    "        \n",
    "        print('These are the top 5 sequences found by the lstm network.')\n",
    "        for i in range(5):\n",
    "            bestexs.append(best[np.argmax(best_out), :])\n",
    "            bestouts.append(np.amax(best_out))\n",
    "            best = np.delete(best, np.argmax(best_out), 0)\n",
    "            best_out = np.delete(best_out, np.argmax(best_out))\n",
    "\n",
    "        print(bestexs)\n",
    "        print(bestouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open your own data like this\n",
    "x1 = np.genfromtxt('BindProteins.txt', delimiter='\\n', dtype='str')\n",
    "x0 = np.genfromtxt('NoBindProteins.txt', delimiter='\\n', dtype='str')\n",
    "x1 = x1.tolist()\n",
    "x0 = x0.tolist()\n",
    "\n",
    "d = {}\n",
    "d[1] = x1\n",
    "d[0] = x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the uniprot keyword for proteins to get\n",
      "a consensus sequence from (e.g. homeobox, KW-0440, etc.). If you\n",
      "have your own data, type None.\n",
      "homeobox\n"
     ]
    }
   ],
   "source": [
    "# ask the user for a protein to find the consensus of \n",
    "kw = raw_input('''Enter the uniprot keyword for proteins to get\n",
    "a consensus sequence from (e.g. homeobox, KW-0440, etc.). If you\n",
    "have your own data, type None.\n",
    "''')\n",
    "\n",
    "if kw in ['None', 'none']:\n",
    "    kw = 'User_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'train' to train a model or 'test'\n",
      "to test a model.\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# prompt the user if they want to train or load a model\n",
    "t = raw_input('''Type 'train' to train a model or 'test'\n",
    "to test a model.\n",
    "''')\n",
    "\n",
    "if t in ['train', 'Train']:\n",
    "    Train = True\n",
    "else:\n",
    "    Train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What sequence length do you want to use?\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# ask the user what sequence length they want to use\n",
    "test_len = int(raw_input('''What sequence length do you want to use?\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from uniprot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93% |###################################################################     |\r"
     ]
    }
   ],
   "source": [
    "network = lstm_proteins(kw,\n",
    "                        test_len, \n",
    "                        Train, \n",
    "                        3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
