{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys,re,time,math\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "\n",
    "#指定第一块GPU可用 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "config = tf.ConfigProto() \n",
    "#不全部占满显存, 按需分配\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_svm(file):\n",
    "    encodings = []\n",
    "    labels = []\n",
    "    with open(file) as f:\n",
    "        records = f.readlines()\n",
    "\n",
    "    for line in records:\n",
    "        line = re.sub('\\d+:', '', line)\n",
    "        array = line.strip().split() if line.strip() != '' else None\n",
    "        encodings.append(array[1:])\n",
    "        labels.append(int(array[0]))\n",
    "\n",
    "    return np.array(encodings).astype(float), np.array(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ROC_curve(y_test,y_predict,savepath=None):\n",
    "    '''\n",
    "    画ROC曲线\n",
    "    '''\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test, y_predict)\n",
    "    roc_auc=auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('ROC')\n",
    "    plt.plot(false_positive_rate, true_positive_rate,'b',label='AUC = %0.3f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.savefig(savepath)\n",
    "    plt.close(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for a binary classifier\n",
    "def auc_1(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割并序列编码\n",
    "AA = 'GAVLIFWYDNEKQMSTCPHR'\n",
    "def pep(path, seq_len):\n",
    "    seqs = open(path).readlines()\n",
    "    cut = (len(seqs[0].split()[0]) - 1 - seq_len) // 2\n",
    "    X = [[AA.index(res.upper()) if res.upper() in AA else 0\n",
    "          for res in (seq.split()[0][cut:-cut] if cut != 0 else seq.split()[0])]\n",
    "        for seq in seqs if seq.strip() != '']\n",
    "    y = [int(seq.split()[-1]) for seq in seqs if seq.strip() != '']\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "path1 = 'C:/Users/Crow/Desktop/human_data/Step_11_CV/Train.txt'\n",
    "path2 = 'C:/Users/Crow/Desktop/human_data/Step_11_IND/Independent.txt'\n",
    "path_train =  'C:/Users/Crow/Desktop/human_data/Step_11_CV/Train_29_EGAAC_cv.txt'\n",
    "path_train2 = 'C;/Users/Crow/Desktop/human_data/Step_11_CV/Train_29_EGAAC_gap4.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data/Step_11_IND/Test_29_EGAAC_gap4.txt'\n",
    "\n",
    "\n",
    "plant_train = 'C:/Users/Crow/Desktop/plant_data/Step_11_CV/Train.txt'\n",
    "plant_test = 'C:/Users/Crow/Desktop/plant_data/Step_11_IND/Independent.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/EGAAC/Train_29_EGAAC_gap4.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/EGAAC/Test_29_EGAAC_gap4.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plant_train,y_plant_train = pep(plant_train,27)\n",
    "x_plant_test,y_plant_test = pep(plant_test,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n",
    "\n",
    "# x_train2,y_train2 = pep(path1,27)\n",
    "# x_test2,y_test2 = pep(path2,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(neurons=130,window=32,dropout=0.3,input_length=29):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(22, 32, input_length = input_length))\n",
    "\n",
    "    model.add(Conv1D(neurons, window, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(neurons, window, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(neurons, window, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Conv1D(neurons, window, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1dcnn_model(neurons=130,window=32,dropout=0.4,input_length=29):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(22, 32, input_length = input_length))\n",
    "    #model.add(Convolution1D(nb_filter=neurons, filter_length=window))\n",
    "    model.add(Conv1D(neurons, window, activation='relu', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout))\n",
    "    #model.add(Dense(2048, activation='relu'))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    #model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm(input_length=29):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(1024, 32, input_length = input_length))\n",
    "\n",
    "    model.add(LSTM(256))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # model.compile(loss='binary_crossentropy',\n",
    "    #               optimizer='adam',\n",
    "    #               metrics=['accuracy',auc_1])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bi_lstm(input_length=29):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(23, 32, input_length = input_length))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(32,return_sequences=True)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # model.compile(loss='binary_crossentropy',\n",
    "    #               optimizer='adam',\n",
    "    #               metrics=['accuracy',auc_1])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model2(input_length=29,dropout=0.4, shape=(130, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(22, 32, input_length = input_length))\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model4(input_length=29,dropout=0.4, shape=(130, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(21, 5, input_length = input_length))\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model5(input_length=29,dropout=0.4):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(21, 5, input_length = input_length))\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model6(input_length=29,dropout=0.4):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(21, 5, input_length = input_length))\n",
    "    model.add(Conv1D(128, 16, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 4, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model3(shape, dropout=0.4):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_score(path,pre,label):\n",
    "    fw = open(path, 'w')\n",
    "\n",
    "    for i in range(0,len(pre)):\n",
    "        fw.write(str(pre[i]).replace('[','').replace(']',''))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(label[i]))\n",
    "        fw.write('\\n')\n",
    "\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_1dcnn_model()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "model.fit(x_train2, y_train2,\n",
    "                   epochs = 25,\n",
    "                   batch_size = 32,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "print(model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## k-fold \n",
    "# human_data\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train2):\n",
    "\n",
    "    x_train3, x_test3 = x_train2[train_index], x_train2[test_index]\n",
    "    y_train3, y_test3 = y_train2[train_index], y_train2[test_index]\n",
    "    \n",
    "    human_model = create_cnn_model(input_length=29)\n",
    "    #filepath=\"C:/Users/Crow/Desktop/human_data/CNN/checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,mode='max', period=4)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    callbacks_list = [early_stopping]\n",
    "\n",
    "    human_model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 512,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(human_model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = human_model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_test2,pre,savepath='C:/Users/Crow/Desktop/human_data/CNN_k-fold_12.4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plant_data\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_plant_train):\n",
    "\n",
    "    x_train3, x_test3 = x_plant_train[train_index], x_plant_train[test_index]\n",
    "    y_train3, y_test3 = y_plant_train[train_index], y_plant_train[test_index]\n",
    "    \n",
    "    plant_model = create_cnn_model(input_length=51)\n",
    "    #filepath=\"C:/Users/Crow/Desktop/human_data/CNN/checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,mode='max', period=4)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    callbacks_list = [early_stopping]\n",
    "\n",
    "    human_model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "\n",
    "print(plant_model.evaluate(x_plant_test, y_plant_test, batch_size=256))\n",
    "pre = plant_model.predict(x_plant_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_plant_test,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_plant_test,pre,savepath='C:/Users/Crow/Desktop/plant_data/CNN_10-fold.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## k-fold \n",
    "# human_data\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train2):\n",
    "\n",
    "    x_train3, x_test3 = x_train2[train_index], x_train2[test_index]\n",
    "    y_train3, y_test3 = y_train2[train_index], y_train2[test_index]\n",
    "    \n",
    "    human_model = create_lstm(input_length=29)\n",
    "    #filepath=\"C:/Users/Crow/Desktop/human_data/CNN/checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,mode='max', period=4)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    callbacks_list = [early_stopping]\n",
    "\n",
    "    human_model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 512,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "human_model = create_bi_lstm(input_length=29)\n",
    "#human_model = create_lstm(input_length=29)\n",
    "    #filepath=\"C:/Users/Crow/Desktop/human_data/CNN/checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,mode='max', period=4)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "human_model.fit(x_train2, y_train2,\n",
    "                   epochs = 25,\n",
    "                   batch_size = 32,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "print(human_model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = human_model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_test2,pre,savepath='C:/Users/Crow/Desktop/human_data/BiLSTM_12.4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "model.fit(x_train2, y_train2,\n",
    "                   epochs = 25,\n",
    "                   batch_size = 512,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "print(model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_test2,pre,savepath='C:/Users/Crow/Desktop/human_data/BiLSTM_12.4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout=0.4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(22, 32, input_length = 29))\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train2, y_train2,\n",
    "                   epochs = 8,\n",
    "                   batch_size = 512,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "print(model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_test2,pre,savepath='C:/Users/Crow/Desktop/human_data/CNN/CNN_12.5.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/Crow/Desktop/human_data/CNN/128_8_0.4_3conv1d_12.5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plant_train,y_plant_train = pep(plant_train,27)\n",
    "x_plant_test,y_plant_test = pep(plant_test,27)\n",
    "\n",
    "\n",
    "dropout=0.5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(22, 256, input_length = 29))\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_plant_train, y_plant_train,\n",
    "                   epochs = 10,\n",
    "                   batch_size = 512,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "print(model.evaluate(x_plant_test, y_plant_test, batch_size=256))\n",
    "pre = model.predict(x_plant_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_plant_test,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_plant_test,pre,savepath='C:/Users/Crow/Desktop/plant_data/CNN/CNN_12.7.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/Crow/Desktop/plant_data/CNN/128_8_0.4_3conv1d_12.5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout=0.4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(22, 32, input_length = 130))\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=(130, 1)))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                   epochs = 30,\n",
    "                   batch_size = 512,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "print(model.evaluate(x_test, y_test, batch_size=256))\n",
    "pre = model.predict(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_test,pre,savepath='C:/Users/Crow/Desktop/human_data/CNN/CNN_12.10.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "seed=13\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 创建 1 维向量，并扩展维度适应 Keras 对输入的要求， data_1d 的大小为 (1, 25, 1)\n",
    "data_1d = np.random.normal(size=25)\n",
    "data_1d = np.expand_dims(data_1d, 0)\n",
    "data_1d = np.expand_dims(data_1d, 2)\n",
    "\n",
    "# 定义卷积层\n",
    "filters = 1 # 卷积核数量为 1\n",
    "kernel_size = 5 # 卷积核大小为 5\n",
    "convolution_1d_layer = Conv1D(filters, kernel_size, strides=1, padding='valid', input_shape=(25, 1), activation=\"relu\", name=\"convolution_1d_layer\")\n",
    "\n",
    "# 定义最大化池化层\n",
    "max_pooling_layer = MaxPool1D(pool_size=5, strides=1, padding=\"valid\", name=\"max_pooling_layer\")\n",
    "\n",
    "# 平铺层，调整维度适应全链接层\n",
    "reshape_layer = Flatten(name=\"reshape_layer\")\n",
    "\n",
    "# 定义全链接层\n",
    "full_connect_layer = Dense(5, kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.1, seed=seed), bias_initializer=\"random_normal\", use_bias=True, name=\"full_connect_layer\")\n",
    "\n",
    "# 编译模型\n",
    "model = Sequential()\n",
    "model.add(convolution_1d_layer)\n",
    "model.add(max_pooling_layer)\n",
    "model.add(reshape_layer)\n",
    "model.add(full_connect_layer)\n",
    "\n",
    "# 打印 full_connect_layer 层的输出\n",
    "output = Model(inputs=model.input, outputs=model.get_layer('full_connect_layer').output).predict(data_1d)\n",
    "print(output)\n",
    "\n",
    "# 打印网络结构\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train2):\n",
    "\n",
    "    x_train3, x_test3 = x_train2[train_index], x_train2[test_index]\n",
    "    y_train3, y_test3 = y_train2[train_index], y_train2[test_index]\n",
    "    \n",
    "    human_model = create_cnn_model2(input_length=29)\n",
    "    #filepath=\"C:/Users/Crow/Desktop/human_data/CNN/checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,mode='max', period=4)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    callbacks_list = [early_stopping]\n",
    "\n",
    "    human_model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 512,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(human_model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = human_model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "draw_ROC_curve(y_test2,pre,savepath='C:/Users/Crow/Desktop/human_data/CNN_k-fold_12.10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0,y_train0 = pep('C:/Users/Crow/Desktop/human_test/Train.txt',27)\n",
    "x_test0,y_test0 = pep('C:/Users/Crow/Desktop/human_test/Independent.txt',27)\n",
    "\n",
    "x_test_small,y_test_small = pep('C:/Users/Crow/Desktop/human_test/human_small.txt',27)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train2):\n",
    "\n",
    "    x_train3, x_test3 = x_train2[train_index], x_train2[test_index]\n",
    "    y_train3, y_test3 = y_train2[train_index], y_train2[test_index]\n",
    "    \n",
    "    human_model = create_cnn_model2(input_length=29)\n",
    "    #filepath=\"C:/Users/Crow/Desktop/human_data/CNN/checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,mode='max', period=4)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    callbacks_list = [early_stopping]\n",
    "\n",
    "    human_model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "print(human_model.evaluate(x_test0, y_test0, batch_size=256))\n",
    "pre = human_model.predict(x_test0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test0,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "\n",
    "print(human_model.evaluate(x_test_small, y_test_small, batch_size=256))\n",
    "pre = human_model.predict(x_test_small)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_small,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2,y_train2 = pep(path1,27)\n",
    "x_test2,y_test2 = pep(path2,27)\n",
    "x_train0,y_train0 = pep('C:/Users/Crow/Desktop/human_test/Train.txt',27)\n",
    "x_test0,y_test0 = pep('C:/Users/Crow/Desktop/human_test/Independent.txt',27)\n",
    "\n",
    "x_test_small,y_test_small = pep('C:/Users/Crow/Desktop/human_test/human_small.txt',27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = Sequential()\n",
    "\n",
    "\n",
    "# #     model.add(Embedding(22, 32, input_length = input_length))\n",
    "# #     model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=(130, 1)))\n",
    "# #     model.add(MaxPooling1D(2))\n",
    "# #     model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "# model.add(Embedding(22, 32, input_length=29))\n",
    "# model.add(Convolution1D(256, 8, padding='same',activation='relu'))\n",
    "# model.add(MaxPool1D(2))\n",
    "# model.add(Convolution1D(128, 8, padding='same',activation='relu'))\n",
    "# model.add(MaxPool1D(2))\n",
    "# model.add(Convolution1D(64, 3, padding='same',activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(BatchNormalization()) # (批)规范化层\n",
    "# model.add(Dense(256,activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Embedding(22, 32, input_length = 29))\n",
    "# model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "# model.add(MaxPooling1D(2))\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "# model.add(MaxPooling1D(2))\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "# model.add(MaxPooling1D(2))\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# callbacks_list = [early_stopping]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.fit(x_train0, y_train0,\n",
    "#                    epochs = 30,\n",
    "#                    batch_size = 256,\n",
    "#                    shuffle=True,validation_split = 0.2,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train2):\n",
    "\n",
    "    x_train3, x_test3 = x_train2[train_index], x_train2[test_index]\n",
    "    y_train3, y_test3 = y_train2[train_index], y_train2[test_index]\n",
    "    \n",
    "    model = create_cnn_model4(input_length=29)\n",
    "    #filepath=\"C:/Users/Crow/Desktop/human_data/CNN/checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,mode='max', period=4)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    callbacks_list = [early_stopping]\n",
    "\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(model.evaluate(x_train2, y_train2, batch_size=256))\n",
    "pre = model.predict(x_train2)\n",
    "fpr, tpr, thresholds = roc_curve(y_train2,pre,pos_label=1)\n",
    "pre1 = model.predict_classes(x_train2)\n",
    "print('human 合并 train')\n",
    "print( \"ACC:  %f \"  %accuracy_score(y_train2,pre1))\n",
    "print(\"AUC: %f\" % sklearn.metrics.auc(fpr, tpr))\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_train2,pre1))\n",
    "\n",
    "\n",
    "\n",
    "print(model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "pre1 = model.predict_classes(x_test2)\n",
    "print('human 合并test')\n",
    "print( \"ACC:  %f \"  %accuracy_score(y_test2,pre1))\n",
    "print(\"AUC: %f\" % sklearn.metrics.auc(fpr, tpr))\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test2,pre1))\n",
    "\n",
    "\n",
    "\n",
    "print(model.evaluate(x_test0, y_test0, batch_size=256))\n",
    "pre = model.predict(x_test0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test0,pre,pos_label=1)\n",
    "pre1 = model.predict_classes(x_test0)\n",
    "print('human large test')\n",
    "print( \"ACC:  %f \"  %accuracy_score(y_test0,pre1))\n",
    "print(\"AUC: %f\" % sklearn.metrics.auc(fpr, tpr))\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test0,pre1))\n",
    "\n",
    "\n",
    "print(model.evaluate(x_test_small, y_test_small, batch_size=256))\n",
    "pre = model.predict(x_test_small)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_small,pre,pos_label=1)\n",
    "pre1 = model.predict_classes(x_test_small)\n",
    "print('human mall')\n",
    "print( \"ACC:  %f \"  %accuracy_score(y_test_small,pre1))\n",
    "print(\"AUC: %f\" % sklearn.metrics.auc(fpr, tpr))\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test_small,pre1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(y_test_small,pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('c:/Users/Crow/Desktop/human_test/human_large_train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(human_model.evaluate(x_train2, y_train2, batch_size=256))\n",
    "pre = human_model.predict(x_train2)\n",
    "fpr, tpr, thresholds = roc_curve(y_train2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "\n",
    "pre1 = model.predict_classes(x_train2)\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_train2,pre1))\n",
    "print( \"ACC:  %f \"  %accuracy_score(y_train2,pre1))\n",
    "sklearn.metrics.accuracy_score(y_train2,pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1 = np.argmax(pre, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MCC: %f \" %matthews_corrcoef(y_train2,pre1))\n",
    "\n",
    "\n",
    "print( \"ACC:  %f \"  %accuracy_score(y_train2,pre1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(y_test_small,pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_model.evaluate(x_test0, y_test0, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_cat = np.argmax(y_train2, axis = 1) # convert one hot array to integers\n",
    "kf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train2, y_train2):\n",
    "\n",
    "   \n",
    "    x_train3, x_test3 = x_train2[train_index], x_train2[test_index]\n",
    "    y_train3, y_test3 = y_train2[train_index], y_train2[test_index]\n",
    "    model = create_cnn_model2(input_length=29)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    callbacks_list = [early_stopping]\n",
    "    #model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 1, batch_size = 64)\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "pre = model.predict(x_train2)\n",
    "fpr, tpr, thresholds = roc_curve(y_train2,pre,pos_label=1)\n",
    "pre1 = model.predict_classes(x_train2)\n",
    "precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_train2,pre1)\n",
    "print('human 合并 train')\n",
    "print(model.evaluate(x_train2, y_train2, batch_size=256))\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_train2,pre1))\n",
    "print(\"Sn: %f\" %SN)\n",
    "print(\"Sp: %f\" %SP)\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_train2,pre1))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "\n",
    "draw_ROC_curve(y_train2,pre,'human 合并 train')\n",
    "write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/Train_keras_result.txt',pre,y_train2)\n",
    "\n",
    "\n",
    "\n",
    "pre = model.predict(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "pre2 = model.predict_classes(x_test2)\n",
    "precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_test2,pre2)\n",
    "print('human 合并test')\n",
    "print(model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test2,pre2))\n",
    "print(\"Sn: %f\" %SN)\n",
    "print(\"Sp: %f\" %SP)\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test2,pre2))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "\n",
    "draw_ROC_curve(y_test2,pre,'human 合并test')\n",
    "write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/Test_keras_result.txt',pre,y_test2)\n",
    "\n",
    "# print(model.evaluate(x_test0, y_test0, batch_size=256))\n",
    "# pre = model.predict(x_test0)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test0,pre,pos_label=1)\n",
    "# pre3 = model.predict_classes(x_test0)\n",
    "# print('human large test')\n",
    "# print( \"ACC:  %f \"  %accuracy_score(y_test0,pre3))\n",
    "# print(\"AUC: %f\" % sklearn.metrics.auc(fpr, tpr))\n",
    "# print(\"MCC: %f \" %matthews_corrcoef(y_test0,pre3))\n",
    "# #draw_ROC_curve(y_test0,pre3,'human large test')\n",
    "\n",
    "# print(model.evaluate(x_test_small, y_test_small, batch_size=256))\n",
    "# pre = model.predict(x_test_small)\n",
    "# fpr, tpr, thresholds = roc_curve(y_test_small,pre,pos_label=1)\n",
    "# pre4 = model.predict_classes(x_test_small)\n",
    "# print('human mall')\n",
    "# print( \"ACC:  %f \"  %accuracy_score(y_test_small,pre4))\n",
    "# print(\"AUC: %f\" % sklearn.metrics.auc(fpr, tpr))\n",
    "# print(\"MCC: %f \" %matthews_corrcoef(y_test_small,pre4))\n",
    "#draw_ROC_curve(y_test_small,pre4,'human mall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(x_test_small, y_test_small, batch_size=256))\n",
    "pre = model.predict(x_test_small)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_small,pre,pos_label=1)\n",
    "pre4 = model.predict_classes(x_test_small)\n",
    "print('human mall')\n",
    "print( \"ACC:  %f \"  %accuracy_score(y_test_small,pre4))\n",
    "print(\"AUC: %f\" % sklearn.metrics.auc(fpr, tpr))\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test_small,pre4))\n",
    "draw_ROC_curve(y_test_small,pre,'human mall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test_small)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(x_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(y_test_small,pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(y_test_small,pre1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_roc(y_pred, y_true, classes=None, title=None, savefile=None):\n",
    "    \"\"\"This function plot the ROC curve and return the AUC\"\"\"\n",
    "    if len(y_pred.shape)==1:\n",
    "        y_pred = y_pred.reshape(y_pred.shape+(1,))\n",
    "        y_true = y_true.reshape(y_true.shape+(1,))\n",
    "   \n",
    "    n_classes = y_pred.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    if classes is None:\n",
    "        legends = ['class'+str(j+1) for j in range(n_classes)]\n",
    "    elif len(classes) == n_classes:\n",
    "        legends = classes\n",
    "    else:\n",
    "        raise ValueError(\"Number of classes doesn't match labels\")    \n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "    colors = cycle(['darkorange', 'cornflowerblue', 'navy', 'aqua'])    \n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color,\n",
    "                 label='ROC curve of {0} (area = {1:0.4f})'\n",
    "                 ''.format(legends[i], roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title('ROC curves for all classes')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if savefile:\n",
    "        plt.savefig(savefile, dpi=300)\n",
    "    return roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_ROC_curve(y_test_small,pre1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "\n",
    "model = create_cnn_model2(input_length=29)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "callbacks_list = [early_stopping]\n",
    "#model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 1, batch_size = 64)\n",
    "model.fit(x_train2, y_train2,\n",
    "                   epochs = 8,\n",
    "                   batch_size = 512,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "print(model.evaluate(x_test2, y_test2, batch_size=256))\n",
    "pre = model.predict(x_test2)\n",
    "pre2 = model.predict_classes(x_test2)\n",
    "fpr, tpr, thresholds = roc_curve(y_test2,pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "_,_,SN,SP,_,_,_,_,_ = performance(y_test2,pre2)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test2,pre2))\n",
    "print(\"Sn: %f\" %SN)\n",
    "print(\"Sp: %f\" %SP)\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test2,pre2))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('C:/Users/Crow/Desktop/human_data_12.12/record.txt', 'w')\n",
    "\n",
    "for i in range(0,len(pre)):\n",
    "    fw.write(str(pre[i]).replace('[','').replace(']',''))\n",
    "    fw.write('\\t')\n",
    "    fw.write(str(y_test2[i]))\n",
    "    fw.write('\\n')\n",
    "\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "Recall = Sn\n",
    "Precison = Sp\n",
    "plt.figure()\n",
    "plt.ylim(0,1.1)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.xlim(0,1.1)\n",
    "plt.ylabel(\"Precison\")\n",
    "plt.plot(Recall,Precison)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/EAAC/Train_29_EAAC_gap5.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/EAAC/Test_29_EAAC_gap5.txt'\n",
    "\n",
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "x_train = np.expand_dims(x_train, axis=2) \n",
    "x_test = np.expand_dims(x_test, axis=2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码测试\n",
    "\n",
    "dropout=0.4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Embedding(22, 32, input_length = 500))\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same',input_shape=(500,1)))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                   epochs = 20,\n",
    "                   batch_size = 512,\n",
    "                   shuffle=True,validation_split = 0.2,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "\n",
    "pre = model.predict(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,pre,pos_label=1)\n",
    "pre1 = model.predict_classes(x_test)\n",
    "precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_test,pre1)\n",
    "print('human 合并 train')\n",
    "print(model.evaluate(x_test, y_test, batch_size=256))\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,pre1))\n",
    "print(\"Sn: %f\" %SN)\n",
    "print(\"Sp: %f\" %SP)\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test,pre1))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "\n",
    "draw_ROC_curve(y_test,pre,'human 合并 train')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array(np.arange(1, 1+10*8*16).reshape([10, 8, 16]), dtype=np.float32)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 编码循环输出result\n",
    "name = 'ZSCALE'\n",
    "gap = ''\n",
    "#q = [21,23,25]\n",
    "#q = [21,23,25,27,29,31,35,37]\n",
    "q=[29]\n",
    "for t in q :\n",
    "    path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    train = read_svm(path_train)\n",
    "    test = read_svm(path_test)\n",
    "\n",
    "\n",
    "    x_train = train[0]\n",
    "    y_train = train[1]\n",
    "\n",
    "    x_test = test[0]\n",
    "    y_test = test[1]\n",
    "    x_train = np.expand_dims(x_train, axis=2) \n",
    "    x_test = np.expand_dims(x_test, axis=2) \n",
    "    shape = x_train.shape[1:]\n",
    "    \n",
    "    # k-fold\n",
    "    kf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "    for train_index, test_index in kf.split(x_train, y_train):\n",
    "        x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "        y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        model = create_cnn_model3(shape=shape)\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "        callbacks_list = [early_stopping]\n",
    "        model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,\n",
    "                  shuffle=True,callbacks=callbacks_list, verbose=0)\n",
    "    \n",
    "    print(t)\n",
    "    pre = model.predict(x_train)\n",
    "    write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_keras_'+ str(t) + '_'+ name + gap+'_result.txt',pre,y_train)\n",
    "\n",
    "\n",
    "\n",
    "    pre1 = model.predict(x_test)\n",
    "    write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_keras_'+ str(t) + '_'+ name+ gap+'_result.txt',pre1,y_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 编码循环输出result\n",
    "name = 'EGAAC'\n",
    "gap = '_gap4'\n",
    "#q = [21,23,25]\n",
    "q = [21,23,25,27,29,31,35,37]\n",
    "test_cutoff = [0.267451,0.257024,0.240165,0.25257,0.230415,0.207153,0.23201,0.243988]\n",
    "train_cutoff = [0.260379,0.254653,0.235919,0.24859,0.225346,0.198662,0.224679,0.239181]\n",
    "c = 0\n",
    "for t in q :\n",
    "    path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    train = read_svm(path_train)\n",
    "    test = read_svm(path_test)\n",
    "\n",
    "\n",
    "    x_train = train[0]\n",
    "    y_train = train[1]\n",
    "\n",
    "    x_test = test[0]\n",
    "    y_test = test[1]\n",
    "    x_train = np.expand_dims(x_train, axis=2) \n",
    "    x_test = np.expand_dims(x_test, axis=2) \n",
    "    shape = x_train.shape[1:]\n",
    "    \n",
    "    # k-fold\n",
    "    kf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "    for train_index, test_index in kf.split(x_train, y_train):\n",
    "        x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "        y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        model = create_cnn_model3(shape=shape)\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "        callbacks_list = [early_stopping]\n",
    "        model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,\n",
    "                  shuffle=True,callbacks=callbacks_list, verbose=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    pre1 = model.predict(x_test)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    for i in range(0,len(pre1)):\n",
    "        if pre1[i] > test_cutoff[c]:       \n",
    "            test_pred[i] = 1\n",
    "        else:\n",
    "            test_pred[i] = 0\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,pre1,pos_label=1)\n",
    "    precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_test,test_pred)\n",
    "    print(t)\n",
    "    print('test:')\n",
    "    print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "    print(\"Sn: %f\" %SN)\n",
    "    print(\"Sp: %f\" %SP)\n",
    "    print(\"MCC: %f \" %matthews_corrcoef(y_test,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    print(\"AUC: %f\" % roc_auc_score(y_test,pre1))\n",
    "    \n",
    "    \n",
    "    pre = model.predict(x_train)\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    for i in range(0,len(pre)):\n",
    "        if pre[i] > train_cutoff[c]:       \n",
    "            train_pred[i] = 1\n",
    "        else:\n",
    "            train_pred[i] = 0\n",
    "    fpr, tpr, thresholds = roc_curve(y_train,pre,pos_label=1)\n",
    "    precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_train,train_pred)\n",
    "    print(t)\n",
    "    print('train:')\n",
    "    print(\"ACC:  %f \"  %accuracy_score(y_train,train_pred))\n",
    "    print(\"Sn: %f\" %SN)\n",
    "    print(\"Sp: %f\" %SP)\n",
    "    print(\"MCC: %f \" %matthews_corrcoef(y_train,train_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    print(\"AUC: %f\" % roc_auc_score(y_train,pre))\n",
    "    \n",
    "    c+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'ZSCALE'\n",
    "gap = ''\n",
    "#q = [21,23,25]\n",
    "q = [21,23,25,27,29,31,35,37]\n",
    "test_cutoff = [0.277751,0.316778,0.264698,0.259903,0.3181,0.287056,0.285303,0.280947]\n",
    "train_cutoff = [0.269478,0.306824,0.255314,0.250627,0.306797,0.28015,0.27627,0.271199]\n",
    "\n",
    "\n",
    "c = 0\n",
    "for t in q :\n",
    "    path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    train = read_svm(path_train)\n",
    "    test = read_svm(path_test)\n",
    "\n",
    "\n",
    "    x_train = train[0]\n",
    "    y_train = train[1]\n",
    "\n",
    "    x_test = test[0]\n",
    "    y_test = test[1]\n",
    "    \n",
    "    path_test_result = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_keras_'+ str(t) + '_'+ name+ gap+'_result.txt'\n",
    "    path_train_result = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_keras_'+ str(t) + '_'+ name + gap+'_result.txt'\n",
    "    \n",
    "    test_result = pd.read_table(path_test_result, header=None)\n",
    "\n",
    "    train_result = pd.read_table(path_train_result, header=None)\n",
    "    \n",
    "    test_result_score = test_result[0]\n",
    "    test_pred = np.array(test_result[1]) \n",
    "    \n",
    "    train_result_score = train_result[0]\n",
    "    train_pred = np.array(train_result[1])\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(test_result_score)):\n",
    "        if test_result_score[i] > test_cutoff[c]:       \n",
    "            test_pred[i] = 1\n",
    "        else:\n",
    "            test_pred[i] = 0\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,test_result_score,pos_label=1)\n",
    "    precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_test,test_pred)\n",
    "    print(t)\n",
    "    print('test:')\n",
    "    print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "    print(\"Sn: %f\" %SN)\n",
    "    print(\"Sp: %f\" %SP)\n",
    "    print(\"MCC: %f \" %matthews_corrcoef(y_test,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    print(\"AUC: %f\" % roc_auc_score(y_test,test_result_score))\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(train_result_score)):\n",
    "        if train_result_score[i] > train_cutoff[c]:       \n",
    "            train_pred[i] = 1\n",
    "        else:\n",
    "            train_pred[i] = 0\n",
    "    fpr, tpr, thresholds = roc_curve(y_train,train_result_score,pos_label=1)\n",
    "    precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_train,train_pred)\n",
    "    print(t)\n",
    "    print('train:')\n",
    "    print(\"ACC:  %f \"  %accuracy_score(y_train,train_pred))\n",
    "    print(\"Sn: %f\" %SN)\n",
    "    print(\"Sp: %f\" %SP)\n",
    "    print(\"MCC: %f \" %matthews_corrcoef(y_train,train_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    print(\"AUC: %f\" % roc_auc_score(y_train,train_result_score))\n",
    "    \n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn_model4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world embedding sliding windows\n",
    "# keras 编码循环输出result\n",
    "name = 'Embedding'\n",
    "gap = ''\n",
    "#q = [21,23,25]\n",
    "q = [21,23,25,27,29,31,35,37]\n",
    "#q=[29]\n",
    "for t in q :\n",
    "    path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "    path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "    x_train,y_train = pep(path_train,t-2)\n",
    "    x_test,y_test = pep(path_test,t-2)\n",
    "\n",
    "\n",
    "    \n",
    "    shape = x_train.shape[1:]\n",
    "    \n",
    "    # k-fold\n",
    "    kf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "    for train_index, test_index in kf.split(x_train, y_train):\n",
    "        x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "        y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        model = create_cnn_model5(input_length=t)\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "        callbacks_list = [early_stopping]\n",
    "        model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,\n",
    "                  shuffle=True,callbacks=callbacks_list, verbose=0)\n",
    "    \n",
    "    print(t)\n",
    "    pre = model.predict(x_train)\n",
    "    write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_keras_'+ str(t) + '_'+ name + gap+'_result.txt',pre,y_train)\n",
    "\n",
    "\n",
    "    pre1 = model.predict(x_test)\n",
    "    write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_keras_'+ str(t) + '_'+ name+ gap+'_result.txt',pre1,y_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# world embedding sliding windows\n",
    "# keras 编码循环输出result\n",
    "name = 'Embedding'\n",
    "gap = ''\n",
    "q = [21,23,25,27,29,31,35,37]\n",
    "test_cutoff = [0.273422,0.268753,0.210156,0.272848,0.258505,0.300157,0.310499,0.201006]\n",
    "train_cutoff = [0.26536,0.25023,0.203575,0.250609,0.235935,0.27466,0.287076,0.184949]\n",
    "\n",
    "c = 0\n",
    "for t in q :\n",
    "    path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "    path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "    x_train,y_train = pep(path_train,t-2)\n",
    "    x_test,y_test = pep(path_test,t-2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    path_train_result = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_keras_'+ str(t) + '_'+ name + gap+'_result.txt'\n",
    "    path_test_result = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_keras_'+ str(t) + '_'+ name+ gap+'_result.txt'\n",
    "    \n",
    "    test_result = pd.read_table(path_test_result, header=None)\n",
    "\n",
    "    train_result = pd.read_table(path_train_result, header=None)\n",
    "    \n",
    "    test_result_score = test_result[0]\n",
    "    test_pred = np.array(test_result[1]) \n",
    "    \n",
    "    train_result_score = train_result[0]\n",
    "    train_pred = np.array(train_result[1])\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(test_result_score)):\n",
    "        if test_result_score[i] > test_cutoff[c]:       \n",
    "            test_pred[i] = 1\n",
    "        else:\n",
    "            test_pred[i] = 0\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,test_result_score,pos_label=1)\n",
    "    precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_test,test_pred)\n",
    "    print(t)\n",
    "    print('test:')\n",
    "    print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "    print(\"Sn: %f\" %SN)\n",
    "    print(\"Sp: %f\" %SP)\n",
    "    print(\"MCC: %f \" %matthews_corrcoef(y_test,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    print(\"AUC: %f\" % roc_auc_score(y_test,test_result_score))\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(train_result_score)):\n",
    "        if train_result_score[i] > train_cutoff[c]:       \n",
    "            train_pred[i] = 1\n",
    "        else:\n",
    "            train_pred[i] = 0\n",
    "    fpr, tpr, thresholds = roc_curve(y_train,train_result_score,pos_label=1)\n",
    "    precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_train,train_pred)\n",
    "    print(t)\n",
    "    print('train:')\n",
    "    print(\"ACC:  %f \"  %accuracy_score(y_train,train_pred))\n",
    "    print(\"Sn: %f\" %SN)\n",
    "    print(\"Sp: %f\" %SP)\n",
    "    print(\"MCC: %f \" %matthews_corrcoef(y_train,train_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    print(\"AUC: %f\" % roc_auc_score(y_train,train_result_score))\n",
    "    \n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'Embedding'\n",
    "gap = ''\n",
    "# 读取数据\n",
    "\n",
    "\n",
    "# path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_29_'+ name + gap +'.txt'\n",
    "# path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_29_'+ name + gap +'.txt'\n",
    "\n",
    "# train = read_svm(path_train)\n",
    "# test = read_svm(path_test)\n",
    "\n",
    "\n",
    "# x_train = train[0]\n",
    "# y_train = train[1]\n",
    "\n",
    "# x_test = test[0]\n",
    "# y_test = test[1]\n",
    "\n",
    "# x_train = np.expand_dims(x_train, axis=2) \n",
    "# x_test = np.expand_dims(x_test, axis=2) \n",
    "\n",
    "# shape = x_train.shape[1:]\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "x_train,y_train = pep(path_train,29-2)\n",
    "x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "\n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    callbacks_list = [early_stopping]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/result/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "   \n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "\n",
    "    \n",
    "    if j == 10:        \n",
    "        model.save('C:/Users/Crow/Desktop/result/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "        test_pred_proba = model.predict(x_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "        print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "        fw = open('C:/Users/Crow/Desktop/result/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "        for t in range(0,len(test_pred_proba)):\n",
    "            fw.write(str(test_pred_proba[t][0]))\n",
    "            fw.write('\\t')\n",
    "            fw.write(str(y_test[t]))\n",
    "            fw.write('\\n') \n",
    "        fw.close()\n",
    "    j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "model = create_cnn_model4(input_length=29)\n",
    "plot_model(model, to_file='C://Users/Crow/Desktop/model1.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组蛋白Train dataset 结果\n",
    "histone_data_p = pd.read_excel('C:/Users/Crow/Desktop/human_data_12.12/histone_train.xlsx',sheet_name='组蛋白正样本')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histone_data_n = pd.read_excel('C:/Users/Crow/Desktop/human_data_12.12/histone_train.xlsx',sheet_name='组蛋白负样本')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histone_data = histone_data_p.append(histone_data_n)\n",
    "order = ['Sequences', 'Protein ID', 'Site', 'Label']\n",
    "histone_data = histone_data[order]\n",
    "histone_data.to_csv('C:/Users/Crow/Desktop/1111.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 预测组蛋白数据\n",
    "model = load_model('C:/Users/Crow/Desktop/result/model/CNN_kfold_Embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test =  'C:/Users/Crow/Desktop/histone_train.txt'\n",
    "x_test,y_test = pep(path_test,29-2)\n",
    "test_pred_proba = model.predict(x_test)\n",
    "test_pred = model.predict_classes(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histone  no-histone train dataset 查重输出到文件\n",
    "path_test =  'C:/Users/Crow/Desktop/histone_train.txt'\n",
    "histone_data = pd.read_table(path_test,names= ['Sequences', 'Protein ID', 'Site', 'Label'])\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test2 =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "human_train = pd.read_table(path_train,names= ['Sequences', 'Protein ID', 'Site', 'Label'])\n",
    "human_test = pd.read_table(path_test2,names= ['Sequences', 'Protein ID', 'Site', 'Label'])\n",
    "# 查重输出文件\n",
    "# a = human_train.append(histone_data)\n",
    "# #a = histone_data.append(human_train)\n",
    "# dIndex = a.duplicated(['Protein ID', 'Site'])\n",
    "# b = a[dIndex]\n",
    "# b.to_excel('C:/Users/Crow/Desktop/hhh.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histone dataset 去除 no-histone dataset 重复的50条数据后，添加到no-histone dataset 训练测试\n",
    "a = human_train.append(histone_data)\n",
    "#a = histone_data.append(human_train)\n",
    "newDF=a.drop_duplicates(['Protein ID', 'Site'])\n",
    "newDF.to_excel('C:/Users/Crow/Desktop/histone_no-histone_train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用histone_no-histone_train 训练模型\n",
    "path_train1 = 'C:/Users/Crow/Desktop/no-histone.txt'\n",
    "path_train2 = 'C:/Users/Crow/Desktop/histone.txt'\n",
    "#path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "x_train1,y_train1 = pep(path_train1,29-2)\n",
    "x_train2,y_train2 = pep(path_train2,29-2)\n",
    "# 合并 numpy.ndarray\n",
    "x_train = np.concatenate((x_train1, x_train2))\n",
    "y_train = np.concatenate((y_train1, y_train2))\n",
    "x_test,y_test = pep(path_test,29-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks_list = [early_stopping]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test =  'C:/Users/Crow/Desktop/histone_train.txt'\n",
    "x_test,y_test = pep(path_test,29-2)\n",
    "test_pred_proba = model.predict(x_test)\n",
    "test_pred = model.predict_classes(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "x_test,y_test = pep(path_test,29-2)\n",
    "test_pred_proba = model.predict(x_test)\n",
    "test_pred = model.predict_classes(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test = pep(path_test,29-2)\n",
    "test_pred_proba = model.predict(x_test)\n",
    "test_pred = model.predict_classes(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新训练CNN word Embedding\n",
    "\n",
    "name = 'Embedding'\n",
    "gap = ''\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "x_train,y_train = pep(path_train,29-2)\n",
    "x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model5(input_length=29,dropout=0.5)\n",
    "    \n",
    "    filepath='C:/Users/Crow/Desktop/result/re_CNN_5/model/dropout0.5_checkpoint'+ str(j) +'-{val_loss:.2f}-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5'\n",
    "   \n",
    "    #filepath=\"C:/Users/Crow/Desktop/result/re_CNN/model/weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False,mode='auto', period=10)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks_list = [early_stopping,checkpoint]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 200, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/result/re_CNN_5/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "   \n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "\n",
    "    \n",
    "    if j == 10:   \n",
    "        print(\"总AUC: %f\" % mean(auc_mean))\n",
    "#         model.save('C:/Users/Crow/Desktop/result/re_CNN_5/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "#         test_pred_proba = model.predict(x_test)\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "#         print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "#         fw = open('C:/Users/Crow/Desktop/result/re_CNN_5/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "#         for t in range(0,len(test_pred_proba)):\n",
    "#             fw.write(str(test_pred_proba[t][0]))\n",
    "#             fw.write('\\t')\n",
    "#             fw.write(str(y_test[t]))\n",
    "#             fw.write('\\n') \n",
    "#         fw.close()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train[-4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/2000\n",
      "66413/66413 [==============================] - 3s 50us/step - loss: 0.3107 - acc: 0.9089 - val_loss: 0.2994 - val_acc: 0.9077\n",
      "Epoch 2/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.2934 - acc: 0.9096 - val_loss: 0.2862 - val_acc: 0.9077\n",
      "Epoch 3/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2661 - acc: 0.9096 - val_loss: 0.2641 - val_acc: 0.9077\n",
      "Epoch 4/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2539 - acc: 0.9095 - val_loss: 0.2536 - val_acc: 0.9077\n",
      "Epoch 5/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2478 - acc: 0.9093 - val_loss: 0.2496 - val_acc: 0.9077\n",
      "Epoch 6/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2420 - acc: 0.9091 - val_loss: 0.2546 - val_acc: 0.9068\n",
      "Epoch 7/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2401 - acc: 0.9095 - val_loss: 0.2419 - val_acc: 0.9079\n",
      "Epoch 8/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2337 - acc: 0.9092 - val_loss: 0.2406 - val_acc: 0.9075\n",
      "Epoch 9/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2308 - acc: 0.9091 - val_loss: 0.2397 - val_acc: 0.9073\n",
      "Epoch 10/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2293 - acc: 0.9101 - val_loss: 0.2375 - val_acc: 0.9079\n",
      "Epoch 11/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2253 - acc: 0.9105 - val_loss: 0.2392 - val_acc: 0.9084\n",
      "Epoch 12/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2218 - acc: 0.9104 - val_loss: 0.2375 - val_acc: 0.9068\n",
      "Epoch 13/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2203 - acc: 0.9108 - val_loss: 0.2360 - val_acc: 0.9077\n",
      "Epoch 14/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2177 - acc: 0.9119 - val_loss: 0.2414 - val_acc: 0.9020\n",
      "Epoch 15/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2153 - acc: 0.9121 - val_loss: 0.2361 - val_acc: 0.9061\n",
      "Epoch 16/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2116 - acc: 0.9139 - val_loss: 0.2454 - val_acc: 0.9014\n",
      "Epoch 17/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2109 - acc: 0.9146 - val_loss: 0.2403 - val_acc: 0.9033\n",
      "Epoch 18/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2096 - acc: 0.9142 - val_loss: 0.2395 - val_acc: 0.9034\n",
      "Epoch 19/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2093 - acc: 0.9145 - val_loss: 0.2370 - val_acc: 0.9049\n",
      "Epoch 20/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2061 - acc: 0.9159 - val_loss: 0.2388 - val_acc: 0.9015\n",
      "Epoch 21/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2033 - acc: 0.9172 - val_loss: 0.2423 - val_acc: 0.9016\n",
      "Epoch 22/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2037 - acc: 0.9166 - val_loss: 0.2450 - val_acc: 0.8963\n",
      "Epoch 23/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2015 - acc: 0.9165 - val_loss: 0.2412 - val_acc: 0.9011\n",
      "Epoch 24/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1986 - acc: 0.9183 - val_loss: 0.2404 - val_acc: 0.8995\n",
      "Epoch 25/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1984 - acc: 0.9192 - val_loss: 0.2384 - val_acc: 0.9023\n",
      "Epoch 26/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1967 - acc: 0.9196 - val_loss: 0.2412 - val_acc: 0.8984\n",
      "Epoch 27/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1952 - acc: 0.9188 - val_loss: 0.2372 - val_acc: 0.9019\n",
      "Epoch 28/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1939 - acc: 0.9203 - val_loss: 0.2501 - val_acc: 0.8913\n",
      "Epoch 29/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1933 - acc: 0.9193 - val_loss: 0.2499 - val_acc: 0.8927\n",
      "Epoch 30/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1921 - acc: 0.9205 - val_loss: 0.2390 - val_acc: 0.8982\n",
      "Epoch 31/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1927 - acc: 0.9209 - val_loss: 0.2466 - val_acc: 0.8973\n",
      "Epoch 32/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1926 - acc: 0.9211 - val_loss: 0.2434 - val_acc: 0.8974\n",
      "Epoch 33/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1895 - acc: 0.9218 - val_loss: 0.2524 - val_acc: 0.8879\n",
      "Epoch 34/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1890 - acc: 0.9219 - val_loss: 0.2579 - val_acc: 0.8850\n",
      "Epoch 35/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1877 - acc: 0.9230 - val_loss: 0.2487 - val_acc: 0.8909\n",
      "Epoch 36/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1871 - acc: 0.9229 - val_loss: 0.2431 - val_acc: 0.8981\n",
      "Epoch 37/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1859 - acc: 0.9236 - val_loss: 0.2511 - val_acc: 0.8893\n",
      "Epoch 38/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1852 - acc: 0.9242 - val_loss: 0.2527 - val_acc: 0.8879\n",
      "Epoch 39/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1822 - acc: 0.9236 - val_loss: 0.2408 - val_acc: 0.8988\n",
      "Epoch 40/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1842 - acc: 0.9246 - val_loss: 0.2460 - val_acc: 0.8939\n",
      "Epoch 41/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1813 - acc: 0.9250 - val_loss: 0.2549 - val_acc: 0.8862\n",
      "Epoch 42/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1808 - acc: 0.9242 - val_loss: 0.2521 - val_acc: 0.8908\n",
      "Epoch 43/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1802 - acc: 0.9256 - val_loss: 0.2433 - val_acc: 0.8963\n",
      "Epoch 44/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1802 - acc: 0.9249 - val_loss: 0.2540 - val_acc: 0.8870\n",
      "Epoch 45/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1784 - acc: 0.9252 - val_loss: 0.2468 - val_acc: 0.8930\n",
      "Epoch 46/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1784 - acc: 0.9259 - val_loss: 0.2578 - val_acc: 0.8822\n",
      "Epoch 47/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1785 - acc: 0.9258 - val_loss: 0.2501 - val_acc: 0.8890\n",
      "Epoch 48/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1767 - acc: 0.9270 - val_loss: 0.2551 - val_acc: 0.8855\n",
      "Epoch 49/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1726 - acc: 0.9286 - val_loss: 0.2575 - val_acc: 0.8839\n",
      "Epoch 50/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1748 - acc: 0.9275 - val_loss: 0.2588 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_1.hdf5\n",
      "Epoch 51/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1755 - acc: 0.9273 - val_loss: 0.2620 - val_acc: 0.8798\n",
      "Epoch 52/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1729 - acc: 0.9289 - val_loss: 0.2459 - val_acc: 0.8961\n",
      "Epoch 53/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.1743 - acc: 0.9272 - val_loss: 0.2517 - val_acc: 0.8873\n",
      "Epoch 54/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.1740 - acc: 0.9275 - val_loss: 0.2564 - val_acc: 0.8886\n",
      "Epoch 55/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1726 - acc: 0.9295 - val_loss: 0.2538 - val_acc: 0.8856\n",
      "Epoch 56/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1707 - acc: 0.9287 - val_loss: 0.2536 - val_acc: 0.8890\n",
      "Epoch 57/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1713 - acc: 0.9283 - val_loss: 0.2520 - val_acc: 0.8862\n",
      "Epoch 58/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1697 - acc: 0.9291 - val_loss: 0.2513 - val_acc: 0.8904\n",
      "Epoch 59/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1685 - acc: 0.9304 - val_loss: 0.2541 - val_acc: 0.8870\n",
      "Epoch 60/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1681 - acc: 0.9305 - val_loss: 0.2612 - val_acc: 0.8806\n",
      "Epoch 61/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1689 - acc: 0.9302 - val_loss: 0.2512 - val_acc: 0.8893\n",
      "Epoch 62/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1671 - acc: 0.9295 - val_loss: 0.2676 - val_acc: 0.8726\n",
      "Epoch 63/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1693 - acc: 0.9294 - val_loss: 0.2493 - val_acc: 0.8909\n",
      "AUC: 0.850693\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/2000\n",
      "66413/66413 [==============================] - 3s 51us/step - loss: 0.3175 - acc: 0.9057 - val_loss: 0.2893 - val_acc: 0.9123\n",
      "Epoch 2/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2819 - acc: 0.9091 - val_loss: 0.2569 - val_acc: 0.9123\n",
      "Epoch 3/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2592 - acc: 0.9091 - val_loss: 0.2528 - val_acc: 0.9123\n",
      "Epoch 4/2000\n",
      "66413/66413 [==============================] - 2s 35us/step - loss: 0.2505 - acc: 0.9089 - val_loss: 0.2387 - val_acc: 0.9123\n",
      "Epoch 5/2000\n",
      "66413/66413 [==============================] - 2s 33us/step - loss: 0.2448 - acc: 0.9092 - val_loss: 0.2345 - val_acc: 0.9123\n",
      "Epoch 6/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2390 - acc: 0.9090 - val_loss: 0.2325 - val_acc: 0.9126\n",
      "Epoch 7/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2364 - acc: 0.9093 - val_loss: 0.2338 - val_acc: 0.9117\n",
      "Epoch 8/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2324 - acc: 0.9093 - val_loss: 0.2317 - val_acc: 0.9130\n",
      "Epoch 9/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2291 - acc: 0.9095 - val_loss: 0.2310 - val_acc: 0.9126\n",
      "Epoch 10/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2277 - acc: 0.9103 - val_loss: 0.2286 - val_acc: 0.9119\n",
      "Epoch 11/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2242 - acc: 0.9101 - val_loss: 0.2314 - val_acc: 0.9095\n",
      "Epoch 12/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2215 - acc: 0.9108 - val_loss: 0.2314 - val_acc: 0.9083\n",
      "Epoch 13/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2211 - acc: 0.9112 - val_loss: 0.2284 - val_acc: 0.9134\n",
      "Epoch 14/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2177 - acc: 0.9114 - val_loss: 0.2311 - val_acc: 0.9088\n",
      "Epoch 15/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2144 - acc: 0.9135 - val_loss: 0.2281 - val_acc: 0.9111\n",
      "Epoch 16/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2149 - acc: 0.9131 - val_loss: 0.2304 - val_acc: 0.9099\n",
      "Epoch 17/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2112 - acc: 0.9142 - val_loss: 0.2291 - val_acc: 0.9117\n",
      "Epoch 18/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2080 - acc: 0.9145 - val_loss: 0.2332 - val_acc: 0.9081\n",
      "Epoch 19/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2073 - acc: 0.9150 - val_loss: 0.2298 - val_acc: 0.9084\n",
      "Epoch 20/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2072 - acc: 0.9155 - val_loss: 0.2300 - val_acc: 0.9117\n",
      "Epoch 21/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2040 - acc: 0.9165 - val_loss: 0.2328 - val_acc: 0.9065\n",
      "Epoch 22/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.2026 - acc: 0.9168 - val_loss: 0.2331 - val_acc: 0.9064\n",
      "Epoch 23/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2017 - acc: 0.9176 - val_loss: 0.2331 - val_acc: 0.9098\n",
      "Epoch 24/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1990 - acc: 0.9184 - val_loss: 0.2371 - val_acc: 0.9042\n",
      "Epoch 25/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.1985 - acc: 0.9190 - val_loss: 0.2308 - val_acc: 0.9108\n",
      "Epoch 26/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1966 - acc: 0.9202 - val_loss: 0.2428 - val_acc: 0.9015\n",
      "Epoch 27/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1945 - acc: 0.9204 - val_loss: 0.2367 - val_acc: 0.9068\n",
      "Epoch 28/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.1948 - acc: 0.9194 - val_loss: 0.2358 - val_acc: 0.9073\n",
      "Epoch 29/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1937 - acc: 0.9215 - val_loss: 0.2398 - val_acc: 0.9022\n",
      "Epoch 30/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1937 - acc: 0.9203 - val_loss: 0.2462 - val_acc: 0.8962\n",
      "Epoch 31/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1915 - acc: 0.9209 - val_loss: 0.2336 - val_acc: 0.9093\n",
      "Epoch 32/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1905 - acc: 0.9221 - val_loss: 0.2373 - val_acc: 0.9069\n",
      "Epoch 33/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1888 - acc: 0.9216 - val_loss: 0.2401 - val_acc: 0.9035\n",
      "Epoch 34/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1887 - acc: 0.9214 - val_loss: 0.2502 - val_acc: 0.8925\n",
      "Epoch 35/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1894 - acc: 0.9217 - val_loss: 0.2403 - val_acc: 0.9015\n",
      "Epoch 36/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1856 - acc: 0.9236 - val_loss: 0.2460 - val_acc: 0.8963\n",
      "Epoch 37/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1868 - acc: 0.9229 - val_loss: 0.2378 - val_acc: 0.9065\n",
      "Epoch 38/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1845 - acc: 0.9238 - val_loss: 0.2426 - val_acc: 0.9027\n",
      "Epoch 39/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1834 - acc: 0.9235 - val_loss: 0.2510 - val_acc: 0.8940\n",
      "Epoch 40/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1846 - acc: 0.9228 - val_loss: 0.2452 - val_acc: 0.9008\n",
      "Epoch 41/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1828 - acc: 0.9237 - val_loss: 0.2563 - val_acc: 0.8889\n",
      "Epoch 42/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1808 - acc: 0.9243 - val_loss: 0.2414 - val_acc: 0.9035\n",
      "Epoch 43/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1801 - acc: 0.9250 - val_loss: 0.2486 - val_acc: 0.8932\n",
      "Epoch 44/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1796 - acc: 0.9257 - val_loss: 0.2469 - val_acc: 0.8934\n",
      "Epoch 45/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1787 - acc: 0.9244 - val_loss: 0.2458 - val_acc: 0.8977\n",
      "Epoch 46/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1808 - acc: 0.9243 - val_loss: 0.2547 - val_acc: 0.8878\n",
      "Epoch 47/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1771 - acc: 0.9270 - val_loss: 0.2500 - val_acc: 0.8969\n",
      "Epoch 48/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1771 - acc: 0.9257 - val_loss: 0.2500 - val_acc: 0.8935\n",
      "Epoch 49/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1760 - acc: 0.9263 - val_loss: 0.2570 - val_acc: 0.8829\n",
      "Epoch 50/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1744 - acc: 0.9282 - val_loss: 0.2680 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_2.hdf5\n",
      "Epoch 51/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1759 - acc: 0.9266 - val_loss: 0.2538 - val_acc: 0.8888\n",
      "Epoch 52/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1725 - acc: 0.9283 - val_loss: 0.2449 - val_acc: 0.9005\n",
      "Epoch 53/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1731 - acc: 0.9273 - val_loss: 0.2662 - val_acc: 0.8770\n",
      "Epoch 54/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1751 - acc: 0.9265 - val_loss: 0.2452 - val_acc: 0.8970\n",
      "Epoch 55/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1734 - acc: 0.9276 - val_loss: 0.2601 - val_acc: 0.8859\n",
      "Epoch 56/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1727 - acc: 0.9274 - val_loss: 0.2648 - val_acc: 0.8789\n",
      "Epoch 57/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1702 - acc: 0.9284 - val_loss: 0.2615 - val_acc: 0.8810\n",
      "Epoch 58/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1712 - acc: 0.9287 - val_loss: 0.2540 - val_acc: 0.8909\n",
      "Epoch 59/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1695 - acc: 0.9292 - val_loss: 0.2593 - val_acc: 0.8835\n",
      "Epoch 60/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1699 - acc: 0.9298 - val_loss: 0.2574 - val_acc: 0.8870\n",
      "Epoch 61/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1702 - acc: 0.9292 - val_loss: 0.2589 - val_acc: 0.8885\n",
      "Epoch 62/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1701 - acc: 0.9291 - val_loss: 0.2605 - val_acc: 0.8829\n",
      "Epoch 63/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1712 - acc: 0.9296 - val_loss: 0.2647 - val_acc: 0.8833\n",
      "Epoch 64/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1672 - acc: 0.9306 - val_loss: 0.2649 - val_acc: 0.8791\n",
      "Epoch 65/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1666 - acc: 0.9307 - val_loss: 0.2700 - val_acc: 0.8762\n",
      "AUC: 0.834875\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/2000\n",
      "66413/66413 [==============================] - 3s 50us/step - loss: 0.3126 - acc: 0.9076 - val_loss: 0.2989 - val_acc: 0.9092\n",
      "Epoch 2/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2695 - acc: 0.9094 - val_loss: 0.2544 - val_acc: 0.9092\n",
      "Epoch 3/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2565 - acc: 0.9094 - val_loss: 0.2494 - val_acc: 0.9092\n",
      "Epoch 4/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2511 - acc: 0.9093 - val_loss: 0.2446 - val_acc: 0.9092\n",
      "Epoch 5/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2440 - acc: 0.9091 - val_loss: 0.2390 - val_acc: 0.9092\n",
      "Epoch 6/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2405 - acc: 0.9093 - val_loss: 0.2396 - val_acc: 0.9100\n",
      "Epoch 7/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2354 - acc: 0.9093 - val_loss: 0.2375 - val_acc: 0.9093\n",
      "Epoch 8/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2337 - acc: 0.9091 - val_loss: 0.2346 - val_acc: 0.9096\n",
      "Epoch 9/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2302 - acc: 0.9097 - val_loss: 0.2336 - val_acc: 0.9103\n",
      "Epoch 10/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2262 - acc: 0.9103 - val_loss: 0.2392 - val_acc: 0.9072\n",
      "Epoch 11/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2250 - acc: 0.9102 - val_loss: 0.2316 - val_acc: 0.9092\n",
      "Epoch 12/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2234 - acc: 0.9100 - val_loss: 0.2299 - val_acc: 0.9096\n",
      "Epoch 13/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.2215 - acc: 0.9106 - val_loss: 0.2308 - val_acc: 0.9092\n",
      "Epoch 14/2000\n",
      "66413/66413 [==============================] - 2s 33us/step - loss: 0.2188 - acc: 0.9115 - val_loss: 0.2400 - val_acc: 0.9070\n",
      "Epoch 15/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2161 - acc: 0.9119 - val_loss: 0.2308 - val_acc: 0.9091\n",
      "Epoch 16/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2143 - acc: 0.9128 - val_loss: 0.2304 - val_acc: 0.9095\n",
      "Epoch 17/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2119 - acc: 0.9137 - val_loss: 0.2323 - val_acc: 0.9057\n",
      "Epoch 18/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2104 - acc: 0.9133 - val_loss: 0.2318 - val_acc: 0.9069\n",
      "Epoch 19/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2093 - acc: 0.9153 - val_loss: 0.2308 - val_acc: 0.9087\n",
      "Epoch 20/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2084 - acc: 0.9155 - val_loss: 0.2309 - val_acc: 0.9065\n",
      "Epoch 21/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2060 - acc: 0.9148 - val_loss: 0.2300 - val_acc: 0.9103\n",
      "Epoch 22/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2039 - acc: 0.9166 - val_loss: 0.2313 - val_acc: 0.9093\n",
      "Epoch 23/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2036 - acc: 0.9168 - val_loss: 0.2314 - val_acc: 0.9064\n",
      "Epoch 24/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.2002 - acc: 0.9177 - val_loss: 0.2309 - val_acc: 0.9069\n",
      "Epoch 25/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.1986 - acc: 0.9177 - val_loss: 0.2301 - val_acc: 0.9085\n",
      "Epoch 26/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.1968 - acc: 0.9194 - val_loss: 0.2322 - val_acc: 0.9065\n",
      "Epoch 27/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1986 - acc: 0.9182 - val_loss: 0.2325 - val_acc: 0.9077\n",
      "Epoch 28/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1963 - acc: 0.9188 - val_loss: 0.2318 - val_acc: 0.9081\n",
      "Epoch 29/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1935 - acc: 0.9203 - val_loss: 0.2348 - val_acc: 0.9047\n",
      "Epoch 30/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1929 - acc: 0.9205 - val_loss: 0.2330 - val_acc: 0.9060\n",
      "Epoch 31/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1932 - acc: 0.9196 - val_loss: 0.2394 - val_acc: 0.9012\n",
      "Epoch 32/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1907 - acc: 0.9206 - val_loss: 0.2327 - val_acc: 0.9051\n",
      "Epoch 33/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1921 - acc: 0.9196 - val_loss: 0.2312 - val_acc: 0.9083\n",
      "Epoch 34/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1892 - acc: 0.9214 - val_loss: 0.2327 - val_acc: 0.9060\n",
      "Epoch 35/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1876 - acc: 0.9224 - val_loss: 0.2463 - val_acc: 0.8973\n",
      "Epoch 36/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1858 - acc: 0.9222 - val_loss: 0.2409 - val_acc: 0.9019\n",
      "Epoch 37/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1842 - acc: 0.9237 - val_loss: 0.2335 - val_acc: 0.9062\n",
      "Epoch 38/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1858 - acc: 0.9227 - val_loss: 0.2352 - val_acc: 0.9061\n",
      "Epoch 39/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1856 - acc: 0.9217 - val_loss: 0.2347 - val_acc: 0.9023\n",
      "Epoch 40/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1825 - acc: 0.9237 - val_loss: 0.2384 - val_acc: 0.9014\n",
      "Epoch 41/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1826 - acc: 0.9232 - val_loss: 0.2397 - val_acc: 0.9016\n",
      "Epoch 42/2000\n",
      "66413/66413 [==============================] - 2s 32us/step - loss: 0.1820 - acc: 0.9248 - val_loss: 0.2372 - val_acc: 0.9030\n",
      "Epoch 43/2000\n",
      "66413/66413 [==============================] - 2s 33us/step - loss: 0.1810 - acc: 0.9252 - val_loss: 0.2420 - val_acc: 0.9005\n",
      "Epoch 44/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1805 - acc: 0.9244 - val_loss: 0.2426 - val_acc: 0.9015\n",
      "Epoch 45/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1808 - acc: 0.9255 - val_loss: 0.2470 - val_acc: 0.8962\n",
      "Epoch 46/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1783 - acc: 0.9253 - val_loss: 0.2373 - val_acc: 0.9030\n",
      "Epoch 47/2000\n",
      "66413/66413 [==============================] - ETA: 0s - loss: 0.1786 - acc: 0.926 - 2s 31us/step - loss: 0.1789 - acc: 0.9259 - val_loss: 0.2488 - val_acc: 0.8940\n",
      "Epoch 48/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1766 - acc: 0.9260 - val_loss: 0.2393 - val_acc: 0.9011\n",
      "Epoch 49/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1776 - acc: 0.9268 - val_loss: 0.2392 - val_acc: 0.9012\n",
      "Epoch 50/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1767 - acc: 0.9270 - val_loss: 0.2469 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_3.hdf5\n",
      "Epoch 51/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1752 - acc: 0.9265 - val_loss: 0.2453 - val_acc: 0.8981\n",
      "Epoch 52/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1742 - acc: 0.9281 - val_loss: 0.2498 - val_acc: 0.8931\n",
      "Epoch 53/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1737 - acc: 0.9274 - val_loss: 0.2507 - val_acc: 0.8928\n",
      "Epoch 54/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1752 - acc: 0.9267 - val_loss: 0.2414 - val_acc: 0.9009\n",
      "Epoch 55/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1724 - acc: 0.9292 - val_loss: 0.2454 - val_acc: 0.8986\n",
      "Epoch 56/2000\n",
      "66413/66413 [==============================] - 2s 30us/step - loss: 0.1737 - acc: 0.9272 - val_loss: 0.2459 - val_acc: 0.8942\n",
      "Epoch 57/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1729 - acc: 0.9277 - val_loss: 0.2438 - val_acc: 0.8995\n",
      "Epoch 58/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1716 - acc: 0.9280 - val_loss: 0.2442 - val_acc: 0.8947\n",
      "Epoch 59/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1717 - acc: 0.9282 - val_loss: 0.2406 - val_acc: 0.9011\n",
      "Epoch 60/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1701 - acc: 0.9292 - val_loss: 0.2526 - val_acc: 0.8893\n",
      "Epoch 61/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1688 - acc: 0.9301 - val_loss: 0.2440 - val_acc: 0.8993\n",
      "Epoch 62/2000\n",
      "66413/66413 [==============================] - 2s 31us/step - loss: 0.1676 - acc: 0.9297 - val_loss: 0.2433 - val_acc: 0.9009\n",
      "AUC: 0.846401\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/2000\n",
      "66414/66414 [==============================] - 3s 52us/step - loss: 0.3131 - acc: 0.9079 - val_loss: 0.3008 - val_acc: 0.9053\n",
      "Epoch 2/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2794 - acc: 0.9098 - val_loss: 0.2672 - val_acc: 0.9053\n",
      "Epoch 3/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2600 - acc: 0.9098 - val_loss: 0.2545 - val_acc: 0.9053\n",
      "Epoch 4/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2512 - acc: 0.9099 - val_loss: 0.2466 - val_acc: 0.9053\n",
      "Epoch 5/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2457 - acc: 0.9097 - val_loss: 0.2415 - val_acc: 0.9046\n",
      "Epoch 6/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2406 - acc: 0.9099 - val_loss: 0.2377 - val_acc: 0.9053\n",
      "Epoch 7/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2366 - acc: 0.9094 - val_loss: 0.2347 - val_acc: 0.9066\n",
      "Epoch 8/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2333 - acc: 0.9101 - val_loss: 0.2343 - val_acc: 0.9057\n",
      "Epoch 9/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2292 - acc: 0.9109 - val_loss: 0.2326 - val_acc: 0.9058\n",
      "Epoch 10/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2281 - acc: 0.9107 - val_loss: 0.2351 - val_acc: 0.9053\n",
      "Epoch 11/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2255 - acc: 0.9108 - val_loss: 0.2339 - val_acc: 0.9051\n",
      "Epoch 12/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2231 - acc: 0.9110 - val_loss: 0.2309 - val_acc: 0.9062\n",
      "Epoch 13/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2205 - acc: 0.9116 - val_loss: 0.2307 - val_acc: 0.9069\n",
      "Epoch 14/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2195 - acc: 0.9121 - val_loss: 0.2321 - val_acc: 0.9058\n",
      "Epoch 15/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2163 - acc: 0.9124 - val_loss: 0.2294 - val_acc: 0.9065\n",
      "Epoch 16/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2151 - acc: 0.9123 - val_loss: 0.2313 - val_acc: 0.9068\n",
      "Epoch 17/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2138 - acc: 0.9138 - val_loss: 0.2292 - val_acc: 0.9069\n",
      "Epoch 18/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2113 - acc: 0.9145 - val_loss: 0.2332 - val_acc: 0.9038\n",
      "Epoch 19/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2077 - acc: 0.9155 - val_loss: 0.2312 - val_acc: 0.9042\n",
      "Epoch 20/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2075 - acc: 0.9157 - val_loss: 0.2325 - val_acc: 0.9047\n",
      "Epoch 21/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2045 - acc: 0.9156 - val_loss: 0.2326 - val_acc: 0.9061\n",
      "Epoch 22/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2054 - acc: 0.9158 - val_loss: 0.2327 - val_acc: 0.9068\n",
      "Epoch 23/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2011 - acc: 0.9174 - val_loss: 0.2366 - val_acc: 0.9000\n",
      "Epoch 24/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2006 - acc: 0.9178 - val_loss: 0.2331 - val_acc: 0.9026\n",
      "Epoch 25/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2008 - acc: 0.9172 - val_loss: 0.2429 - val_acc: 0.8990\n",
      "Epoch 26/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2005 - acc: 0.9177 - val_loss: 0.2329 - val_acc: 0.9038\n",
      "Epoch 27/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1985 - acc: 0.9181 - val_loss: 0.2328 - val_acc: 0.9034\n",
      "Epoch 28/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1959 - acc: 0.9197 - val_loss: 0.2304 - val_acc: 0.9042\n",
      "Epoch 29/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1956 - acc: 0.9193 - val_loss: 0.2332 - val_acc: 0.9046\n",
      "Epoch 30/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1939 - acc: 0.9197 - val_loss: 0.2360 - val_acc: 0.9015\n",
      "Epoch 31/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1930 - acc: 0.9199 - val_loss: 0.2347 - val_acc: 0.9008\n",
      "Epoch 32/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1913 - acc: 0.9211 - val_loss: 0.2356 - val_acc: 0.9007\n",
      "Epoch 33/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1877 - acc: 0.9231 - val_loss: 0.2388 - val_acc: 0.8977\n",
      "Epoch 34/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1884 - acc: 0.9223 - val_loss: 0.2406 - val_acc: 0.8944\n",
      "Epoch 35/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1906 - acc: 0.9206 - val_loss: 0.2394 - val_acc: 0.8973\n",
      "Epoch 36/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1872 - acc: 0.9223 - val_loss: 0.2396 - val_acc: 0.8986\n",
      "Epoch 37/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1854 - acc: 0.9234 - val_loss: 0.2481 - val_acc: 0.8927\n",
      "Epoch 38/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1869 - acc: 0.9223 - val_loss: 0.2384 - val_acc: 0.8978\n",
      "Epoch 39/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1853 - acc: 0.9239 - val_loss: 0.2438 - val_acc: 0.8959\n",
      "Epoch 40/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1839 - acc: 0.9239 - val_loss: 0.2470 - val_acc: 0.8940\n",
      "Epoch 41/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1828 - acc: 0.9237 - val_loss: 0.2419 - val_acc: 0.8932\n",
      "Epoch 42/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1822 - acc: 0.9241 - val_loss: 0.2425 - val_acc: 0.8966\n",
      "Epoch 43/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1805 - acc: 0.9254 - val_loss: 0.2426 - val_acc: 0.8959\n",
      "Epoch 44/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1806 - acc: 0.9256 - val_loss: 0.2403 - val_acc: 0.8965\n",
      "Epoch 45/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1804 - acc: 0.9250 - val_loss: 0.2507 - val_acc: 0.8894\n",
      "Epoch 46/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1782 - acc: 0.9265 - val_loss: 0.2429 - val_acc: 0.8977\n",
      "Epoch 47/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1803 - acc: 0.9243 - val_loss: 0.2511 - val_acc: 0.8920\n",
      "Epoch 48/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1767 - acc: 0.9270 - val_loss: 0.2452 - val_acc: 0.8950\n",
      "Epoch 49/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1769 - acc: 0.9264 - val_loss: 0.2576 - val_acc: 0.8826\n",
      "Epoch 50/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1770 - acc: 0.9268 - val_loss: 0.2474 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_4.hdf5\n",
      "Epoch 51/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1783 - acc: 0.9255 - val_loss: 0.2517 - val_acc: 0.8906\n",
      "Epoch 52/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1750 - acc: 0.9271 - val_loss: 0.2570 - val_acc: 0.8839\n",
      "Epoch 53/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1750 - acc: 0.9265 - val_loss: 0.2481 - val_acc: 0.8916\n",
      "Epoch 54/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1742 - acc: 0.9286 - val_loss: 0.2490 - val_acc: 0.8901\n",
      "Epoch 55/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1729 - acc: 0.9274 - val_loss: 0.2532 - val_acc: 0.8877\n",
      "Epoch 56/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1740 - acc: 0.9275 - val_loss: 0.2629 - val_acc: 0.8780\n",
      "Epoch 57/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1718 - acc: 0.9290 - val_loss: 0.2520 - val_acc: 0.8894\n",
      "Epoch 58/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1686 - acc: 0.9299 - val_loss: 0.2504 - val_acc: 0.8933\n",
      "Epoch 59/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1743 - acc: 0.9273 - val_loss: 0.2520 - val_acc: 0.8868\n",
      "Epoch 60/2000\n",
      "66414/66414 [==============================] - 2s 30us/step - loss: 0.1716 - acc: 0.9297 - val_loss: 0.2575 - val_acc: 0.8843\n",
      "Epoch 61/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1700 - acc: 0.9286 - val_loss: 0.2547 - val_acc: 0.8852\n",
      "Epoch 62/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1689 - acc: 0.9300 - val_loss: 0.2485 - val_acc: 0.8952\n",
      "Epoch 63/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1700 - acc: 0.9286 - val_loss: 0.2532 - val_acc: 0.8887\n",
      "Epoch 64/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1692 - acc: 0.9294 - val_loss: 0.2523 - val_acc: 0.8868\n",
      "Epoch 65/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1693 - acc: 0.9303 - val_loss: 0.2661 - val_acc: 0.8768\n",
      "Epoch 66/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1676 - acc: 0.9300 - val_loss: 0.2519 - val_acc: 0.8917\n",
      "Epoch 67/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1661 - acc: 0.9304 - val_loss: 0.2605 - val_acc: 0.8836\n",
      "AUC: 0.846892\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/2000\n",
      "66414/66414 [==============================] - 4s 53us/step - loss: 0.3073 - acc: 0.9078 - val_loss: 0.2924 - val_acc: 0.9064\n",
      "Epoch 2/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2697 - acc: 0.9097 - val_loss: 0.2593 - val_acc: 0.9064\n",
      "Epoch 3/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2563 - acc: 0.9097 - val_loss: 0.2473 - val_acc: 0.9064\n",
      "Epoch 4/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2472 - acc: 0.9095 - val_loss: 0.2455 - val_acc: 0.9064\n",
      "Epoch 5/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2440 - acc: 0.9090 - val_loss: 0.2392 - val_acc: 0.9074\n",
      "Epoch 6/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2392 - acc: 0.9092 - val_loss: 0.2407 - val_acc: 0.9092\n",
      "Epoch 7/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2359 - acc: 0.9091 - val_loss: 0.2348 - val_acc: 0.9074\n",
      "Epoch 8/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2318 - acc: 0.9098 - val_loss: 0.2351 - val_acc: 0.9092\n",
      "Epoch 9/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2299 - acc: 0.9101 - val_loss: 0.2333 - val_acc: 0.9077\n",
      "Epoch 10/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2270 - acc: 0.9106 - val_loss: 0.2336 - val_acc: 0.9074\n",
      "Epoch 11/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2249 - acc: 0.9102 - val_loss: 0.2333 - val_acc: 0.9088\n",
      "Epoch 12/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2221 - acc: 0.9120 - val_loss: 0.2296 - val_acc: 0.9076\n",
      "Epoch 13/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2205 - acc: 0.9118 - val_loss: 0.2326 - val_acc: 0.9054\n",
      "Epoch 14/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2179 - acc: 0.9128 - val_loss: 0.2344 - val_acc: 0.9026\n",
      "Epoch 15/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2157 - acc: 0.9135 - val_loss: 0.2330 - val_acc: 0.9058\n",
      "Epoch 16/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2155 - acc: 0.9128 - val_loss: 0.2316 - val_acc: 0.9054\n",
      "Epoch 17/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2113 - acc: 0.9140 - val_loss: 0.2317 - val_acc: 0.9045\n",
      "Epoch 18/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2118 - acc: 0.9145 - val_loss: 0.2344 - val_acc: 0.9034\n",
      "Epoch 19/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2087 - acc: 0.9152 - val_loss: 0.2298 - val_acc: 0.9068\n",
      "Epoch 20/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2068 - acc: 0.9155 - val_loss: 0.2331 - val_acc: 0.9064\n",
      "Epoch 21/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2056 - acc: 0.9159 - val_loss: 0.2311 - val_acc: 0.9074\n",
      "Epoch 22/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2059 - acc: 0.9160 - val_loss: 0.2301 - val_acc: 0.9035\n",
      "Epoch 23/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2028 - acc: 0.9170 - val_loss: 0.2336 - val_acc: 0.9024\n",
      "Epoch 24/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2020 - acc: 0.9175 - val_loss: 0.2394 - val_acc: 0.8996\n",
      "Epoch 25/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2002 - acc: 0.9189 - val_loss: 0.2413 - val_acc: 0.8975\n",
      "Epoch 26/2000\n",
      "66414/66414 [==============================] - 2s 33us/step - loss: 0.2001 - acc: 0.9179 - val_loss: 0.2368 - val_acc: 0.8973\n",
      "Epoch 27/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1983 - acc: 0.9192 - val_loss: 0.2413 - val_acc: 0.8963\n",
      "Epoch 28/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1982 - acc: 0.9186 - val_loss: 0.2316 - val_acc: 0.9031\n",
      "Epoch 29/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1959 - acc: 0.9194 - val_loss: 0.2434 - val_acc: 0.8939\n",
      "Epoch 30/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1954 - acc: 0.9194 - val_loss: 0.2379 - val_acc: 0.8988\n",
      "Epoch 31/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1923 - acc: 0.9211 - val_loss: 0.2379 - val_acc: 0.8989\n",
      "Epoch 32/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1915 - acc: 0.9208 - val_loss: 0.2381 - val_acc: 0.8982\n",
      "Epoch 33/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1918 - acc: 0.9211 - val_loss: 0.2348 - val_acc: 0.9004\n",
      "Epoch 34/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1909 - acc: 0.9210 - val_loss: 0.2353 - val_acc: 0.9020\n",
      "Epoch 35/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1887 - acc: 0.9220 - val_loss: 0.2409 - val_acc: 0.8971\n",
      "Epoch 36/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1890 - acc: 0.9217 - val_loss: 0.2379 - val_acc: 0.9008\n",
      "Epoch 37/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1857 - acc: 0.9234 - val_loss: 0.2391 - val_acc: 0.8961\n",
      "Epoch 38/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1855 - acc: 0.9228 - val_loss: 0.2447 - val_acc: 0.8948\n",
      "Epoch 39/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1869 - acc: 0.9236 - val_loss: 0.2407 - val_acc: 0.8986\n",
      "Epoch 40/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1856 - acc: 0.9236 - val_loss: 0.2372 - val_acc: 0.8999\n",
      "Epoch 41/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1846 - acc: 0.9242 - val_loss: 0.2481 - val_acc: 0.8882\n",
      "Epoch 42/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1814 - acc: 0.9251 - val_loss: 0.2432 - val_acc: 0.8920\n",
      "Epoch 43/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1828 - acc: 0.9233 - val_loss: 0.2490 - val_acc: 0.8905\n",
      "Epoch 44/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1820 - acc: 0.9248 - val_loss: 0.2429 - val_acc: 0.8946\n",
      "Epoch 45/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1804 - acc: 0.9250 - val_loss: 0.2492 - val_acc: 0.8887\n",
      "Epoch 46/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1810 - acc: 0.9255 - val_loss: 0.2421 - val_acc: 0.8946\n",
      "Epoch 47/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1796 - acc: 0.9256 - val_loss: 0.2456 - val_acc: 0.8908\n",
      "Epoch 48/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1791 - acc: 0.9265 - val_loss: 0.2522 - val_acc: 0.8882\n",
      "Epoch 49/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1769 - acc: 0.9266 - val_loss: 0.2556 - val_acc: 0.8872\n",
      "Epoch 50/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1786 - acc: 0.9258 - val_loss: 0.2358 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_5.hdf5\n",
      "Epoch 51/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1776 - acc: 0.9266 - val_loss: 0.2512 - val_acc: 0.8875\n",
      "Epoch 52/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1751 - acc: 0.9262 - val_loss: 0.2488 - val_acc: 0.8872\n",
      "Epoch 53/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1763 - acc: 0.9272 - val_loss: 0.2422 - val_acc: 0.8939\n",
      "Epoch 54/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1746 - acc: 0.9269 - val_loss: 0.2460 - val_acc: 0.8914\n",
      "Epoch 55/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1758 - acc: 0.9265 - val_loss: 0.2513 - val_acc: 0.8868\n",
      "Epoch 56/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1751 - acc: 0.9269 - val_loss: 0.2550 - val_acc: 0.8847\n",
      "Epoch 57/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1735 - acc: 0.9275 - val_loss: 0.2429 - val_acc: 0.8967\n",
      "Epoch 58/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1752 - acc: 0.9280 - val_loss: 0.2484 - val_acc: 0.8920\n",
      "Epoch 59/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1728 - acc: 0.9277 - val_loss: 0.2447 - val_acc: 0.8946\n",
      "Epoch 60/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1720 - acc: 0.9277 - val_loss: 0.2489 - val_acc: 0.8889\n",
      "Epoch 61/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1724 - acc: 0.9284 - val_loss: 0.2435 - val_acc: 0.8947\n",
      "Epoch 62/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1703 - acc: 0.9292 - val_loss: 0.2521 - val_acc: 0.8860\n",
      "AUC: 0.855829\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/2000\n",
      "66414/66414 [==============================] - 4s 54us/step - loss: 0.3106 - acc: 0.9088 - val_loss: 0.2768 - val_acc: 0.9125\n",
      "Epoch 2/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2697 - acc: 0.9090 - val_loss: 0.2526 - val_acc: 0.9125\n",
      "Epoch 3/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2551 - acc: 0.9091 - val_loss: 0.2496 - val_acc: 0.9125\n",
      "Epoch 4/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2454 - acc: 0.9088 - val_loss: 0.2393 - val_acc: 0.9123\n",
      "Epoch 5/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2410 - acc: 0.9094 - val_loss: 0.2397 - val_acc: 0.9112\n",
      "Epoch 6/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2364 - acc: 0.9088 - val_loss: 0.2503 - val_acc: 0.9102\n",
      "Epoch 7/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2332 - acc: 0.9094 - val_loss: 0.2331 - val_acc: 0.9119\n",
      "Epoch 8/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2299 - acc: 0.9099 - val_loss: 0.2334 - val_acc: 0.9120\n",
      "Epoch 9/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2273 - acc: 0.9100 - val_loss: 0.2318 - val_acc: 0.9123\n",
      "Epoch 10/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2234 - acc: 0.9099 - val_loss: 0.2338 - val_acc: 0.9088\n",
      "Epoch 11/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2227 - acc: 0.9110 - val_loss: 0.2312 - val_acc: 0.9087\n",
      "Epoch 12/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2211 - acc: 0.9106 - val_loss: 0.2338 - val_acc: 0.9085\n",
      "Epoch 13/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2168 - acc: 0.9133 - val_loss: 0.2380 - val_acc: 0.9058\n",
      "Epoch 14/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2154 - acc: 0.9130 - val_loss: 0.2336 - val_acc: 0.9083\n",
      "Epoch 15/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2133 - acc: 0.9139 - val_loss: 0.2305 - val_acc: 0.9107\n",
      "Epoch 16/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2136 - acc: 0.9138 - val_loss: 0.2321 - val_acc: 0.9092\n",
      "Epoch 17/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2107 - acc: 0.9146 - val_loss: 0.2408 - val_acc: 0.9016\n",
      "Epoch 18/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2075 - acc: 0.9149 - val_loss: 0.2339 - val_acc: 0.9031\n",
      "Epoch 19/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2067 - acc: 0.9149 - val_loss: 0.2344 - val_acc: 0.9066\n",
      "Epoch 20/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2071 - acc: 0.9150 - val_loss: 0.2302 - val_acc: 0.9137\n",
      "Epoch 21/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2033 - acc: 0.9168 - val_loss: 0.2312 - val_acc: 0.9107\n",
      "Epoch 22/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2009 - acc: 0.9176 - val_loss: 0.2343 - val_acc: 0.9058\n",
      "Epoch 23/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2010 - acc: 0.9178 - val_loss: 0.2452 - val_acc: 0.8974\n",
      "Epoch 24/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2001 - acc: 0.9172 - val_loss: 0.2368 - val_acc: 0.9046\n",
      "Epoch 25/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1982 - acc: 0.9187 - val_loss: 0.2352 - val_acc: 0.9078\n",
      "Epoch 26/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1961 - acc: 0.9188 - val_loss: 0.2461 - val_acc: 0.8920\n",
      "Epoch 27/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1962 - acc: 0.9191 - val_loss: 0.2384 - val_acc: 0.8988\n",
      "Epoch 28/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1934 - acc: 0.9205 - val_loss: 0.2395 - val_acc: 0.9012\n",
      "Epoch 29/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1941 - acc: 0.9203 - val_loss: 0.2429 - val_acc: 0.8938\n",
      "Epoch 30/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1919 - acc: 0.9205 - val_loss: 0.2487 - val_acc: 0.8905\n",
      "Epoch 31/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1918 - acc: 0.9210 - val_loss: 0.2491 - val_acc: 0.8913\n",
      "Epoch 32/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1890 - acc: 0.9214 - val_loss: 0.2553 - val_acc: 0.8860\n",
      "Epoch 33/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1899 - acc: 0.9212 - val_loss: 0.2516 - val_acc: 0.8885\n",
      "Epoch 34/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1890 - acc: 0.9216 - val_loss: 0.2603 - val_acc: 0.8821\n",
      "Epoch 35/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1878 - acc: 0.9222 - val_loss: 0.2485 - val_acc: 0.8909\n",
      "Epoch 36/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1849 - acc: 0.9234 - val_loss: 0.2457 - val_acc: 0.8914\n",
      "Epoch 37/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1862 - acc: 0.9228 - val_loss: 0.2563 - val_acc: 0.8826\n",
      "Epoch 38/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1856 - acc: 0.9228 - val_loss: 0.2468 - val_acc: 0.8902\n",
      "Epoch 39/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1829 - acc: 0.9246 - val_loss: 0.2496 - val_acc: 0.8891\n",
      "Epoch 40/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1815 - acc: 0.9249 - val_loss: 0.2493 - val_acc: 0.8898\n",
      "Epoch 41/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1840 - acc: 0.9230 - val_loss: 0.2724 - val_acc: 0.8691\n",
      "Epoch 42/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1815 - acc: 0.9252 - val_loss: 0.2527 - val_acc: 0.8870\n",
      "Epoch 43/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1805 - acc: 0.9252 - val_loss: 0.2533 - val_acc: 0.8883\n",
      "Epoch 44/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1792 - acc: 0.9263 - val_loss: 0.2478 - val_acc: 0.8954\n",
      "Epoch 45/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1791 - acc: 0.9259 - val_loss: 0.2717 - val_acc: 0.8669\n",
      "Epoch 46/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1791 - acc: 0.9248 - val_loss: 0.2547 - val_acc: 0.8837\n",
      "Epoch 47/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1768 - acc: 0.9269 - val_loss: 0.2601 - val_acc: 0.8793\n",
      "Epoch 48/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1760 - acc: 0.9281 - val_loss: 0.2524 - val_acc: 0.8863\n",
      "Epoch 49/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1769 - acc: 0.9271 - val_loss: 0.2727 - val_acc: 0.8687\n",
      "Epoch 50/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1760 - acc: 0.9275 - val_loss: 0.2463 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_6.hdf5\n",
      "Epoch 51/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1749 - acc: 0.9275 - val_loss: 0.2590 - val_acc: 0.8810\n",
      "Epoch 52/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1733 - acc: 0.9285 - val_loss: 0.2518 - val_acc: 0.8859\n",
      "Epoch 53/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1733 - acc: 0.9286 - val_loss: 0.2590 - val_acc: 0.8818\n",
      "Epoch 54/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1739 - acc: 0.9294 - val_loss: 0.2608 - val_acc: 0.8835\n",
      "Epoch 55/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1718 - acc: 0.9285 - val_loss: 0.2572 - val_acc: 0.8841\n",
      "Epoch 56/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1743 - acc: 0.9280 - val_loss: 0.2484 - val_acc: 0.8929\n",
      "Epoch 57/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1722 - acc: 0.9295 - val_loss: 0.2580 - val_acc: 0.8780\n",
      "Epoch 58/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1707 - acc: 0.9291 - val_loss: 0.2765 - val_acc: 0.8675\n",
      "Epoch 59/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1710 - acc: 0.9294 - val_loss: 0.2627 - val_acc: 0.8782\n",
      "Epoch 60/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1685 - acc: 0.9309 - val_loss: 0.2564 - val_acc: 0.8809\n",
      "Epoch 61/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1708 - acc: 0.9297 - val_loss: 0.2659 - val_acc: 0.8757\n",
      "Epoch 62/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1699 - acc: 0.9288 - val_loss: 0.2697 - val_acc: 0.8703\n",
      "Epoch 63/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1681 - acc: 0.9295 - val_loss: 0.2568 - val_acc: 0.8822\n",
      "Epoch 64/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1684 - acc: 0.9309 - val_loss: 0.2928 - val_acc: 0.8563\n",
      "Epoch 65/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1672 - acc: 0.9306 - val_loss: 0.2616 - val_acc: 0.8837\n",
      "Epoch 66/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1682 - acc: 0.9304 - val_loss: 0.2590 - val_acc: 0.8851\n",
      "Epoch 67/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1672 - acc: 0.9303 - val_loss: 0.2648 - val_acc: 0.8791\n",
      "Epoch 68/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1674 - acc: 0.9302 - val_loss: 0.2672 - val_acc: 0.8759\n",
      "Epoch 69/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1667 - acc: 0.9301 - val_loss: 0.2570 - val_acc: 0.8862\n",
      "Epoch 70/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1652 - acc: 0.9318 - val_loss: 0.2836 - val_acc: 0.8619\n",
      "AUC: 0.835227\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/2000\n",
      "66414/66414 [==============================] - 4s 57us/step - loss: 0.3077 - acc: 0.9070 - val_loss: 0.2800 - val_acc: 0.9068\n",
      "Epoch 2/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2673 - acc: 0.9097 - val_loss: 0.2585 - val_acc: 0.9068\n",
      "Epoch 3/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2560 - acc: 0.9097 - val_loss: 0.2489 - val_acc: 0.9068\n",
      "Epoch 4/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2494 - acc: 0.9096 - val_loss: 0.2414 - val_acc: 0.9069\n",
      "Epoch 5/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2425 - acc: 0.9091 - val_loss: 0.2369 - val_acc: 0.9069\n",
      "Epoch 6/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2385 - acc: 0.9096 - val_loss: 0.2366 - val_acc: 0.9065\n",
      "Epoch 7/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2357 - acc: 0.9095 - val_loss: 0.2327 - val_acc: 0.9069\n",
      "Epoch 8/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2320 - acc: 0.9098 - val_loss: 0.2335 - val_acc: 0.9074\n",
      "Epoch 9/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2293 - acc: 0.9100 - val_loss: 0.2327 - val_acc: 0.9072\n",
      "Epoch 10/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2250 - acc: 0.9108 - val_loss: 0.2296 - val_acc: 0.9083\n",
      "Epoch 11/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2231 - acc: 0.9113 - val_loss: 0.2328 - val_acc: 0.9089\n",
      "Epoch 12/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2208 - acc: 0.9110 - val_loss: 0.2314 - val_acc: 0.9083\n",
      "Epoch 13/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2186 - acc: 0.9116 - val_loss: 0.2331 - val_acc: 0.9072\n",
      "Epoch 14/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2174 - acc: 0.9126 - val_loss: 0.2309 - val_acc: 0.9069\n",
      "Epoch 15/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2144 - acc: 0.9124 - val_loss: 0.2327 - val_acc: 0.9085\n",
      "Epoch 16/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2133 - acc: 0.9130 - val_loss: 0.2309 - val_acc: 0.9081\n",
      "Epoch 17/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2112 - acc: 0.9142 - val_loss: 0.2312 - val_acc: 0.9062\n",
      "Epoch 18/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2097 - acc: 0.9148 - val_loss: 0.2424 - val_acc: 0.9003\n",
      "Epoch 19/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2063 - acc: 0.9163 - val_loss: 0.2325 - val_acc: 0.9065\n",
      "Epoch 20/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2066 - acc: 0.9156 - val_loss: 0.2300 - val_acc: 0.9087\n",
      "Epoch 21/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2037 - acc: 0.9167 - val_loss: 0.2312 - val_acc: 0.9049\n",
      "Epoch 22/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2034 - acc: 0.9160 - val_loss: 0.2330 - val_acc: 0.9064\n",
      "Epoch 23/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2014 - acc: 0.9175 - val_loss: 0.2310 - val_acc: 0.9046\n",
      "Epoch 24/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1986 - acc: 0.9183 - val_loss: 0.2371 - val_acc: 0.9023\n",
      "Epoch 25/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1979 - acc: 0.9183 - val_loss: 0.2379 - val_acc: 0.9009\n",
      "Epoch 26/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1960 - acc: 0.9201 - val_loss: 0.2359 - val_acc: 0.9028\n",
      "Epoch 27/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1963 - acc: 0.9195 - val_loss: 0.2329 - val_acc: 0.9064\n",
      "Epoch 28/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1962 - acc: 0.9195 - val_loss: 0.2325 - val_acc: 0.9061\n",
      "Epoch 29/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1930 - acc: 0.9202 - val_loss: 0.2405 - val_acc: 0.9013\n",
      "Epoch 30/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1923 - acc: 0.9211 - val_loss: 0.2358 - val_acc: 0.9017\n",
      "Epoch 31/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1913 - acc: 0.9203 - val_loss: 0.2346 - val_acc: 0.9055\n",
      "Epoch 32/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1904 - acc: 0.9223 - val_loss: 0.2399 - val_acc: 0.8992\n",
      "Epoch 33/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1896 - acc: 0.9222 - val_loss: 0.2349 - val_acc: 0.9049\n",
      "Epoch 34/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1876 - acc: 0.9218 - val_loss: 0.2360 - val_acc: 0.9047\n",
      "Epoch 35/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1870 - acc: 0.9228 - val_loss: 0.2381 - val_acc: 0.9057\n",
      "Epoch 36/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1848 - acc: 0.9243 - val_loss: 0.2380 - val_acc: 0.9023\n",
      "Epoch 37/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1836 - acc: 0.9244 - val_loss: 0.2439 - val_acc: 0.8977\n",
      "Epoch 38/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1835 - acc: 0.9234 - val_loss: 0.2488 - val_acc: 0.8959\n",
      "Epoch 39/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1843 - acc: 0.9240 - val_loss: 0.2428 - val_acc: 0.8986\n",
      "Epoch 40/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1828 - acc: 0.9237 - val_loss: 0.2393 - val_acc: 0.9031\n",
      "Epoch 41/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1816 - acc: 0.9245 - val_loss: 0.2439 - val_acc: 0.9012\n",
      "Epoch 42/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1819 - acc: 0.9252 - val_loss: 0.2451 - val_acc: 0.8963\n",
      "Epoch 43/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1785 - acc: 0.9272 - val_loss: 0.2483 - val_acc: 0.8938\n",
      "Epoch 44/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1797 - acc: 0.9245 - val_loss: 0.2433 - val_acc: 0.8969\n",
      "Epoch 45/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1771 - acc: 0.9275 - val_loss: 0.2453 - val_acc: 0.8959\n",
      "Epoch 46/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1778 - acc: 0.9274 - val_loss: 0.2466 - val_acc: 0.8971\n",
      "Epoch 47/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1767 - acc: 0.9269 - val_loss: 0.2432 - val_acc: 0.9000\n",
      "Epoch 48/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1789 - acc: 0.9270 - val_loss: 0.2416 - val_acc: 0.9009\n",
      "Epoch 49/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1760 - acc: 0.9264 - val_loss: 0.2460 - val_acc: 0.8956\n",
      "Epoch 50/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1749 - acc: 0.9272 - val_loss: 0.2469 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_7.hdf5\n",
      "Epoch 51/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1734 - acc: 0.9280 - val_loss: 0.2458 - val_acc: 0.8956\n",
      "Epoch 52/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1731 - acc: 0.9285 - val_loss: 0.2438 - val_acc: 0.8978\n",
      "Epoch 53/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1723 - acc: 0.9283 - val_loss: 0.2457 - val_acc: 0.8954\n",
      "Epoch 54/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1695 - acc: 0.9282 - val_loss: 0.2425 - val_acc: 0.9008\n",
      "Epoch 55/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1730 - acc: 0.9280 - val_loss: 0.2510 - val_acc: 0.8917\n",
      "Epoch 56/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1713 - acc: 0.9293 - val_loss: 0.2429 - val_acc: 0.8967\n",
      "Epoch 57/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1716 - acc: 0.9295 - val_loss: 0.2433 - val_acc: 0.8982\n",
      "Epoch 58/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1686 - acc: 0.9297 - val_loss: 0.2453 - val_acc: 0.8963\n",
      "Epoch 59/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1704 - acc: 0.9303 - val_loss: 0.2426 - val_acc: 0.9009\n",
      "Epoch 60/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1691 - acc: 0.9300 - val_loss: 0.2477 - val_acc: 0.8943\n",
      "AUC: 0.851594\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/2000\n",
      "66414/66414 [==============================] - 4s 58us/step - loss: 0.3118 - acc: 0.9080 - val_loss: 0.3003 - val_acc: 0.9087\n",
      "Epoch 2/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2875 - acc: 0.9095 - val_loss: 0.2680 - val_acc: 0.9087\n",
      "Epoch 3/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2624 - acc: 0.9095 - val_loss: 0.2480 - val_acc: 0.9087\n",
      "Epoch 4/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2542 - acc: 0.9094 - val_loss: 0.2443 - val_acc: 0.9087\n",
      "Epoch 5/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2482 - acc: 0.9094 - val_loss: 0.2402 - val_acc: 0.9087\n",
      "Epoch 6/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2431 - acc: 0.9091 - val_loss: 0.2342 - val_acc: 0.9089\n",
      "Epoch 7/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2391 - acc: 0.9090 - val_loss: 0.2328 - val_acc: 0.9092\n",
      "Epoch 8/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2350 - acc: 0.9093 - val_loss: 0.2328 - val_acc: 0.9092\n",
      "Epoch 9/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2333 - acc: 0.9100 - val_loss: 0.2319 - val_acc: 0.9097\n",
      "Epoch 10/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2279 - acc: 0.9099 - val_loss: 0.2284 - val_acc: 0.9095\n",
      "Epoch 11/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2255 - acc: 0.9106 - val_loss: 0.2339 - val_acc: 0.9081\n",
      "Epoch 12/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2236 - acc: 0.9108 - val_loss: 0.2277 - val_acc: 0.9104\n",
      "Epoch 13/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2208 - acc: 0.9116 - val_loss: 0.2293 - val_acc: 0.9107\n",
      "Epoch 14/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2188 - acc: 0.9114 - val_loss: 0.2292 - val_acc: 0.9111\n",
      "Epoch 15/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2163 - acc: 0.9119 - val_loss: 0.2368 - val_acc: 0.9076\n",
      "Epoch 16/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2156 - acc: 0.9124 - val_loss: 0.2329 - val_acc: 0.9080\n",
      "Epoch 17/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2126 - acc: 0.9138 - val_loss: 0.2269 - val_acc: 0.9089\n",
      "Epoch 18/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2102 - acc: 0.9139 - val_loss: 0.2294 - val_acc: 0.9076\n",
      "Epoch 19/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2082 - acc: 0.9142 - val_loss: 0.2286 - val_acc: 0.9070\n",
      "Epoch 20/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2071 - acc: 0.9148 - val_loss: 0.2298 - val_acc: 0.9076\n",
      "Epoch 21/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2062 - acc: 0.9152 - val_loss: 0.2284 - val_acc: 0.9106\n",
      "Epoch 22/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2050 - acc: 0.9160 - val_loss: 0.2300 - val_acc: 0.9076\n",
      "Epoch 23/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2015 - acc: 0.9177 - val_loss: 0.2325 - val_acc: 0.9050\n",
      "Epoch 24/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2004 - acc: 0.9162 - val_loss: 0.2358 - val_acc: 0.9004\n",
      "Epoch 25/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1987 - acc: 0.9188 - val_loss: 0.2283 - val_acc: 0.9054\n",
      "Epoch 26/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1975 - acc: 0.9177 - val_loss: 0.2265 - val_acc: 0.9097\n",
      "Epoch 27/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1971 - acc: 0.9189 - val_loss: 0.2352 - val_acc: 0.9015\n",
      "Epoch 28/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1954 - acc: 0.9183 - val_loss: 0.2338 - val_acc: 0.9042\n",
      "Epoch 29/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1939 - acc: 0.9197 - val_loss: 0.2330 - val_acc: 0.9053\n",
      "Epoch 30/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1929 - acc: 0.9216 - val_loss: 0.2365 - val_acc: 0.9008\n",
      "Epoch 31/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1925 - acc: 0.9211 - val_loss: 0.2335 - val_acc: 0.9043\n",
      "Epoch 32/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1936 - acc: 0.9203 - val_loss: 0.2470 - val_acc: 0.8914\n",
      "Epoch 33/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1905 - acc: 0.9210 - val_loss: 0.2374 - val_acc: 0.9034\n",
      "Epoch 34/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1894 - acc: 0.9211 - val_loss: 0.2398 - val_acc: 0.8993\n",
      "Epoch 35/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1888 - acc: 0.9216 - val_loss: 0.2412 - val_acc: 0.8985\n",
      "Epoch 36/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1878 - acc: 0.9217 - val_loss: 0.2363 - val_acc: 0.8994\n",
      "Epoch 37/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1877 - acc: 0.9225 - val_loss: 0.2416 - val_acc: 0.8933\n",
      "Epoch 38/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1889 - acc: 0.9216 - val_loss: 0.2348 - val_acc: 0.9036\n",
      "Epoch 39/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1861 - acc: 0.9226 - val_loss: 0.2397 - val_acc: 0.8981\n",
      "Epoch 40/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1838 - acc: 0.9249 - val_loss: 0.2561 - val_acc: 0.8841\n",
      "Epoch 41/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1831 - acc: 0.9248 - val_loss: 0.2395 - val_acc: 0.8967\n",
      "Epoch 42/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1831 - acc: 0.9243 - val_loss: 0.2428 - val_acc: 0.8925\n",
      "Epoch 43/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1820 - acc: 0.9246 - val_loss: 0.2410 - val_acc: 0.8944\n",
      "Epoch 44/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1816 - acc: 0.9236 - val_loss: 0.2550 - val_acc: 0.8822\n",
      "Epoch 45/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1799 - acc: 0.9255 - val_loss: 0.2438 - val_acc: 0.8932\n",
      "Epoch 46/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1808 - acc: 0.9242 - val_loss: 0.2470 - val_acc: 0.8875\n",
      "Epoch 47/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1797 - acc: 0.9251 - val_loss: 0.2446 - val_acc: 0.8882\n",
      "Epoch 48/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1807 - acc: 0.9251 - val_loss: 0.2428 - val_acc: 0.8927\n",
      "Epoch 49/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1783 - acc: 0.9264 - val_loss: 0.2465 - val_acc: 0.8906\n",
      "Epoch 50/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1758 - acc: 0.9269 - val_loss: 0.2501 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_8.hdf5\n",
      "Epoch 51/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1780 - acc: 0.9260 - val_loss: 0.2454 - val_acc: 0.8883\n",
      "Epoch 52/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1760 - acc: 0.9266 - val_loss: 0.2525 - val_acc: 0.8848\n",
      "Epoch 53/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1762 - acc: 0.9265 - val_loss: 0.2458 - val_acc: 0.8874\n",
      "Epoch 54/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1734 - acc: 0.9276 - val_loss: 0.2452 - val_acc: 0.8925\n",
      "Epoch 55/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1747 - acc: 0.9276 - val_loss: 0.2463 - val_acc: 0.8901\n",
      "Epoch 56/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1735 - acc: 0.9289 - val_loss: 0.2553 - val_acc: 0.8841\n",
      "Epoch 57/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1726 - acc: 0.9280 - val_loss: 0.2507 - val_acc: 0.8909\n",
      "Epoch 58/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1717 - acc: 0.9287 - val_loss: 0.2448 - val_acc: 0.8929\n",
      "Epoch 59/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1724 - acc: 0.9286 - val_loss: 0.2521 - val_acc: 0.8882\n",
      "Epoch 60/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1718 - acc: 0.9289 - val_loss: 0.2479 - val_acc: 0.8906\n",
      "Epoch 61/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1715 - acc: 0.9289 - val_loss: 0.2417 - val_acc: 0.8959\n",
      "Epoch 62/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1696 - acc: 0.9283 - val_loss: 0.2594 - val_acc: 0.8807\n",
      "Epoch 63/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1704 - acc: 0.9294 - val_loss: 0.2628 - val_acc: 0.8771\n",
      "Epoch 64/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1696 - acc: 0.9287 - val_loss: 0.2659 - val_acc: 0.8765\n",
      "Epoch 65/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1687 - acc: 0.9299 - val_loss: 0.2622 - val_acc: 0.8797\n",
      "Epoch 66/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1670 - acc: 0.9303 - val_loss: 0.2550 - val_acc: 0.8847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1673 - acc: 0.9306 - val_loss: 0.2595 - val_acc: 0.8769\n",
      "Epoch 68/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1692 - acc: 0.9299 - val_loss: 0.2501 - val_acc: 0.8871\n",
      "Epoch 69/2000\n",
      "66414/66414 [==============================] - ETA: 0s - loss: 0.1671 - acc: 0.929 - 2s 31us/step - loss: 0.1671 - acc: 0.9294 - val_loss: 0.2643 - val_acc: 0.8765\n",
      "Epoch 70/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1678 - acc: 0.9306 - val_loss: 0.2443 - val_acc: 0.8940\n",
      "Epoch 71/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1647 - acc: 0.9311 - val_loss: 0.2491 - val_acc: 0.8887\n",
      "Epoch 72/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1673 - acc: 0.9295 - val_loss: 0.2448 - val_acc: 0.8928\n",
      "Epoch 73/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1663 - acc: 0.9303 - val_loss: 0.2577 - val_acc: 0.8807\n",
      "Epoch 74/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1644 - acc: 0.9315 - val_loss: 0.2648 - val_acc: 0.8744\n",
      "Epoch 75/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1649 - acc: 0.9315 - val_loss: 0.2715 - val_acc: 0.8668\n",
      "Epoch 76/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1618 - acc: 0.9329 - val_loss: 0.2534 - val_acc: 0.8839\n",
      "AUC: 0.851434\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/2000\n",
      "66414/66414 [==============================] - 4s 58us/step - loss: 0.3114 - acc: 0.9080 - val_loss: 0.2927 - val_acc: 0.9088\n",
      "Epoch 2/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2740 - acc: 0.9094 - val_loss: 0.2555 - val_acc: 0.9088\n",
      "Epoch 3/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2579 - acc: 0.9094 - val_loss: 0.2513 - val_acc: 0.9088\n",
      "Epoch 4/2000\n",
      "66414/66414 [==============================] - ETA: 0s - loss: 0.2532 - acc: 0.909 - 2s 31us/step - loss: 0.2533 - acc: 0.9094 - val_loss: 0.2448 - val_acc: 0.9088\n",
      "Epoch 5/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2456 - acc: 0.9091 - val_loss: 0.2361 - val_acc: 0.9088\n",
      "Epoch 6/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2409 - acc: 0.9094 - val_loss: 0.2334 - val_acc: 0.9089\n",
      "Epoch 7/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2367 - acc: 0.9098 - val_loss: 0.2285 - val_acc: 0.9089\n",
      "Epoch 8/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2326 - acc: 0.9096 - val_loss: 0.2305 - val_acc: 0.9085\n",
      "Epoch 9/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2307 - acc: 0.9099 - val_loss: 0.2280 - val_acc: 0.9095\n",
      "Epoch 10/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2281 - acc: 0.9102 - val_loss: 0.2280 - val_acc: 0.9095\n",
      "Epoch 11/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2263 - acc: 0.9106 - val_loss: 0.2275 - val_acc: 0.9069\n",
      "Epoch 12/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2231 - acc: 0.9105 - val_loss: 0.2284 - val_acc: 0.9088\n",
      "Epoch 13/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2203 - acc: 0.9113 - val_loss: 0.2469 - val_acc: 0.9011\n",
      "Epoch 14/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2176 - acc: 0.9126 - val_loss: 0.2368 - val_acc: 0.9059\n",
      "Epoch 15/2000\n",
      "66414/66414 [==============================] - 2s 33us/step - loss: 0.2156 - acc: 0.9132 - val_loss: 0.2301 - val_acc: 0.9085\n",
      "Epoch 16/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2144 - acc: 0.9129 - val_loss: 0.2341 - val_acc: 0.9057\n",
      "Epoch 17/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2110 - acc: 0.9148 - val_loss: 0.2280 - val_acc: 0.9095\n",
      "Epoch 18/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2107 - acc: 0.9148 - val_loss: 0.2335 - val_acc: 0.9069\n",
      "Epoch 19/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2096 - acc: 0.9152 - val_loss: 0.2376 - val_acc: 0.9034\n",
      "Epoch 20/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2076 - acc: 0.9157 - val_loss: 0.2361 - val_acc: 0.9026\n",
      "Epoch 21/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2065 - acc: 0.9157 - val_loss: 0.2307 - val_acc: 0.9069\n",
      "Epoch 22/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2042 - acc: 0.9172 - val_loss: 0.2418 - val_acc: 0.8993\n",
      "Epoch 23/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2040 - acc: 0.9171 - val_loss: 0.2373 - val_acc: 0.9004\n",
      "Epoch 24/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.2018 - acc: 0.9179 - val_loss: 0.2393 - val_acc: 0.8981\n",
      "Epoch 25/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1976 - acc: 0.9184 - val_loss: 0.2351 - val_acc: 0.9034\n",
      "Epoch 26/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1980 - acc: 0.9190 - val_loss: 0.2407 - val_acc: 0.8988\n",
      "Epoch 27/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1990 - acc: 0.9182 - val_loss: 0.2351 - val_acc: 0.9042\n",
      "Epoch 28/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1955 - acc: 0.9206 - val_loss: 0.2338 - val_acc: 0.9027\n",
      "Epoch 29/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1954 - acc: 0.9202 - val_loss: 0.2415 - val_acc: 0.8943\n",
      "Epoch 30/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1938 - acc: 0.9208 - val_loss: 0.2422 - val_acc: 0.8961\n",
      "Epoch 31/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1903 - acc: 0.9226 - val_loss: 0.2417 - val_acc: 0.8984\n",
      "Epoch 32/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1933 - acc: 0.9210 - val_loss: 0.2526 - val_acc: 0.8879\n",
      "Epoch 33/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1915 - acc: 0.9206 - val_loss: 0.2425 - val_acc: 0.8967\n",
      "Epoch 34/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1903 - acc: 0.9221 - val_loss: 0.2422 - val_acc: 0.8959\n",
      "Epoch 35/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1886 - acc: 0.9228 - val_loss: 0.2386 - val_acc: 0.9007\n",
      "Epoch 36/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1879 - acc: 0.9224 - val_loss: 0.2467 - val_acc: 0.8947\n",
      "Epoch 37/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1860 - acc: 0.9236 - val_loss: 0.2440 - val_acc: 0.8938\n",
      "Epoch 38/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1843 - acc: 0.9237 - val_loss: 0.2419 - val_acc: 0.8944\n",
      "Epoch 39/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1869 - acc: 0.9230 - val_loss: 0.2430 - val_acc: 0.8943\n",
      "Epoch 40/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1843 - acc: 0.9242 - val_loss: 0.2551 - val_acc: 0.8898\n",
      "Epoch 41/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1842 - acc: 0.9246 - val_loss: 0.2498 - val_acc: 0.8894\n",
      "Epoch 42/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1830 - acc: 0.9246 - val_loss: 0.2607 - val_acc: 0.8832\n",
      "Epoch 43/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1816 - acc: 0.9260 - val_loss: 0.2475 - val_acc: 0.8923\n",
      "Epoch 44/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1805 - acc: 0.9253 - val_loss: 0.2538 - val_acc: 0.8856\n",
      "Epoch 45/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1807 - acc: 0.9257 - val_loss: 0.2719 - val_acc: 0.8723\n",
      "Epoch 46/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1804 - acc: 0.9260 - val_loss: 0.2642 - val_acc: 0.8793\n",
      "Epoch 47/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1787 - acc: 0.9275 - val_loss: 0.2564 - val_acc: 0.8841\n",
      "Epoch 48/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1797 - acc: 0.9260 - val_loss: 0.2571 - val_acc: 0.8829\n",
      "Epoch 49/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1780 - acc: 0.9260 - val_loss: 0.2512 - val_acc: 0.8916\n",
      "Epoch 50/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1755 - acc: 0.9274 - val_loss: 0.2644 - val_acc: 0.8803\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_9.hdf5\n",
      "Epoch 51/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1768 - acc: 0.9282 - val_loss: 0.2431 - val_acc: 0.8970\n",
      "Epoch 52/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1743 - acc: 0.9271 - val_loss: 0.2549 - val_acc: 0.8855\n",
      "Epoch 53/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1750 - acc: 0.9284 - val_loss: 0.2613 - val_acc: 0.8830\n",
      "Epoch 54/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1739 - acc: 0.9281 - val_loss: 0.2599 - val_acc: 0.8810\n",
      "Epoch 55/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1759 - acc: 0.9288 - val_loss: 0.2628 - val_acc: 0.8791\n",
      "Epoch 56/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1728 - acc: 0.9297 - val_loss: 0.2532 - val_acc: 0.8845\n",
      "Epoch 57/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1727 - acc: 0.9285 - val_loss: 0.2601 - val_acc: 0.8806\n",
      "Epoch 58/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1742 - acc: 0.9281 - val_loss: 0.2676 - val_acc: 0.8740\n",
      "Epoch 59/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1717 - acc: 0.9294 - val_loss: 0.2631 - val_acc: 0.8820\n",
      "Epoch 60/2000\n",
      "66414/66414 [==============================] - 2s 31us/step - loss: 0.1721 - acc: 0.9287 - val_loss: 0.2541 - val_acc: 0.8859\n",
      "Epoch 61/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1708 - acc: 0.9295 - val_loss: 0.2560 - val_acc: 0.8843\n",
      "AUC: 0.855499\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/2000\n",
      "66414/66414 [==============================] - 4s 60us/step - loss: 0.3141 - acc: 0.9070 - val_loss: 0.2858 - val_acc: 0.9162\n",
      "Epoch 2/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2797 - acc: 0.9086 - val_loss: 0.2575 - val_acc: 0.9162\n",
      "Epoch 3/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2585 - acc: 0.9086 - val_loss: 0.2418 - val_acc: 0.9162\n",
      "Epoch 4/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2480 - acc: 0.9086 - val_loss: 0.2354 - val_acc: 0.9162\n",
      "Epoch 5/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2419 - acc: 0.9084 - val_loss: 0.2307 - val_acc: 0.9164\n",
      "Epoch 6/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2367 - acc: 0.9088 - val_loss: 0.2308 - val_acc: 0.9146\n",
      "Epoch 7/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2332 - acc: 0.9086 - val_loss: 0.2300 - val_acc: 0.9153\n",
      "Epoch 8/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2300 - acc: 0.9095 - val_loss: 0.2273 - val_acc: 0.9149\n",
      "Epoch 9/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2266 - acc: 0.9097 - val_loss: 0.2264 - val_acc: 0.9148\n",
      "Epoch 10/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2243 - acc: 0.9110 - val_loss: 0.2289 - val_acc: 0.9139\n",
      "Epoch 11/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2210 - acc: 0.9111 - val_loss: 0.2266 - val_acc: 0.9164\n",
      "Epoch 12/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2188 - acc: 0.9119 - val_loss: 0.2253 - val_acc: 0.9160\n",
      "Epoch 13/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2170 - acc: 0.9123 - val_loss: 0.2256 - val_acc: 0.9175\n",
      "Epoch 14/2000\n",
      "66414/66414 [==============================] - ETA: 0s - loss: 0.2137 - acc: 0.913 - 2s 33us/step - loss: 0.2136 - acc: 0.9131 - val_loss: 0.2251 - val_acc: 0.9161\n",
      "Epoch 15/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2125 - acc: 0.9142 - val_loss: 0.2268 - val_acc: 0.9138\n",
      "Epoch 16/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2088 - acc: 0.9150 - val_loss: 0.2363 - val_acc: 0.9099\n",
      "Epoch 17/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2083 - acc: 0.9145 - val_loss: 0.2304 - val_acc: 0.9093\n",
      "Epoch 18/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2073 - acc: 0.9152 - val_loss: 0.2279 - val_acc: 0.9127\n",
      "Epoch 19/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2053 - acc: 0.9162 - val_loss: 0.2308 - val_acc: 0.9093\n",
      "Epoch 20/2000\n",
      "66414/66414 [==============================] - 2s 33us/step - loss: 0.2035 - acc: 0.9174 - val_loss: 0.2310 - val_acc: 0.9074\n",
      "Epoch 21/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2025 - acc: 0.9172 - val_loss: 0.2270 - val_acc: 0.9110\n",
      "Epoch 22/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2024 - acc: 0.9174 - val_loss: 0.2290 - val_acc: 0.9106\n",
      "Epoch 23/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.2009 - acc: 0.9181 - val_loss: 0.2336 - val_acc: 0.9076\n",
      "Epoch 24/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1984 - acc: 0.9185 - val_loss: 0.2280 - val_acc: 0.9127\n",
      "Epoch 25/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1969 - acc: 0.9198 - val_loss: 0.2275 - val_acc: 0.9134\n",
      "Epoch 26/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1944 - acc: 0.9206 - val_loss: 0.2355 - val_acc: 0.9047\n",
      "Epoch 27/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1955 - acc: 0.9190 - val_loss: 0.2296 - val_acc: 0.9116\n",
      "Epoch 28/2000\n",
      "66414/66414 [==============================] - 2s 33us/step - loss: 0.1941 - acc: 0.9204 - val_loss: 0.2321 - val_acc: 0.9036\n",
      "Epoch 29/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1927 - acc: 0.9212 - val_loss: 0.2430 - val_acc: 0.8958\n",
      "Epoch 30/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1923 - acc: 0.9211 - val_loss: 0.2285 - val_acc: 0.9116\n",
      "Epoch 31/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1897 - acc: 0.9221 - val_loss: 0.2309 - val_acc: 0.9083\n",
      "Epoch 32/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1889 - acc: 0.9224 - val_loss: 0.2325 - val_acc: 0.9069\n",
      "Epoch 33/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1877 - acc: 0.9226 - val_loss: 0.2387 - val_acc: 0.8990\n",
      "Epoch 34/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1851 - acc: 0.9236 - val_loss: 0.2297 - val_acc: 0.9114\n",
      "Epoch 35/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1859 - acc: 0.9230 - val_loss: 0.2329 - val_acc: 0.9049\n",
      "Epoch 36/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1856 - acc: 0.9235 - val_loss: 0.2378 - val_acc: 0.9008\n",
      "Epoch 37/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1841 - acc: 0.9243 - val_loss: 0.2379 - val_acc: 0.8992\n",
      "Epoch 38/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1829 - acc: 0.9252 - val_loss: 0.2364 - val_acc: 0.9017\n",
      "Epoch 39/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1830 - acc: 0.9249 - val_loss: 0.2502 - val_acc: 0.8902\n",
      "Epoch 40/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1796 - acc: 0.9267 - val_loss: 0.2432 - val_acc: 0.8948\n",
      "Epoch 41/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1812 - acc: 0.9250 - val_loss: 0.2401 - val_acc: 0.8963\n",
      "Epoch 42/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1824 - acc: 0.9246 - val_loss: 0.2435 - val_acc: 0.8938\n",
      "Epoch 43/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1808 - acc: 0.9257 - val_loss: 0.2351 - val_acc: 0.9041\n",
      "Epoch 44/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1802 - acc: 0.9256 - val_loss: 0.2377 - val_acc: 0.9043\n",
      "Epoch 45/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1782 - acc: 0.9259 - val_loss: 0.2385 - val_acc: 0.9020\n",
      "Epoch 46/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1781 - acc: 0.9273 - val_loss: 0.2491 - val_acc: 0.8927\n",
      "Epoch 47/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1768 - acc: 0.9281 - val_loss: 0.2469 - val_acc: 0.8940\n",
      "Epoch 48/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1792 - acc: 0.9268 - val_loss: 0.2510 - val_acc: 0.8912\n",
      "Epoch 49/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1756 - acc: 0.9285 - val_loss: 0.2435 - val_acc: 0.8947\n",
      "Epoch 50/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1775 - acc: 0.9273 - val_loss: 0.2513 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_Embedding_10.hdf5\n",
      "Epoch 51/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1755 - acc: 0.9276 - val_loss: 0.2536 - val_acc: 0.8883\n",
      "Epoch 52/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1754 - acc: 0.9273 - val_loss: 0.2459 - val_acc: 0.8970\n",
      "Epoch 53/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1746 - acc: 0.9274 - val_loss: 0.2453 - val_acc: 0.8948\n",
      "Epoch 54/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1744 - acc: 0.9281 - val_loss: 0.2483 - val_acc: 0.8902\n",
      "Epoch 55/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1734 - acc: 0.9282 - val_loss: 0.2456 - val_acc: 0.8955\n",
      "Epoch 56/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1723 - acc: 0.9292 - val_loss: 0.2497 - val_acc: 0.8904\n",
      "Epoch 57/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1717 - acc: 0.9290 - val_loss: 0.2572 - val_acc: 0.8864\n",
      "Epoch 58/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1711 - acc: 0.9298 - val_loss: 0.2448 - val_acc: 0.8970\n",
      "Epoch 59/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1718 - acc: 0.9289 - val_loss: 0.2496 - val_acc: 0.8940\n",
      "Epoch 60/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1700 - acc: 0.9306 - val_loss: 0.2468 - val_acc: 0.8971\n",
      "Epoch 61/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1697 - acc: 0.9321 - val_loss: 0.2567 - val_acc: 0.8887\n",
      "Epoch 62/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1662 - acc: 0.9319 - val_loss: 0.2538 - val_acc: 0.8879\n",
      "Epoch 63/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1689 - acc: 0.9297 - val_loss: 0.2558 - val_acc: 0.8868\n",
      "Epoch 64/2000\n",
      "66414/66414 [==============================] - 2s 32us/step - loss: 0.1679 - acc: 0.9303 - val_loss: 0.2518 - val_acc: 0.8890\n",
      "AUC: 0.838664\n",
      "[0.8506930812870355, 0.8348745285797352, 0.846400560535623, 0.8468916244763691, 0.8558294355313357, 0.8352272596641743, 0.8515938626339442, 0.8514344448206197, 0.8554987682627918, 0.8386644514105983]\n",
      "CV AUC: 0.846711\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 重新训练CNN word Embedding\n",
    "\n",
    "name = 'Embedding'\n",
    "gap = ''\n",
    "auc_mean=[]\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "x_train,y_train = pep(path_train,29-2)\n",
    "x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model6(input_length=29,dropout=0.5)\n",
    "    \n",
    "    filepath='C:/Users/Crow/Desktop/new_result/CNN6/model/29_kfold_CNN_'+ name + gap+'_'+ str(j) +'.hdf5'\n",
    "   \n",
    "    #filepath=\"C:/Users/Crow/Desktop/result/re_CNN/model/weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False,mode='auto', period=50)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    callbacks_list = [early_stopping,checkpoint]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 2000, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    auc_mean.append(auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN6/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN6/29_kfold_CNN_'+ name + gap+'_test_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(y_test3)):\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    if j == 10:\n",
    "        print(auc_mean)\n",
    "        print(print(\"CV AUC: %f\" % mean(auc_mean)))\n",
    "#         model.save('C:/Users/Crow/Desktop/result/re_CNN/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "#         test_pred_proba = model.predict(x_test)\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "#         print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "#         fw = open('C:/Users/Crow/Desktop/result/re_CNN/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "#         for t in range(0,len(test_pred_proba)):\n",
    "#             fw.write(str(test_pred_proba[t][0]))\n",
    "#             fw.write('\\t')\n",
    "#             fw.write(str(y_test[t]))\n",
    "#             fw.write('\\n') \n",
    "#         fw.close()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5种特征 CNN\n",
    "# 重新训练CNN word Embedding\n",
    "\n",
    "name = 'BINARY'\n",
    "gap = ''\n",
    "auc_mean=[]\n",
    "# path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "# path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "# x_train,y_train = pep(path_train,29-2)\n",
    "# x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_29_'+ name + gap +'.txt'\n",
    "path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_29_'+ name + gap +'.txt'\n",
    "\n",
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "\n",
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2) \n",
    "x_test = np.expand_dims(x_test, axis=2) \n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model3(shape=shape,dropout=0.6)\n",
    "    \n",
    "    #filepath='C:/Users/Crow/Desktop/result/re_CNN3/model/'+ str(j) +'checkpoint-{val_loss:.2f}-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5'\n",
    "    filepath='C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_'+ name + gap+'_'+ str(j) +'.hdf5'\n",
    "    #filepath=\"C:/Users/Crow/Desktop/result/re_CNN/model/weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False,mode='auto', period=50)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    callbacks_list = [early_stopping,checkpoint]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 1000, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    auc_mean.append(auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_test_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(y_test3)):\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    if j == 10:\n",
    "        print(auc_mean)\n",
    "        print(print(\"CV AUC: %f\" % mean(auc_mean)))\n",
    "#         model.save('C:/Users/Crow/Desktop/result/re_CNN/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "#         test_pred_proba = model.predict(x_test)\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "#         print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "#         fw = open('C:/Users/Crow/Desktop/result/re_CNN/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "#         for t in range(0,len(test_pred_proba)):\n",
    "#             fw.write(str(test_pred_proba[t][0]))\n",
    "#             fw.write('\\t')\n",
    "#             fw.write(str(y_test[t]))\n",
    "#             fw.write('\\n') \n",
    "#         fw.close()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5种特征 CNN\n",
    "# 重新训练CNN word Embedding\n",
    "\n",
    "name = 'EAAC'\n",
    "gap = '_gap5'\n",
    "auc_mean=[]\n",
    "# path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "# path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "# x_train,y_train = pep(path_train,29-2)\n",
    "# x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_29_'+ name + gap +'.txt'\n",
    "path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_29_'+ name + gap +'.txt'\n",
    "\n",
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "\n",
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2) \n",
    "x_test = np.expand_dims(x_test, axis=2) \n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model3(shape=shape,dropout=0.6)\n",
    "    \n",
    "    #filepath='C:/Users/Crow/Desktop/result/re_CNN3/model/'+ str(j) +'checkpoint-{val_loss:.2f}-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5'\n",
    "    filepath='C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_'+ name + gap+'_'+ str(j) +'.hdf5'\n",
    "    #filepath=\"C:/Users/Crow/Desktop/result/re_CNN/model/weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False,mode='auto', period=50)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    callbacks_list = [early_stopping,checkpoint]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 1000, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    auc_mean.append(auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_test_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(y_test3)):\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    if j == 10:\n",
    "        print(auc_mean)\n",
    "        print(print(\"CV AUC: %f\" % mean(auc_mean)))\n",
    "#         model.save('C:/Users/Crow/Desktop/result/re_CNN/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "#         test_pred_proba = model.predict(x_test)\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "#         print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "#         fw = open('C:/Users/Crow/Desktop/result/re_CNN/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "#         for t in range(0,len(test_pred_proba)):\n",
    "#             fw.write(str(test_pred_proba[t][0]))\n",
    "#             fw.write('\\t')\n",
    "#             fw.write(str(y_test[t]))\n",
    "#             fw.write('\\n') \n",
    "#         fw.close()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "x_test,y_test = pep(path_test,29-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('C:/Users/Crow/Desktop/result/re_CNN/model/5checkpoint-0.23-50e-val_acc_0.90.hdf5')\n",
    "\n",
    "test_pred_proba = model.predict(x_test)\n",
    "test_pred = model.predict_classes(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 AUC AUC01\n",
    "name = 'AAC'\n",
    "gap = ''\n",
    "model = ''\n",
    "q = [21,23,25,27,29,31,35,37]\n",
    "#q = [29]\n",
    "for t in q :\n",
    "    path_test='C:/Users/Crow/Desktop/human_data_12.12/result/'+ name +'/Test'+ model +'_' +str(t)+'_'+ name + gap +'_ROC01_result.txt'\n",
    "    print('test: %i'%t)\n",
    "    #read_result(path_test)\n",
    "    fr = open(path_test,'r')\n",
    "    for i in range(2):\n",
    "        print(fr.readline().split(':')[1])\n",
    "    fr.close() \n",
    "\n",
    "    \n",
    "for t in q :\n",
    "    path_train='C:/Users/Crow/Desktop/human_data_12.12/result/'+ name +'/Train'+ model +'_'+str(t)+'_'+ name +  gap +'_ROC01_result.txt'\n",
    "    print('train:  %i'%t)\n",
    "    #read_result(path_train)\n",
    "    print('')\n",
    "    fr = open(path_train,'r')\n",
    "    for i in range(2):\n",
    "        print(fr.readline().split(':')[1])\n",
    "    fr.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'Embedding'\n",
    "\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "x_train,y_train = pep(path_train,27)\n",
    "x_test,y_test = pep(path_test,27)\n",
    "\n",
    "model = create_cnn_model5(input_length=29,dropout=0.6)\n",
    "model.summary()\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "#callbacks_list = [early_stopping]\n",
    "#model.fit(x_train, y_train, epochs = 20, batch_size = 256,callbacks=callbacks_list, verbose=1)\n",
    "hit = model.fit(x_train, y_train, epochs = 10000,batch_size = 256,validation_split = 0.2, verbose=1, shuffle=True)\n",
    "\n",
    "\n",
    "print(model.evaluate(x_test, y_test, batch_size=256))\n",
    "pre = model.predict(x_test)\n",
    "pre2 = model.predict_classes(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pre,pos_label=1)\n",
    "print(sklearn.metrics.auc(fpr, tpr))\n",
    "_,_,SN,SP,_,_,_,_,_ = performance(y_test,pre2)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,pre2))\n",
    "print(\"Sn: %f\" %SN) \n",
    "print(\"Sp: %f\" %SP)\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test,pre2))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割并序列编码\n",
    "AA = '_GAVLIFWYDNEKQMSTCPHR'\n",
    "def pep(path, seq_len):\n",
    "    seqs = open(path).readlines()\n",
    "    cut = (len(seqs[0].split()[0]) - 1 - seq_len) // 2\n",
    "    X = [[AA.index(res.upper()) if res.upper() in AA else 0\n",
    "          for res in (seq.split()[0][cut:-cut] if cut != 0 else seq.split()[0])]\n",
    "        for seq in seqs if seq.strip() != '']\n",
    "    y = [int(seq.split()[-1]) for seq in seqs if seq.strip() != '']\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA.index('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(str1):\n",
    "    a = []\n",
    "    dic = {'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y':20,'-':21}\n",
    "    for i in range(len(str1)):\n",
    "        a.append(dic.get(str1[i]))\n",
    "    return a\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans('ACKL--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainData(str1):\n",
    "    sequence_num = []\n",
    "    label_num = []\n",
    "    for line in open(str1):\n",
    "        proteinId, sequence, label = line.split(\",\")\n",
    "        proteinId = proteinId.strip(' \\t\\r\\n');\n",
    "        sequence = sequence.strip(' \\t\\r\\n');\n",
    "        sequence_num.append(trans(sequence))\n",
    "        label = label.strip(' \\t\\r\\n');\n",
    "        label_num.append(int(label))\n",
    "\n",
    "    return sequence_num,label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集大小对独立测试集性能影响 十折交叉验证 AUC AUC01\n",
    "# DL\n",
    "# RF EGAAC _gap4\n",
    "# 临时在此\n",
    "\n",
    "\n",
    "name = 'EGAAC'\n",
    "gap = '_gap4'\n",
    "# 读取数据\n",
    "\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_29_'+ name + gap +'.txt'\n",
    "path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_29_'+ name + gap +'.txt'\n",
    "\n",
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "\n",
    "x_train_ori = train[0]\n",
    "y_train_ori = train[1]\n",
    "size = 0.0625\n",
    "size2 = 1-size\n",
    "x_train, _, y_train, _ =train_test_split (x_train_ori,y_train_ori,test_size = size2,random_state=5, shuffle=True, stratify=y_train_ori)\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1\n",
    "auc_mean = []\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=1600,oob_score=True,n_jobs=3,\n",
    "                                 random_state=50,max_depth=11,min_samples_split=30,max_features=19,min_samples_leaf=20)\n",
    "#     clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#             max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
    "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#             min_samples_leaf=1, min_samples_split=2,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,\n",
    "#             oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "    clf.fit(x_train3, y_train3)\n",
    "    test_pred = clf.predict(x_test3)\n",
    "    test_pred_proba = clf.predict_proba(x_test3)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "\n",
    "    auc_mean.append(auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    joblib.dump(clf, 'C:/Users/Crow/Desktop/new_result/datasize/model/'+ str(j) +'_'+str(size)+'_clf_kfold_'+ name + gap +'.pkl')\n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/datasize/29_kfold_'+str(size)+'_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "   \n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "\n",
    "    \n",
    "    if j == 10:        \n",
    "        print(auc_mean)\n",
    "        print(print(\"CV AUC: %f\" % mean(auc_mean)))\n",
    "        \n",
    "    j+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集大小对独立测试集性能影响 十折交叉验证 AUC AUC01\n",
    "# DL\n",
    "# Embedding\n",
    "# 临时在此\n",
    "name = 'Embedding'\n",
    "gap = ''\n",
    "auc_mean=[]\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "x_train_ori,y_train_ori = pep(path_train,29-2)\n",
    "size = 0.0625\n",
    "size2 = 1-size\n",
    "x_train, _, y_train, _ =train_test_split (x_train_ori,y_train_ori,test_size = size2,random_state=5, shuffle=True, stratify=y_train_ori)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "\n",
    "x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model6(input_length=29,dropout=0.5)\n",
    "    \n",
    "    #filepath='C:/Users/Crow/Desktop/new_result/datasize/CNN/model/29_kfold_CNN_'+'_'+str(size)+'_'+ name + gap+'_'+ str(j) +'.hdf5'\n",
    "   \n",
    "    #filepath=\"C:/Users/Crow/Desktop/result/re_CNN/model/weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False,mode='auto', period=50)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    callbacks_list = [early_stopping,checkpoint]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 2000, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    auc_mean.append(auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/datasize/CNN/29_kfold_CNN_'+'_'+str(size)+'_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/datasize/CNN/29_kfold_CNN_'+'_'+str(size)+'_'+ name + gap+'_test_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(y_test3)):\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    if j == 10:\n",
    "        print(auc_mean)\n",
    "        print(print(\"CV AUC: %f\" % mean(auc_mean)))\n",
    "#         model.save('C:/Users/Crow/Desktop/result/re_CNN/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "#         test_pred_proba = model.predict(x_test)\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "#         print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "#         fw = open('C:/Users/Crow/Desktop/result/re_CNN/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "#         for t in range(0,len(test_pred_proba)):\n",
    "#             fw.write(str(test_pred_proba[t][0]))\n",
    "#             fw.write('\\t')\n",
    "#             fw.write(str(y_test[t]))\n",
    "#             fw.write('\\n') \n",
    "#         fw.close()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ori,y_train_ori = pep(path_train,29-2)\n",
    "size = 0.125\n",
    "size2 = 1-size\n",
    "x_train, _, y_train, _ =train_test_split (x_train_ori,y_train_ori,test_size = size2,random_state=5, shuffle=True, stratify=y_train_ori)\n",
    "\n",
    "\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF EGAAC hap4\n",
    "AUC_1_16 = [0.7337822979659153, 0.7124106652006597, 0.688857006217121, 0.7232804232804232, 0.7363413819962168, 0.7151188140396774, 0.7185363247863248, 0.6952214452214452, 0.6517357222844344, 0.6957026713124274]\n",
    "AUC01_1_16 = [0.014431,0.0141561,0.0133907,0.0202381,0.00806721,0.0218552,0.0142094,0.00728438,0.012007,0.0149245]\n",
    "\n",
    "AUC_1_8 = [0.7756614074029635, 0.7099938418228204, 0.7381056069678825, 0.7371937942297224, 0.7329593483439637, 0.7822943949711891, 0.7330908551068883, 0.7419570267131242, 0.7281856333115326, 0.801059878745174]\n",
    "AUC01_1_8 = [0.0225718,0.0123897,0.0193658,0.0187534,0.0170291,0.0222106,0.0201306,0.0204704,0.0183807,0.0258511]\n",
    "\n",
    "AUC_1_4 = [0.7935586221554249, 0.7521843738128403, 0.7691161930687349, 0.755496899348068, 0.7406853296857027, 0.7740323881438553, 0.7755122655122655, 0.7821445289847478, 0.7853042479908152, 0.7712202429295937]\n",
    "AUC01_1_4 = [0.0234587,0.0213649,0.0221818,0.0202894,0.0176967,0.0222927,0.0210786,0.0197692,0.0186064,0.0229718]\n",
    "\n",
    "AUC_1_2 = [0.7668826151560179, 0.8126446838063074, 0.7966258773354422, 0.7765518076373588, 0.7807456852211682, 0.7566508126399111, 0.8010958963919467, 0.785541560304506, 0.7886318932583471, 0.7762957504298698]\n",
    "AUC01_1_2 = [0.0185594,0.0237894,0.0221814,0.0190358,0.0225772,0.0198215,0.0225137,0.0226929,0.0248152,0.0228411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Embedding\n",
    "AUC_1_16 = [0.7035459043430456, 0.7205882352941176, 0.7131516021042564, 0.7584656084656084, 0.6444308445532435, 0.618759537824286, 0.7250534188034188, 0.6939831002331003, 0.6928580316038323, 0.7059233449477352]\n",
    "AUC01_1_16 = [0.0186229,0.0164239,0.0241989,0.0185185,0.00723267,0.0134075,0.0213675,0.0178467,0.0204678,0.0170151]\n",
    "\n",
    "AUC_1_8 = [0.8114463975043494, 0.7565467288349316, 0.6903375068045727, 0.7692161132280892, 0.7759778682855606, 0.7646804609743321, 0.7917013064133016, 0.7632984901277585, 0.8010546108567691, 0.7904464115324202]\n",
    "AUC01_1_8 = [0.0256614,0.0175655,0.0100572,0.023571,0.0208714,0.0219094,0.0272565,0.0216899,0.0273872,0.0240601]\n",
    "\n",
    "AUC_1_4 = [0.819647492826889, 0.7984915157654806, 0.8049506285391441, 0.8291302273811416, 0.7943505766779618, 0.813339947042744, 0.8088023088023087, 0.8210400553354712, 0.8091883776384351, 0.8198927933293627]\n",
    "AUC01_1_4 = [0.0208817,0.0225837,0.0188851,0.026179,0.0246565,0.0303862,0.0248449,0.0248101,0.0280456,0.0219467]\n",
    "\n",
    "AUC_1_2 = [0.8178964453080353, 0.8528667819598018, 0.8418421925971953, 0.8442124125239122, 0.8417263687278547, 0.8308962498756591, 0.842994285839032, 0.8578390004490363, 0.8314427023418971, 0.839707265011562]\n",
    "AUC01_1_2 =[0.0246401,0.0312474,0.0297923,0.0278558,0.0274966,0.0246649,0.0278959,0.0330277,0.0263588,0.0278793]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(AUC_1_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_datasize_AUC = [0.7480501787615261,0.7699255091632049,0.7841666582180875,0.791109499999999]\n",
    "RF_datasize_AUC01 = [0.019715319999999998,0.02097102,0.021882759999999998,0.02216211]\n",
    "\n",
    "CNN_datasize_AUC = [0.7714705894562085,0.811883392333894,0.8401423704633986,0.863449099999999]\n",
    "CNN_datasize_AUC01 = [0.022002960000000002,0.024321950000000002,0.028085879999999997,0.03232128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "name='EGAAC'\n",
    "gap='_gap4'\n",
    "size = 0.0625\n",
    "a = []\n",
    "b = []\n",
    "for i in range(1,11):\n",
    "    path = 'C:/Users/Crow/Desktop/new_result/datasize/result/29_kfold_'+str(size)+'_'+name+gap+'_result_ROC01_result_'+str(i)+'.txt'\n",
    "    fr = open(path,'r')\n",
    "    for line in fr.readlines()[0:1]:\n",
    "        print(line.split(':')[1].split('\\n')[0])\n",
    "        a.append(float(line.split(':')[1].split('\\n')[0]))\n",
    "        print(',')\n",
    "    fr.close()\n",
    "    fr = open(path,'r')\n",
    "    for line in fr.readlines()[1:2]:\n",
    "        print(line.split(':')[1].split('\\n')[0])\n",
    "        b.append(float(line.split(':')[1].split('\\n')[0]))\n",
    "        print(',')\n",
    "    fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集大小对独立测试集性能影响 十折交叉验证 AUC AUC01\n",
    "# CNN Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(x):\n",
    "    block = Conv1D(filter_nr, kernel_size=filter_size, padding=same, activation=linear, \n",
    "                kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(x)\n",
    "    block = BatchNormalization()(block)\n",
    "    block = PReLU()(block)\n",
    "    block = Conv1D(filter_nr, kernel_size=filter_size, padding=same, activation=linear, \n",
    "                kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block)\n",
    "    block = BatchNormalization()(block)\n",
    "    block = PReLU()(block)\n",
    "    return block\n",
    "\n",
    "def DPCNN():\n",
    "    filter_nr = 64 #滤波器通道个数\n",
    "    filter_size = 3 #卷积核\n",
    "    max_pool_size = 3 #池化层的pooling_size\n",
    "    max_pool_strides = 2 #池化层的步长\n",
    "    dense_nr = 256 #全连接层\n",
    "    spatial_dropout = 0.2\n",
    "    dense_dropout = 0.5\n",
    "    train_embed = False\n",
    "    conv_kern_reg = regularizers.l2(0.00001)\n",
    "    conv_bias_reg = regularizers.l2(0.00001)\n",
    "\n",
    "    comment = Input(shape=(maxlen,))\n",
    "    emb_comment = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=train_embed)(comment)\n",
    "    emb_comment = SpatialDropout1D(spatial_dropout)(emb_comment)\n",
    "\n",
    "    #region embedding层\n",
    "    resize_emb = Conv1D(filter_nr, kernel_size=1, padding=same, activation=linear, \n",
    "                kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(emb_comment)\n",
    "    resize_emb = PReLU()(resize_emb)\n",
    "    #第一层\n",
    "    block1 = CNN(emb_comment)\n",
    "    block1_output = add([block1, resize_emb])\n",
    "    block1_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block1_output)\n",
    "    #第二层\n",
    "    block2 = CNN(block1_output)\n",
    "    block2_output = add([block2, block1_output])\n",
    "    block2_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block2_output)\n",
    "    #第三层\n",
    "    block3 = CNN(block2_output)\n",
    "    block3_output = add([block3, block2_output])\n",
    "    block3_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block3_output)  \n",
    "    #第四层\n",
    "    block4 = CNN(block3_output) \n",
    "    block4_output = add([block4, block3_output])\n",
    "    block4_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block4_output)\n",
    "    #第五层\n",
    "    block5 = CNN(block4_output) \n",
    "    block5_output = add([block5, block4_output])\n",
    "    block5_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block5_output)\n",
    "    #第六层\n",
    "    block6 = CNN(block5_output) \n",
    "    block6_output = add([block6, block5_output])\n",
    "    block6_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block6_output)\n",
    "    #第七层\n",
    "    block7 = CNN(block6_output) \n",
    "    block7_output = add([block7, block6_output])\n",
    "    output = GlobalMaxPooling1D()(block7_output)\n",
    "    #全连接层\n",
    "    output = Dense(dense_nr, activation=linear)(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = PReLU()(output)\n",
    "    output = Dropout(dense_dropout)(output)\n",
    "    output = Dense(6, activation=sigmoid)(output)\n",
    "\n",
    "    model = Model(comment, output)\n",
    "    model.summary()\n",
    "    model.compile(loss=binary_crossentropy, \n",
    "                optimizer=optimizers.Adam(),\n",
    "                metrics=[accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
