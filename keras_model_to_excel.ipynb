{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys,re,time,math\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "\n",
    "#指定第一块GPU可用 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "config = tf.ConfigProto() \n",
    "#不全部占满显存, 按需分配\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_svm(file):\n",
    "    encodings = []\n",
    "    labels = []\n",
    "    with open(file) as f:\n",
    "        records = f.readlines()\n",
    "\n",
    "    for line in records:\n",
    "        line = re.sub('\\d+:', '', line)\n",
    "        array = line.strip().split() if line.strip() != '' else None\n",
    "        encodings.append(array[1:])\n",
    "        labels.append(int(array[0]))\n",
    "\n",
    "    return np.array(encodings).astype(float), np.array(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ROC_curve(y_test,y_predict,savepath=None):\n",
    "    '''\n",
    "    画ROC曲线\n",
    "    '''\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test, y_predict)\n",
    "    roc_auc=auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('ROC')\n",
    "    plt.plot(false_positive_rate, true_positive_rate,'b',label='AUC = %0.3f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.savefig(savepath)\n",
    "    plt.close(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割并序列编码\n",
    "AA = 'GAVLIFWYDNEKQMSTCPHR'\n",
    "def pep(path, seq_len):\n",
    "    seqs = open(path).readlines()\n",
    "    cut = (len(seqs[0].split()[0]) - 1 - seq_len) // 2\n",
    "    X = [[AA.index(res.upper()) if res.upper() in AA else 0\n",
    "          for res in (seq.split()[0][cut:-cut] if cut != 0 else seq.split()[0])]\n",
    "        for seq in seqs if seq.strip() != '']\n",
    "    y = [int(seq.split()[-1]) for seq in seqs if seq.strip() != '']\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model2(input_length=29,dropout=0.4, shape=(130, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(22, 32, input_length = input_length))\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model3(shape, dropout=0.4):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_score(path,pre,label):\n",
    "    fw = open(path, 'w')\n",
    "\n",
    "    for i in range(0,len(pre)):\n",
    "        fw.write(str(pre[i]).replace('[','').replace(']',''))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(label[i]))\n",
    "        fw.write('\\n')\n",
    "\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "31\n",
      "35\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# keras 编码循环输出result\n",
    "name = 'EAAC'\n",
    "gap = '_gap5'\n",
    "#q = [21,23,25]\n",
    "q = [21,23,25,27,29,31,35,37]\n",
    "#q=[29]\n",
    "for t in q :\n",
    "    path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_'+str(t)+'_'+ name + gap +'.txt'\n",
    "    train = read_svm(path_train)\n",
    "    test = read_svm(path_test)\n",
    "\n",
    "\n",
    "    x_train = train[0]\n",
    "    y_train = train[1]\n",
    "\n",
    "    x_test = test[0]\n",
    "    y_test = test[1]\n",
    "    x_train = np.expand_dims(x_train, axis=2) \n",
    "    x_test = np.expand_dims(x_test, axis=2) \n",
    "    shape = x_train.shape[1:]\n",
    "    \n",
    "    # k-fold\n",
    "    kf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "    for train_index, test_index in kf.split(x_train, y_train):\n",
    "        x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "        y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        model = create_cnn_model3(shape=shape)\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "        callbacks_list = [early_stopping]\n",
    "        model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,\n",
    "                  shuffle=True,callbacks=callbacks_list, verbose=0)\n",
    "    \n",
    "    print(t)\n",
    "    pre = model.predict(x_train)\n",
    "    write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_keras_'+ str(t) + '_'+ name + gap+'_result.txt',pre,y_train)\n",
    "\n",
    "\n",
    "\n",
    "    pre1 = model.predict(x_test)\n",
    "    write_score('C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_keras_'+ str(t) + '_'+ name+ gap+'_result.txt',pre1,y_test)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
