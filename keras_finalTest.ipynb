{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys,re,time,math\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "\n",
    "#指定第一块GPU可用 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "config = tf.ConfigProto() \n",
    "#不全部占满显存, 按需分配\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_svm(file):\n",
    "    encodings = []\n",
    "    labels = []\n",
    "    with open(file) as f:\n",
    "        records = f.readlines()\n",
    "\n",
    "    for line in records:\n",
    "        line = re.sub('\\d+:', '', line)\n",
    "        array = line.strip().split() if line.strip() != '' else None\n",
    "        encodings.append(array[1:])\n",
    "        labels.append(int(array[0]))\n",
    "\n",
    "    return np.array(encodings).astype(float), np.array(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ROC_curve(y_test,y_predict,savepath=None):\n",
    "    '''\n",
    "    画ROC曲线\n",
    "    '''\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test, y_predict)\n",
    "    roc_auc=auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('ROC')\n",
    "    plt.plot(false_positive_rate, true_positive_rate,'b',label='AUC = %0.3f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.savefig(savepath)\n",
    "    plt.close(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割并序列编码\n",
    "AA = 'GAVLIFWYDNEKQMSTCPHR_'\n",
    "def pep(path, seq_len):\n",
    "    seqs = open(path).readlines()\n",
    "    cut = (len(seqs[0].split()[0]) - 1 - seq_len) // 2\n",
    "    X = [[AA.index(res.upper()) if res.upper() in AA else 0\n",
    "          for res in (seq.split()[0][cut:-cut] if cut != 0 else seq.split()[0])]\n",
    "        for seq in seqs if seq.strip() != '']\n",
    "    y = [int(seq.split()[-1]) for seq in seqs if seq.strip() != '']\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model3(shape, dropout=0.4):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model4(input_length=29,dropout=0.4):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(21, 5, input_length = input_length))\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model5(input_length=29,dropout=0.4):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(21, 5, input_length = input_length))\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 29, 5)             105       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 29, 128)           5248      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 14, 128)           131200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 7, 128)            131200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 385       \n",
      "=================================================================\n",
      "Total params: 268,138\n",
      "Trainable params: 268,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_cnn_model4(input_length=29)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_EGAAC = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/EGAAC/Train_29_EGAAC_gap4.txt'\n",
    "path_test_EGAAC =  'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/EGAAC/Test_29_EGAAC_gap4.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = pep(path_train,29)\n",
    "x_test,y_test = pep(path_test,29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73793, 31)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 101s 2ms/step - loss: 0.3100 - acc: 0.9078 - val_loss: 0.2967 - val_acc: 0.9093\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 12s 177us/step - loss: 0.2861 - acc: 0.9094 - val_loss: 0.2749 - val_acc: 0.9093\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 12s 180us/step - loss: 0.2624 - acc: 0.9094 - val_loss: 0.2472 - val_acc: 0.9093\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 12s 174us/step - loss: 0.2504 - acc: 0.9093 - val_loss: 0.2381 - val_acc: 0.9095\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 12s 178us/step - loss: 0.2427 - acc: 0.9088 - val_loss: 0.2286 - val_acc: 0.9099\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 12s 175us/step - loss: 0.2363 - acc: 0.9091 - val_loss: 0.2241 - val_acc: 0.9093\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 12s 174us/step - loss: 0.2330 - acc: 0.9090 - val_loss: 0.2221 - val_acc: 0.9099\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 12s 174us/step - loss: 0.2293 - acc: 0.9100 - val_loss: 0.2168 - val_acc: 0.9102\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 12s 173us/step - loss: 0.2264 - acc: 0.9104 - val_loss: 0.2191 - val_acc: 0.9110\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 12s 176us/step - loss: 0.2239 - acc: 0.9115 - val_loss: 0.2217 - val_acc: 0.9115\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 12s 176us/step - loss: 0.2195 - acc: 0.9116 - val_loss: 0.2162 - val_acc: 0.9117\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 12s 177us/step - loss: 0.2181 - acc: 0.9122 - val_loss: 0.2188 - val_acc: 0.9111\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 12s 176us/step - loss: 0.2167 - acc: 0.9127 - val_loss: 0.2221 - val_acc: 0.9103\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 12s 175us/step - loss: 0.2123 - acc: 0.9136 - val_loss: 0.2185 - val_acc: 0.9108\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 12s 176us/step - loss: 0.2098 - acc: 0.9141 - val_loss: 0.2179 - val_acc: 0.9096\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 12s 176us/step - loss: 0.2062 - acc: 0.9163 - val_loss: 0.2199 - val_acc: 0.9102\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 131s 2ms/step - loss: 0.3105 - acc: 0.9086 - val_loss: 0.2989 - val_acc: 0.9093\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 13s 200us/step - loss: 0.2756 - acc: 0.9094 - val_loss: 0.2596 - val_acc: 0.9093\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 13s 199us/step - loss: 0.2555 - acc: 0.9093 - val_loss: 0.2530 - val_acc: 0.9093\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 13s 200us/step - loss: 0.2466 - acc: 0.9091 - val_loss: 0.2497 - val_acc: 0.9092\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 13s 201us/step - loss: 0.2399 - acc: 0.9092 - val_loss: 0.2456 - val_acc: 0.9092\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 13s 202us/step - loss: 0.2355 - acc: 0.9095 - val_loss: 0.2460 - val_acc: 0.9091\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 13s 201us/step - loss: 0.2307 - acc: 0.9097 - val_loss: 0.2430 - val_acc: 0.9095\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 13s 194us/step - loss: 0.2279 - acc: 0.9098 - val_loss: 0.2408 - val_acc: 0.9088\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 13s 197us/step - loss: 0.2234 - acc: 0.9104 - val_loss: 0.2401 - val_acc: 0.9100\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2205 - acc: 0.9113 - val_loss: 0.2408 - val_acc: 0.9102\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 15s 219us/step - loss: 0.2183 - acc: 0.9115 - val_loss: 0.2442 - val_acc: 0.9061\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 15s 222us/step - loss: 0.2153 - acc: 0.9122 - val_loss: 0.2394 - val_acc: 0.9065\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2122 - acc: 0.9128 - val_loss: 0.2487 - val_acc: 0.8988\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 15s 221us/step - loss: 0.2112 - acc: 0.9132 - val_loss: 0.2427 - val_acc: 0.9077\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 15s 220us/step - loss: 0.2071 - acc: 0.9146 - val_loss: 0.2426 - val_acc: 0.9035\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 15s 220us/step - loss: 0.2059 - acc: 0.9151 - val_loss: 0.2451 - val_acc: 0.9077\n",
      "Epoch 17/20\n",
      "66413/66413 [==============================] - 15s 219us/step - loss: 0.2026 - acc: 0.9156 - val_loss: 0.2427 - val_acc: 0.9054\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 132s 2ms/step - loss: 0.3072 - acc: 0.9089 - val_loss: 0.2882 - val_acc: 0.9093\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 14s 216us/step - loss: 0.2700 - acc: 0.9094 - val_loss: 0.2599 - val_acc: 0.9093\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 14s 216us/step - loss: 0.2546 - acc: 0.9094 - val_loss: 0.2468 - val_acc: 0.9093\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 15s 219us/step - loss: 0.2442 - acc: 0.9095 - val_loss: 0.2413 - val_acc: 0.9092\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2388 - acc: 0.9091 - val_loss: 0.2420 - val_acc: 0.9092\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2346 - acc: 0.9089 - val_loss: 0.2387 - val_acc: 0.9098\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 14s 216us/step - loss: 0.2309 - acc: 0.9089 - val_loss: 0.2360 - val_acc: 0.9095\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2258 - acc: 0.9104 - val_loss: 0.2372 - val_acc: 0.9091\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2240 - acc: 0.9106 - val_loss: 0.2429 - val_acc: 0.9088\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 14s 213us/step - loss: 0.2225 - acc: 0.9104 - val_loss: 0.2388 - val_acc: 0.9080\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 14s 211us/step - loss: 0.2192 - acc: 0.9117 - val_loss: 0.2331 - val_acc: 0.9075\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2168 - acc: 0.9120 - val_loss: 0.2341 - val_acc: 0.9075\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 15s 218us/step - loss: 0.2137 - acc: 0.9130 - val_loss: 0.2376 - val_acc: 0.9066\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 15s 219us/step - loss: 0.2112 - acc: 0.9134 - val_loss: 0.2376 - val_acc: 0.9081\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 14s 214us/step - loss: 0.2079 - acc: 0.9147 - val_loss: 0.2389 - val_acc: 0.9068\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 14s 214us/step - loss: 0.2074 - acc: 0.9146 - val_loss: 0.2388 - val_acc: 0.9061\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 132s 2ms/step - loss: 0.3085 - acc: 0.9070 - val_loss: 0.2850 - val_acc: 0.9093\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 15s 222us/step - loss: 0.2722 - acc: 0.9094 - val_loss: 0.2564 - val_acc: 0.9093\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2551 - acc: 0.9094 - val_loss: 0.2561 - val_acc: 0.9093\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2448 - acc: 0.9092 - val_loss: 0.2382 - val_acc: 0.9099\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 15s 220us/step - loss: 0.2378 - acc: 0.9090 - val_loss: 0.2320 - val_acc: 0.9096\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2327 - acc: 0.9095 - val_loss: 0.2309 - val_acc: 0.9099\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2293 - acc: 0.9091 - val_loss: 0.2284 - val_acc: 0.9102\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 15s 220us/step - loss: 0.2246 - acc: 0.9103 - val_loss: 0.2281 - val_acc: 0.9111\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2220 - acc: 0.9102 - val_loss: 0.2273 - val_acc: 0.9099\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 14s 214us/step - loss: 0.2204 - acc: 0.9110 - val_loss: 0.2321 - val_acc: 0.9104\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 14s 216us/step - loss: 0.2178 - acc: 0.9115 - val_loss: 0.2260 - val_acc: 0.9087\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 15s 220us/step - loss: 0.2153 - acc: 0.9127 - val_loss: 0.2270 - val_acc: 0.9087\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2126 - acc: 0.9128 - val_loss: 0.2283 - val_acc: 0.9088\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2103 - acc: 0.9132 - val_loss: 0.2304 - val_acc: 0.9108\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 14s 216us/step - loss: 0.2079 - acc: 0.9136 - val_loss: 0.2271 - val_acc: 0.9081\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2057 - acc: 0.9156 - val_loss: 0.2309 - val_acc: 0.9054\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 133s 2ms/step - loss: 0.3145 - acc: 0.9062 - val_loss: 0.2972 - val_acc: 0.9093\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2820 - acc: 0.9094 - val_loss: 0.2697 - val_acc: 0.9093\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 14s 218us/step - loss: 0.2589 - acc: 0.9094 - val_loss: 0.2653 - val_acc: 0.9093\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 14s 216us/step - loss: 0.2475 - acc: 0.9093 - val_loss: 0.2512 - val_acc: 0.9093\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 14s 214us/step - loss: 0.2393 - acc: 0.9092 - val_loss: 0.2543 - val_acc: 0.9092\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 15s 219us/step - loss: 0.2326 - acc: 0.9090 - val_loss: 0.2514 - val_acc: 0.9091s - loss: 0.2322 - acc: 0.90 - ETA: 1s -\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 15s 219us/step - loss: 0.2306 - acc: 0.9100 - val_loss: 0.2525 - val_acc: 0.9084\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 15s 218us/step - loss: 0.2278 - acc: 0.9100 - val_loss: 0.2604 - val_acc: 0.9030\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 15s 220us/step - loss: 0.2253 - acc: 0.9106 - val_loss: 0.2500 - val_acc: 0.90791s - los\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 15s 220us/step - loss: 0.2215 - acc: 0.9108 - val_loss: 0.2486 - val_acc: 0.9072\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 15s 219us/step - loss: 0.2194 - acc: 0.9118 - val_loss: 0.2552 - val_acc: 0.9037\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 14s 216us/step - loss: 0.2160 - acc: 0.9121 - val_loss: 0.2544 - val_acc: 0.8995\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 14s 217us/step - loss: 0.2130 - acc: 0.9128 - val_loss: 0.2517 - val_acc: 0.90534 - acc: 0.9 - ETA: 6s - loss: 0.2128 - acc: 0. - ETA: 6s - loss: - ETA: 5s - loss: 0.21 - ETA: 4s - loss: 0.2 - ETA: 2s \n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 14s 210us/step - loss: 0.2113 - acc: 0.9144 - val_loss: 0.2528 - val_acc: 0.9015\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 13s 194us/step - loss: 0.2085 - acc: 0.9150 - val_loss: 0.2590 - val_acc: 0.8984\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 114s 2ms/step - loss: 0.3117 - acc: 0.9063 - val_loss: 0.2990 - val_acc: 0.9093\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 12s 182us/step - loss: 0.2820 - acc: 0.9094 - val_loss: 0.2716 - val_acc: 0.9093\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 12s 182us/step - loss: 0.2609 - acc: 0.9094 - val_loss: 0.2503 - val_acc: 0.9093\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 12s 182us/step - loss: 0.2517 - acc: 0.9093 - val_loss: 0.2442 - val_acc: 0.9093\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 12s 180us/step - loss: 0.2462 - acc: 0.9091 - val_loss: 0.2402 - val_acc: 0.9096\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 12s 180us/step - loss: 0.2399 - acc: 0.9091 - val_loss: 0.2495 - val_acc: 0.9085\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 12s 180us/step - loss: 0.2346 - acc: 0.9086 - val_loss: 0.2402 - val_acc: 0.9093\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 12s 181us/step - loss: 0.2312 - acc: 0.9100 - val_loss: 0.2370 - val_acc: 0.9096\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 12s 177us/step - loss: 0.2293 - acc: 0.9096 - val_loss: 0.2354 - val_acc: 0.9088\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 12s 179us/step - loss: 0.2247 - acc: 0.9103 - val_loss: 0.2379 - val_acc: 0.9061\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 12s 179us/step - loss: 0.2227 - acc: 0.9109 - val_loss: 0.2336 - val_acc: 0.9075\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 12s 182us/step - loss: 0.2179 - acc: 0.9121 - val_loss: 0.2357 - val_acc: 0.9092\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 12s 180us/step - loss: 0.2174 - acc: 0.9111 - val_loss: 0.2360 - val_acc: 0.9085\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 12s 180us/step - loss: 0.2123 - acc: 0.9139 - val_loss: 0.2431 - val_acc: 0.9039\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 12s 180us/step - loss: 0.2107 - acc: 0.9134 - val_loss: 0.2392 - val_acc: 0.9087\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 12s 183us/step - loss: 0.2087 - acc: 0.9145 - val_loss: 0.2412 - val_acc: 0.9072\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 100s 2ms/step - loss: 0.3114 - acc: 0.9075 - val_loss: 0.2926 - val_acc: 0.9093\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 12s 177us/step - loss: 0.2823 - acc: 0.9094 - val_loss: 0.2687 - val_acc: 0.9093\n",
      "Epoch 3/20\n",
      "66414/66414 [==============================] - 12s 178us/step - loss: 0.2600 - acc: 0.9094 - val_loss: 0.2474 - val_acc: 0.9093\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 12s 178us/step - loss: 0.2474 - acc: 0.9094 - val_loss: 0.2393 - val_acc: 0.9091\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 12s 177us/step - loss: 0.2398 - acc: 0.9091 - val_loss: 0.2422 - val_acc: 0.9093\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 12s 178us/step - loss: 0.2350 - acc: 0.9097 - val_loss: 0.2403 - val_acc: 0.9081\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 12s 179us/step - loss: 0.2308 - acc: 0.9095 - val_loss: 0.2314 - val_acc: 0.9096\n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 12s 179us/step - loss: 0.2278 - acc: 0.9099 - val_loss: 0.2321 - val_acc: 0.9083\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 12s 176us/step - loss: 0.2241 - acc: 0.9108 - val_loss: 0.2289 - val_acc: 0.9083\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 12s 178us/step - loss: 0.2224 - acc: 0.9107 - val_loss: 0.2425 - val_acc: 0.9032\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 12s 178us/step - loss: 0.2191 - acc: 0.9114 - val_loss: 0.2327 - val_acc: 0.9066\n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 12s 174us/step - loss: 0.2163 - acc: 0.9125 - val_loss: 0.2328 - val_acc: 0.9053\n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 12s 181us/step - loss: 0.2131 - acc: 0.9133 - val_loss: 0.2349 - val_acc: 0.9055\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 13s 202us/step - loss: 0.2118 - acc: 0.9146 - val_loss: 0.2396 - val_acc: 0.9043\n",
      "Train on 66415 samples, validate on 7378 samples\n",
      "Epoch 1/20\n",
      "66415/66415 [==============================] - 103s 2ms/step - loss: 0.3106 - acc: 0.9066 - val_loss: 0.2869 - val_acc: 0.9095\n",
      "Epoch 2/20\n",
      "66415/66415 [==============================] - 12s 178us/step - loss: 0.2704 - acc: 0.9094 - val_loss: 0.2698 - val_acc: 0.9095\n",
      "Epoch 3/20\n",
      "66415/66415 [==============================] - 12s 179us/step - loss: 0.2568 - acc: 0.9093 - val_loss: 0.2551 - val_acc: 0.9095\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2486 - acc: 0.9091 - val_loss: 0.2453 - val_acc: 0.9095\n",
      "Epoch 5/20\n",
      "66415/66415 [==============================] - 12s 183us/step - loss: 0.2405 - acc: 0.9092 - val_loss: 0.2504 - val_acc: 0.9091\n",
      "Epoch 6/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2369 - acc: 0.9091 - val_loss: 0.2408 - val_acc: 0.9080\n",
      "Epoch 7/20\n",
      "66415/66415 [==============================] - 12s 178us/step - loss: 0.2329 - acc: 0.9097 - val_loss: 0.2345 - val_acc: 0.9088\n",
      "Epoch 8/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2289 - acc: 0.9094 - val_loss: 0.2333 - val_acc: 0.9084\n",
      "Epoch 9/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2256 - acc: 0.9105 - val_loss: 0.2323 - val_acc: 0.9092\n",
      "Epoch 10/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2237 - acc: 0.9106 - val_loss: 0.2310 - val_acc: 0.9082\n",
      "Epoch 11/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2200 - acc: 0.9110 - val_loss: 0.2378 - val_acc: 0.9057\n",
      "Epoch 12/20\n",
      "66415/66415 [==============================] - 12s 179us/step - loss: 0.2179 - acc: 0.9117 - val_loss: 0.2355 - val_acc: 0.9076\n",
      "Epoch 13/20\n",
      "66415/66415 [==============================] - 12s 177us/step - loss: 0.2155 - acc: 0.9125 - val_loss: 0.2358 - val_acc: 0.9057\n",
      "Epoch 14/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2131 - acc: 0.9135 - val_loss: 0.2358 - val_acc: 0.9076\n",
      "Epoch 15/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2091 - acc: 0.9138 - val_loss: 0.2401 - val_acc: 0.9021\n",
      "Train on 66415 samples, validate on 7378 samples\n",
      "Epoch 1/20\n",
      "66415/66415 [==============================] - 101s 2ms/step - loss: 0.3073 - acc: 0.9080 - val_loss: 0.2832 - val_acc: 0.9095\n",
      "Epoch 2/20\n",
      "66415/66415 [==============================] - 12s 176us/step - loss: 0.2709 - acc: 0.9094 - val_loss: 0.2585 - val_acc: 0.9095\n",
      "Epoch 3/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2561 - acc: 0.9094 - val_loss: 0.2361 - val_acc: 0.9096\n",
      "Epoch 4/20\n",
      "66415/66415 [==============================] - 12s 178us/step - loss: 0.2450 - acc: 0.9094 - val_loss: 0.2353 - val_acc: 0.9112\n",
      "Epoch 5/20\n",
      "66415/66415 [==============================] - 12s 177us/step - loss: 0.2396 - acc: 0.9094 - val_loss: 0.2287 - val_acc: 0.9101\n",
      "Epoch 6/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2366 - acc: 0.9092 - val_loss: 0.2246 - val_acc: 0.9110\n",
      "Epoch 7/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2324 - acc: 0.9093 - val_loss: 0.2257 - val_acc: 0.9105\n",
      "Epoch 8/20\n",
      "66415/66415 [==============================] - 12s 178us/step - loss: 0.2289 - acc: 0.9104 - val_loss: 0.2274 - val_acc: 0.9096\n",
      "Epoch 9/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2257 - acc: 0.9100 - val_loss: 0.2248 - val_acc: 0.9105\n",
      "Epoch 10/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2240 - acc: 0.9099 - val_loss: 0.2307 - val_acc: 0.9096\n",
      "Epoch 11/20\n",
      "66415/66415 [==============================] - 12s 177us/step - loss: 0.2217 - acc: 0.9109 - val_loss: 0.2258 - val_acc: 0.9076\n",
      "Train on 66415 samples, validate on 7378 samples\n",
      "Epoch 1/20\n",
      "66415/66415 [==============================] - 101s 2ms/step - loss: 0.3088 - acc: 0.9084 - val_loss: 0.2837 - val_acc: 0.9095\n",
      "Epoch 2/20\n",
      "66415/66415 [==============================] - 12s 179us/step - loss: 0.2693 - acc: 0.9094 - val_loss: 0.2514 - val_acc: 0.9095\n",
      "Epoch 3/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2546 - acc: 0.9094 - val_loss: 0.2433 - val_acc: 0.9099\n",
      "Epoch 4/20\n",
      "66415/66415 [==============================] - 12s 183us/step - loss: 0.2450 - acc: 0.9089 - val_loss: 0.2324 - val_acc: 0.9099\n",
      "Epoch 5/20\n",
      "66415/66415 [==============================] - 12s 182us/step - loss: 0.2396 - acc: 0.9088 - val_loss: 0.2305 - val_acc: 0.9104\n",
      "Epoch 6/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2362 - acc: 0.9089 - val_loss: 0.2262 - val_acc: 0.9103\n",
      "Epoch 7/20\n",
      "66415/66415 [==============================] - 12s 179us/step - loss: 0.2324 - acc: 0.9091 - val_loss: 0.2273 - val_acc: 0.9099\n",
      "Epoch 8/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2284 - acc: 0.9102 - val_loss: 0.2281 - val_acc: 0.9097\n",
      "Epoch 9/20\n",
      "66415/66415 [==============================] - 12s 180us/step - loss: 0.2256 - acc: 0.9102 - val_loss: 0.2255 - val_acc: 0.9095\n",
      "Epoch 10/20\n",
      "66415/66415 [==============================] - 12s 179us/step - loss: 0.2231 - acc: 0.9098 - val_loss: 0.2270 - val_acc: 0.9096\n",
      "Epoch 11/20\n",
      "66415/66415 [==============================] - 12s 182us/step - loss: 0.2205 - acc: 0.9110 - val_loss: 0.2227 - val_acc: 0.9100\n",
      "Epoch 12/20\n",
      "66415/66415 [==============================] - 12s 184us/step - loss: 0.2169 - acc: 0.9116 - val_loss: 0.2232 - val_acc: 0.9124\n",
      "Epoch 13/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2156 - acc: 0.9134 - val_loss: 0.2232 - val_acc: 0.9105\n",
      "Epoch 14/20\n",
      "66415/66415 [==============================] - 12s 181us/step - loss: 0.2125 - acc: 0.9125 - val_loss: 0.2234 - val_acc: 0.9095\n",
      "Epoch 15/20\n",
      "66415/66415 [==============================] - 12s 187us/step - loss: 0.2102 - acc: 0.9131 - val_loss: 0.2230 - val_acc: 0.9092\n",
      "Epoch 16/20\n",
      "66415/66415 [==============================] - 13s 203us/step - loss: 0.2081 - acc: 0.9153 - val_loss: 0.2251 - val_acc: 0.9116\n",
      "17980/17980 [==============================] - 3s 143us/step\n",
      "[0.22098376286175678, 0.9159621802002225]\n",
      "ACC:  0.915962 \n",
      "Sn: 0.086986\n",
      "Sp: 0.990483\n",
      "MCC: 0.170335 \n",
      "AUC: 0.850662\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "\n",
    "   \n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    model = create_cnn_model4(input_length=31)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks_list = [early_stopping]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "pre = model.predict(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,pre,pos_label=1)\n",
    "pre1 = model.predict_classes(x_test)\n",
    "precision,recall,SN,SP,GM,TP,TN,FP,FN = performance(y_test,pre1)\n",
    "print(model.evaluate(x_test, y_test, batch_size=256))\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,pre1))\n",
    "print(\"Sn: %f\" %SN)\n",
    "print(\"Sp: %f\" %SP)\n",
    "print(\"MCC: %f \" %matthews_corrcoef(y_test,pre1))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17980/17980 [==============================] - 0s 9us/step\n",
      "[0.21914273882336557, 0.9150166852588251]\n",
      "ACC:  0.915017 \n",
      "Sn: 0.163857\n",
      "Sp: 0.982542\n",
      "MCC: 0.237892 \n",
      "AUC: 0.856130\n"
     ]
    }
   ],
   "source": [
    "# embedding: 5 \n",
    "model.predict(x_test)\n",
    "model.predict_function()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model3(shape, dropout=0.4):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same',  input_shape=shape))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(128, 8, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 27s 409us/step - loss: 0.3129 - acc: 0.9091 - val_loss: 0.3079 - val_acc: 0.9077\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 25s 379us/step - loss: 0.3021 - acc: 0.9096 - val_loss: 0.3043 - val_acc: 0.9077\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2952 - acc: 0.9096 - val_loss: 0.3036 - val_acc: 0.9077\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 25s 378us/step - loss: 0.2920 - acc: 0.9096 - val_loss: 0.2948 - val_acc: 0.90772s - los\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 25s 373us/step - loss: 0.2913 - acc: 0.9096 - val_loss: 0.2945 - val_acc: 0.9077\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2887 - acc: 0.9095 - val_loss: 0.2916 - val_acc: 0.9077\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2873 - acc: 0.9095 - val_loss: 0.2885 - val_acc: 0.9077TA: 4s - loss: 0.2850  - ETA: - ETA: 0s - loss: 0.2873 - acc: 0.909\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 25s 372us/step - loss: 0.2838 - acc: 0.9096 - val_loss: 0.2900 - val_acc: 0.9076\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2807 - acc: 0.9095 - val_loss: 0.2863 - val_acc: 0.9079\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 25s 374us/step - loss: 0.2778 - acc: 0.9095 - val_loss: 0.2944 - val_acc: 0.9080\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 25s 374us/step - loss: 0.2758 - acc: 0.9096 - val_loss: 0.2844 - val_acc: 0.9080\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2739 - acc: 0.9097 - val_loss: 0.2800 - val_acc: 0.9079\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 25s 374us/step - loss: 0.2696 - acc: 0.9098 - val_loss: 0.2836 - val_acc: 0.9081\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2681 - acc: 0.9096 - val_loss: 0.2816 - val_acc: 0.9081oss: 0.2682 - acc: 0.90\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2661 - acc: 0.9100 - val_loss: 0.2806 - val_acc: 0.9081\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2628 - acc: 0.9097 - val_loss: 0.2796 - val_acc: 0.9070\n",
      "Epoch 17/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2604 - acc: 0.9105 - val_loss: 0.2819 - val_acc: 0.9075\n",
      "Epoch 18/20\n",
      "66413/66413 [==============================] - 25s 376us/step - loss: 0.2592 - acc: 0.9107 - val_loss: 0.2792 - val_acc: 0.9080\n",
      "Epoch 19/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2550 - acc: 0.9108 - val_loss: 0.2802 - val_acc: 0.9065\n",
      "Epoch 20/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2540 - acc: 0.9105 - val_loss: 0.2795 - val_acc: 0.9085\n",
      "AUC: 0.727375\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 25s 381us/step - loss: 0.3143 - acc: 0.9073 - val_loss: 0.2991 - val_acc: 0.9123\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.3037 - acc: 0.9090 - val_loss: 0.2951 - val_acc: 0.9123\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2974 - acc: 0.9091 - val_loss: 0.2905 - val_acc: 0.91237s -  - ETA: 4s - loss - ETA: 2s - loss: 0.2976 - acc:  - ETA: 2s - lo\n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2951 - acc: 0.9091 - val_loss: 0.2919 - val_acc: 0.9123\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2922 - acc: 0.9091 - val_loss: 0.2849 - val_acc: 0.9123\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2901 - acc: 0.9090 - val_loss: 0.2847 - val_acc: 0.9123- loss: 0.2892 -  - ETA: 2s \n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 25s 373us/step - loss: 0.2880 - acc: 0.9090 - val_loss: 0.2865 - val_acc: 0.9123- acc: 0. - ETA: 1s - loss: 0.28\n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2853 - acc: 0.9090 - val_loss: 0.2810 - val_acc: 0.9123\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2820 - acc: 0.9090 - val_loss: 0.2785 - val_acc: 0.9123\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2800 - acc: 0.9091 - val_loss: 0.2814 - val_acc: 0.9121\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2768 - acc: 0.9088 - val_loss: 0.2803 - val_acc: 0.9125\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2743 - acc: 0.9089 - val_loss: 0.2859 - val_acc: 0.9130 loss: 0.2744 -\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2721 - acc: 0.9093 - val_loss: 0.2844 - val_acc: 0.9127\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2697 - acc: 0.9094 - val_loss: 0.2773 - val_acc: 0.9129\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2674 - acc: 0.9095 - val_loss: 0.2771 - val_acc: 0.9126 ETA: 4s - loss: 0.2683  - ETA\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2652 - acc: 0.9092 - val_loss: 0.2806 - val_acc: 0.9110\n",
      "Epoch 17/20\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2628 - acc: 0.9095 - val_loss: 0.2765 - val_acc: 0.9123\n",
      "Epoch 18/20\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2604 - acc: 0.9098 - val_loss: 0.2856 - val_acc: 0.9084\n",
      "Epoch 19/20\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2568 - acc: 0.9097 - val_loss: 0.2793 - val_acc: 0.9117\n",
      "Epoch 20/20\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2546 - acc: 0.9096 - val_loss: 0.2789 - val_acc: 0.9119ETA: 3s - loss: 0.2542 - ac - ETA: 2s - loss: 0 - ETA: 0s - loss: 0.2542 - acc:\n",
      "AUC: 0.702889\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/20\n",
      "66413/66413 [==============================] - 25s 384us/step - loss: 0.3130 - acc: 0.9085 - val_loss: 0.3058 - val_acc: 0.9092\n",
      "Epoch 2/20\n",
      "66413/66413 [==============================] - 25s 379us/step - loss: 0.3009 - acc: 0.9094 - val_loss: 0.2936 - val_acc: 0.9092\n",
      "Epoch 3/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2950 - acc: 0.9094 - val_loss: 0.2906 - val_acc: 0.90920.909 - ETA: 0s - loss: 0.2949 - \n",
      "Epoch 4/20\n",
      "66413/66413 [==============================] - 25s 379us/step - loss: 0.2926 - acc: 0.9094 - val_loss: 0.2893 - val_acc: 0.9092\n",
      "Epoch 5/20\n",
      "66413/66413 [==============================] - 25s 380us/step - loss: 0.2897 - acc: 0.9094 - val_loss: 0.2886 - val_acc: 0.9092\n",
      "Epoch 6/20\n",
      "66413/66413 [==============================] - 25s 378us/step - loss: 0.2867 - acc: 0.9094 - val_loss: 0.2951 - val_acc: 0.9091\n",
      "Epoch 7/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2854 - acc: 0.9094 - val_loss: 0.2844 - val_acc: 0.90937s - - ETA: 0s - loss: 0.2862 - \n",
      "Epoch 8/20\n",
      "66413/66413 [==============================] - 25s 375us/step - loss: 0.2837 - acc: 0.9093 - val_loss: 0.2831 - val_acc: 0.9092\n",
      "Epoch 9/20\n",
      "66413/66413 [==============================] - 25s 373us/step - loss: 0.2788 - acc: 0.9095 - val_loss: 0.2799 - val_acc: 0.9088: 0.2788 - acc - ETA: 1s - loss: 0.2783 - ac - ETA: 0s - loss: 0.2789 - acc\n",
      "Epoch 10/20\n",
      "66413/66413 [==============================] - 25s 374us/step - loss: 0.2766 - acc: 0.9093 - val_loss: 0.2810 - val_acc: 0.9089TA: 1s - loss: 0.2 - ETA: 0s - loss: 0.2767 - acc: 0.9\n",
      "Epoch 11/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2744 - acc: 0.9096 - val_loss: 0.2803 - val_acc: 0.9089\n",
      "Epoch 12/20\n",
      "66413/66413 [==============================] - 25s 382us/step - loss: 0.2719 - acc: 0.9094 - val_loss: 0.2808 - val_acc: 0.9089\n",
      "Epoch 13/20\n",
      "66413/66413 [==============================] - 25s 379us/step - loss: 0.2695 - acc: 0.9096 - val_loss: 0.2784 - val_acc: 0.9095\n",
      "Epoch 14/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2669 - acc: 0.9093 - val_loss: 0.2809 - val_acc: 0.90920.2662 - acc: 0.908 - ETA:  - ETA: 5s - l\n",
      "Epoch 15/20\n",
      "66413/66413 [==============================] - 25s 378us/step - loss: 0.2644 - acc: 0.9099 - val_loss: 0.2774 - val_acc: 0.9093\n",
      "Epoch 16/20\n",
      "66413/66413 [==============================] - 25s 378us/step - loss: 0.2602 - acc: 0.9102 - val_loss: 0.2797 - val_acc: 0.9093 - loss: 0.2603 - acc:\n",
      "Epoch 17/20\n",
      "66413/66413 [==============================] - 25s 379us/step - loss: 0.2598 - acc: 0.9101 - val_loss: 0.2809 - val_acc: 0.9076\n",
      "Epoch 18/20\n",
      "66413/66413 [==============================] - 25s 379us/step - loss: 0.2563 - acc: 0.9098 - val_loss: 0.2820 - val_acc: 0.9089 loss: 0.2549 - ETA: 6s - loss: 0.25 - ETA:  - ETA: 2s - los\n",
      "Epoch 19/20\n",
      "66413/66413 [==============================] - 25s 377us/step - loss: 0.2536 - acc: 0.9109 - val_loss: 0.2846 - val_acc: 0.9095\n",
      "Epoch 20/20\n",
      "66413/66413 [==============================] - 25s 378us/step - loss: 0.2510 - acc: 0.9111 - val_loss: 0.2871 - val_acc: 0.9039\n",
      "AUC: 0.718538\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 26s 388us/step - loss: 0.3116 - acc: 0.9089 - val_loss: 0.3122 - val_acc: 0.905320 - acc: 0.90\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.3002 - acc: 0.9098 - val_loss: 0.3047 - val_acc: 0.9053\n",
      "Epoch 3/20\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2952 - acc: 0.9098 - val_loss: 0.3049 - val_acc: 0.9053\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2921 - acc: 0.9098 - val_loss: 0.2967 - val_acc: 0.9053\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2910 - acc: 0.9098 - val_loss: 0.2968 - val_acc: 0.9053\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2888 - acc: 0.9098 - val_loss: 0.2981 - val_acc: 0.9051\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2883 - acc: 0.9098 - val_loss: 0.2928 - val_acc: 0.9053 - loss - ETA: 1s - loss: 0.2889 - acc:  - ETA: 1s - loss: 0.2888 \n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 25s 381us/step - loss: 0.2851 - acc: 0.9098 - val_loss: 0.2915 - val_acc: 0.9053\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2833 - acc: 0.9098 - val_loss: 0.2903 - val_acc: 0.9051\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2811 - acc: 0.9097 - val_loss: 0.2903 - val_acc: 0.9053A: 4s - loss: 0.2811\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2784 - acc: 0.9100 - val_loss: 0.2893 - val_acc: 0.9051\n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2773 - acc: 0.9099 - val_loss: 0.2887 - val_acc: 0.9053\n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2733 - acc: 0.9101 - val_loss: 0.2871 - val_acc: 0.9045\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2714 - acc: 0.9102 - val_loss: 0.2869 - val_acc: 0.9049\n",
      "Epoch 15/20\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2702 - acc: 0.9098 - val_loss: 0.2860 - val_acc: 0.9049 loss: 0.2677 - - ETA: 11\n",
      "Epoch 16/20\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2675 - acc: 0.9098 - val_loss: 0.2890 - val_acc: 0.9050 5s - loss: 0.2654 - ETA: 3s - loss: 0.2653 - a - ETA: 2s -  - ETA: 0s - loss: 0.2667 - acc: \n",
      "Epoch 17/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2647 - acc: 0.9101 - val_loss: 0.2873 - val_acc: 0.9054\n",
      "Epoch 18/20\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2636 - acc: 0.9103 - val_loss: 0.2869 - val_acc: 0.9047 1s - loss: 0.\n",
      "Epoch 19/20\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2592 - acc: 0.9108 - val_loss: 0.2876 - val_acc: 0.9039A: 9s - loss: 0.2584 - - ETA: 8s - loss: 0.257 - ET\n",
      "Epoch 20/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2576 - acc: 0.9105 - val_loss: 0.2881 - val_acc: 0.9043s: 0.2572 - - ETA: 3s - loss: 0.2576 - acc: 0.9 - ETA: 3s - loss: 0.2581 - acc: 0.910 - ETA: 3s - loss: 0.2580 - ac - ETA: 2s - loss: 0.2578 - a - ETA: 1s - loss: 0.2\n",
      "AUC: 0.715293\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 26s 390us/step - loss: 0.3118 - acc: 0.9094 - val_loss: 0.3086 - val_acc: 0.9064- ETA: 18s - loss: 0.32 - ETA: 17s - loss: 0.3260 - a - ETA: 16s - loss: 0.3250 - ETA: 13s - loss:  - ETA: 10s - loss: 0.314 - ETA: 9s - loss  - ETA: 0s - loss: 0.3119 - acc: 0.9\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.3015 - acc: 0.9097 - val_loss: 0.3020 - val_acc: 0.9061loss: 0.2991 - acc: 0.911 - ETA: 8s - loss: 0.2993 -  - ET - ETA: 4s - loss: 0.3005 - a\n",
      "Epoch 3/20\n",
      "66414/66414 [==============================] - 25s 383us/step - loss: 0.2944 - acc: 0.9097 - val_loss: 0.3008 - val_acc: 0.9064\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 25s 381us/step - loss: 0.2915 - acc: 0.9097 - val_loss: 0.3116 - val_acc: 0.9064\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 25s 382us/step - loss: 0.2911 - acc: 0.9097 - val_loss: 0.2981 - val_acc: 0.9064\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 25s 383us/step - loss: 0.2884 - acc: 0.9096 - val_loss: 0.2967 - val_acc: 0.9064\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 25s 382us/step - loss: 0.2874 - acc: 0.9097 - val_loss: 0.2907 - val_acc: 0.9064 0s - loss: 0.2873 - acc:\n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 25s 382us/step - loss: 0.2840 - acc: 0.9097 - val_loss: 0.2882 - val_acc: 0.9064\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 25s 382us/step - loss: 0.2813 - acc: 0.9097 - val_loss: 0.2883 - val_acc: 0.9064\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 25s 381us/step - loss: 0.2791 - acc: 0.9099 - val_loss: 0.2889 - val_acc: 0.9066\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.2769 - acc: 0.9098 - val_loss: 0.2898 - val_acc: 0.9064\n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2737 - acc: 0.9098 - val_loss: 0.2861 - val_acc: 0.9059\n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2717 - acc: 0.9095 - val_loss: 0.2878 - val_acc: 0.9065TA: 5s - lo - ETA: 2s - loss: 0.2715 - ac - ETA: 2s - loss: 0. - ETA: 0s - loss: 0.2721 - acc: 0.9 - ETA: 0s - loss: 0.2718 - acc: 0.909\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2685 - acc: 0.9100 - val_loss: 0.2871 - val_acc: 0.9064\n",
      "Epoch 15/20\n",
      "66414/66414 [==============================] - 26s 384us/step - loss: 0.2663 - acc: 0.9101 - val_loss: 0.2860 - val_acc: 0.9058\n",
      "Epoch 16/20\n",
      "66414/66414 [==============================] - 25s 383us/step - loss: 0.2647 - acc: 0.9096 - val_loss: 0.2865 - val_acc: 0.9061\n",
      "Epoch 17/20\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2604 - acc: 0.9103 - val_loss: 0.2912 - val_acc: 0.9061\n",
      "Epoch 18/20\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2581 - acc: 0.9108 - val_loss: 0.2872 - val_acc: 0.9054\n",
      "Epoch 19/20\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2552 - acc: 0.9108 - val_loss: 0.2881 - val_acc: 0.9034\n",
      "Epoch 20/20\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2530 - acc: 0.9107 - val_loss: 0.2880 - val_acc: 0.9045s: 0.2512 -  - ETA: 5s - loss:  - \n",
      "AUC: 0.720199\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 26s 391us/step - loss: 0.3134 - acc: 0.9075 - val_loss: 0.2957 - val_acc: 0.9125\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.3030 - acc: 0.9090 - val_loss: 0.2910 - val_acc: 0.9125\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2965 - acc: 0.9090 - val_loss: 0.2889 - val_acc: 0.9125\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2938 - acc: 0.9090 - val_loss: 0.2912 - val_acc: 0.9125 1s - loss:\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2918 - acc: 0.9090 - val_loss: 0.2877 - val_acc: 0.9125s - loss: 0.2889 - acc: 0.910 - ETA: 6s - loss: 0.2892 - acc: 0. - ETA: 5s - - E\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2890 - acc: 0.9090 - val_loss: 0.2839 - val_acc: 0.9125 loss: 0. - ETA: 17s  - ETA: 12s - loss: 0.2916 - acc: 0.90 - ETA: 12s - loss: 0.2914 - acc - ETA: 11s  - ETA: 10s - loss: 0.2920 - acc: 0.90 - ETA: 10s - loss: - ETA: 8s - loss: 0.2908 - acc - ETA: 7s - loss: 0.2909 - acc: 0.908 - ETA: 7s  - ETA: 5s - loss - ETA: 3s - loss: 0.2894 - acc: 0. - ETA: 2s - loss: 0.2893 - acc: 0.908 - ETA: 2\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2885 - acc: 0.9090 - val_loss: 0.2825 - val_acc: 0.9125\n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2847 - acc: 0.9089 - val_loss: 0.2808 - val_acc: 0.9120845 - acc: 0.909\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2811 - acc: 0.9089 - val_loss: 0.2983 - val_acc: 0.9103\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2787 - acc: 0.9091 - val_loss: 0.2780 - val_acc: 0.9123\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.2761 - acc: 0.9089 - val_loss: 0.2790 - val_acc: 0.9126 - loss: 0.2768 - acc:  - ETA:  - ETA: 10s - loss: 0.27 - ETA: 2s - \n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2747 - acc: 0.9089 - val_loss: 0.2779 - val_acc: 0.9116s - ETA: 2s - \n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2718 - acc: 0.9089 - val_loss: 0.2778 - val_acc: 0.91220.90\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2688 - acc: 0.9091 - val_loss: 0.2793 - val_acc: 0.9122\n",
      "Epoch 15/20\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2664 - acc: 0.9094 - val_loss: 0.2741 - val_acc: 0.9122\n",
      "Epoch 16/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2649 - acc: 0.9092 - val_loss: 0.2776 - val_acc: 0.9122\n",
      "Epoch 17/20\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2629 - acc: 0.9097 - val_loss: 0.2777 - val_acc: 0.9122\n",
      "Epoch 18/20\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2607 - acc: 0.9099 - val_loss: 0.2757 - val_acc: 0.9122\n",
      "Epoch 19/20\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2572 - acc: 0.9097 - val_loss: 0.2793 - val_acc: 0.9107\n",
      "Epoch 20/20\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.2552 - acc: 0.9100 - val_loss: 0.2777 - val_acc: 0.9108\n",
      "AUC: 0.705757\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 30s 446us/step - loss: 0.3116 - acc: 0.9086 - val_loss: 0.3135 - val_acc: 0.9068\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.3019 - acc: 0.9097 - val_loss: 0.3038 - val_acc: 0.9068\n",
      "Epoch 3/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2945 - acc: 0.9097 - val_loss: 0.2975 - val_acc: 0.9068\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2916 - acc: 0.9097 - val_loss: 0.2973 - val_acc: 0.9068\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2888 - acc: 0.9097 - val_loss: 0.2951 - val_acc: 0.9068\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2880 - acc: 0.9096 - val_loss: 0.2922 - val_acc: 0.9068\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2846 - acc: 0.9097 - val_loss: 0.2912 - val_acc: 0.9066\n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2826 - acc: 0.9097 - val_loss: 0.2891 - val_acc: 0.9069\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2796 - acc: 0.9095 - val_loss: 0.2868 - val_acc: 0.9070\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2763 - acc: 0.9099 - val_loss: 0.2885 - val_acc: 0.9066\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2736 - acc: 0.9097 - val_loss: 0.2859 - val_acc: 0.9069\n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2711 - acc: 0.9097 - val_loss: 0.2839 - val_acc: 0.9066\n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2690 - acc: 0.9099 - val_loss: 0.2844 - val_acc: 0.9066\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2669 - acc: 0.9099 - val_loss: 0.2972 - val_acc: 0.9041\n",
      "Epoch 15/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2646 - acc: 0.9099 - val_loss: 0.2870 - val_acc: 0.9049\n",
      "Epoch 16/20\n",
      "66414/66414 [==============================] - 28s 419us/step - loss: 0.2609 - acc: 0.9106 - val_loss: 0.2848 - val_acc: 0.9069\n",
      "Epoch 17/20\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.2588 - acc: 0.9103 - val_loss: 0.2858 - val_acc: 0.9051\n",
      "AUC: 0.717760\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 29s 440us/step - loss: 0.3131 - acc: 0.9078 - val_loss: 0.3051 - val_acc: 0.9087\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.3033 - acc: 0.9094 - val_loss: 0.3041 - val_acc: 0.9087\n",
      "Epoch 3/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2963 - acc: 0.9095 - val_loss: 0.2953 - val_acc: 0.9087\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2921 - acc: 0.9095 - val_loss: 0.2906 - val_acc: 0.9087\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.2918 - acc: 0.9095 - val_loss: 0.2900 - val_acc: 0.9087\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2901 - acc: 0.9095 - val_loss: 0.2893 - val_acc: 0.9087\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.2872 - acc: 0.9094 - val_loss: 0.2874 - val_acc: 0.9087\n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.2850 - acc: 0.9094 - val_loss: 0.2864 - val_acc: 0.9087\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 30s 448us/step - loss: 0.2835 - acc: 0.9094 - val_loss: 0.2835 - val_acc: 0.9087\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2803 - acc: 0.9093 - val_loss: 0.2866 - val_acc: 0.9087\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2786 - acc: 0.9094 - val_loss: 0.2799 - val_acc: 0.9087\n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2766 - acc: 0.9093 - val_loss: 0.2795 - val_acc: 0.9087\n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2734 - acc: 0.9092 - val_loss: 0.2769 - val_acc: 0.9085\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2716 - acc: 0.9093 - val_loss: 0.2754 - val_acc: 0.9096\n",
      "Epoch 15/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2702 - acc: 0.9095 - val_loss: 0.2801 - val_acc: 0.9106\n",
      "Epoch 16/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2671 - acc: 0.9095 - val_loss: 0.2752 - val_acc: 0.9091\n",
      "Epoch 17/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2650 - acc: 0.9096 - val_loss: 0.2738 - val_acc: 0.9095\n",
      "Epoch 18/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2615 - acc: 0.9103 - val_loss: 0.2744 - val_acc: 0.9095\n",
      "Epoch 19/20\n",
      "66414/66414 [==============================] - 28s 421us/step - loss: 0.2590 - acc: 0.9104 - val_loss: 0.2746 - val_acc: 0.9092\n",
      "Epoch 20/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2574 - acc: 0.9102 - val_loss: 0.2745 - val_acc: 0.9095\n",
      "AUC: 0.733371\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 29s 443us/step - loss: 0.3112 - acc: 0.9080 - val_loss: 0.3117 - val_acc: 0.9088\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 28s 426us/step - loss: 0.3025 - acc: 0.9094 - val_loss: 0.2969 - val_acc: 0.9088\n",
      "Epoch 3/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2962 - acc: 0.9094 - val_loss: 0.2928 - val_acc: 0.9088\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2927 - acc: 0.9094 - val_loss: 0.2945 - val_acc: 0.9088\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2909 - acc: 0.9094 - val_loss: 0.2906 - val_acc: 0.9088\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2883 - acc: 0.9094 - val_loss: 0.2887 - val_acc: 0.9088\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2868 - acc: 0.9094 - val_loss: 0.2881 - val_acc: 0.9088\n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2842 - acc: 0.9094 - val_loss: 0.2852 - val_acc: 0.9088\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 28s 417us/step - loss: 0.2816 - acc: 0.9095 - val_loss: 0.2818 - val_acc: 0.9088\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2798 - acc: 0.9095 - val_loss: 0.2822 - val_acc: 0.9087\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2768 - acc: 0.9095 - val_loss: 0.2783 - val_acc: 0.9088\n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2742 - acc: 0.9096 - val_loss: 0.2764 - val_acc: 0.9083\n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2720 - acc: 0.9095 - val_loss: 0.2778 - val_acc: 0.9084\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2692 - acc: 0.9096 - val_loss: 0.2861 - val_acc: 0.9083\n",
      "Epoch 15/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2663 - acc: 0.9095 - val_loss: 0.2756 - val_acc: 0.9080\n",
      "Epoch 16/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2642 - acc: 0.9104 - val_loss: 0.2774 - val_acc: 0.9080\n",
      "Epoch 17/20\n",
      "66414/66414 [==============================] - 28s 425us/step - loss: 0.2620 - acc: 0.9104 - val_loss: 0.2771 - val_acc: 0.9084\n",
      "Epoch 18/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2585 - acc: 0.9106 - val_loss: 0.2815 - val_acc: 0.9062\n",
      "Epoch 19/20\n",
      "66414/66414 [==============================] - 28s 418us/step - loss: 0.2559 - acc: 0.9105 - val_loss: 0.2795 - val_acc: 0.9064\n",
      "Epoch 20/20\n",
      "66414/66414 [==============================] - 28s 424us/step - loss: 0.2548 - acc: 0.9109 - val_loss: 0.2758 - val_acc: 0.9072\n",
      "AUC: 0.732077\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/20\n",
      "66414/66414 [==============================] - 30s 445us/step - loss: 0.3154 - acc: 0.9070 - val_loss: 0.2890 - val_acc: 0.9162\n",
      "Epoch 2/20\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.3046 - acc: 0.9086 - val_loss: 0.2830 - val_acc: 0.9162\n",
      "Epoch 3/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2981 - acc: 0.9086 - val_loss: 0.2817 - val_acc: 0.9162\n",
      "Epoch 4/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2945 - acc: 0.9086 - val_loss: 0.2812 - val_acc: 0.9162\n",
      "Epoch 5/20\n",
      "66414/66414 [==============================] - 29s 430us/step - loss: 0.2925 - acc: 0.9086 - val_loss: 0.2798 - val_acc: 0.9162\n",
      "Epoch 6/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2914 - acc: 0.9086 - val_loss: 0.2807 - val_acc: 0.9162\n",
      "Epoch 7/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2894 - acc: 0.9085 - val_loss: 0.2782 - val_acc: 0.9162\n",
      "Epoch 8/20\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.2881 - acc: 0.9086 - val_loss: 0.2882 - val_acc: 0.9157\n",
      "Epoch 9/20\n",
      "66414/66414 [==============================] - 28s 422us/step - loss: 0.2853 - acc: 0.9086 - val_loss: 0.2806 - val_acc: 0.9164\n",
      "Epoch 10/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2825 - acc: 0.9086 - val_loss: 0.2774 - val_acc: 0.9161\n",
      "Epoch 11/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2805 - acc: 0.9086 - val_loss: 0.2740 - val_acc: 0.9154\n",
      "Epoch 12/20\n",
      "66414/66414 [==============================] - 28s 429us/step - loss: 0.2777 - acc: 0.9087 - val_loss: 0.2696 - val_acc: 0.9162\n",
      "Epoch 13/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2764 - acc: 0.9085 - val_loss: 0.2695 - val_acc: 0.9162\n",
      "Epoch 14/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2730 - acc: 0.9090 - val_loss: 0.2785 - val_acc: 0.9153\n",
      "Epoch 15/20\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.2706 - acc: 0.9086 - val_loss: 0.2685 - val_acc: 0.9154\n",
      "Epoch 16/20\n",
      "66414/66414 [==============================] - 28s 429us/step - loss: 0.2686 - acc: 0.9091 - val_loss: 0.2761 - val_acc: 0.9150\n",
      "Epoch 17/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2666 - acc: 0.9091 - val_loss: 0.2683 - val_acc: 0.9161\n",
      "Epoch 18/20\n",
      "66414/66414 [==============================] - 28s 428us/step - loss: 0.2650 - acc: 0.9092 - val_loss: 0.2698 - val_acc: 0.9146\n",
      "Epoch 19/20\n",
      "66414/66414 [==============================] - 28s 419us/step - loss: 0.2633 - acc: 0.9089 - val_loss: 0.2672 - val_acc: 0.9154\n",
      "Epoch 20/20\n",
      "66414/66414 [==============================] - 28s 429us/step - loss: 0.2599 - acc: 0.9091 - val_loss: 0.2662 - val_acc: 0.9164\n",
      "AUC: 0.708407\n",
      "总AUC: 0.699561\n"
     ]
    }
   ],
   "source": [
    "name = 'CKSAAP'\n",
    "gap = '_gap4'\n",
    "# 读取数据\n",
    "\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_29_'+ name + gap +'.txt'\n",
    "path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_29_'+ name + gap +'.txt'\n",
    "\n",
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "\n",
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2) \n",
    "x_test = np.expand_dims(x_test, axis=2) \n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "# path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "# path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "\n",
    "# x_train,y_train = pep(path_train,29-2)\n",
    "# x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "\n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    model = create_cnn_model3(shape=shape)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks_list = [early_stopping]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "         callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/result/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "   \n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "\n",
    "    \n",
    "    if j == 10:        \n",
    "        model.save('C:/Users/Crow/Desktop/result/model/CNN_kfold_'+ name + gap +'.h5')\n",
    "        \n",
    "        test_pred_proba = model.predict(x_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "        print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "        fw = open('C:/Users/Crow/Desktop/result/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "        for t in range(0,len(test_pred_proba)):\n",
    "            fw.write(str(test_pred_proba[t][0]))\n",
    "            fw.write('\\t')\n",
    "            fw.write(str(y_test[t]))\n",
    "            fw.write('\\n')\n",
    "        fw.close()\n",
    "    j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10685588"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba[t][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/1000\n",
      "66413/66413 [==============================] - 11s 166us/step - loss: 0.3062 - acc: 0.9076 - val_loss: 0.3094 - val_acc: 0.9077\n",
      "Epoch 2/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2966 - acc: 0.9096 - val_loss: 0.2983 - val_acc: 0.9077\n",
      "Epoch 3/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2909 - acc: 0.9096 - val_loss: 0.3258 - val_acc: 0.9077.2919 - acc: 0\n",
      "Epoch 4/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2886 - acc: 0.9096 - val_loss: 0.2899 - val_acc: 0.9077\n",
      "Epoch 5/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2840 - acc: 0.9096 - val_loss: 0.2933 - val_acc: 0.9077\n",
      "Epoch 6/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2824 - acc: 0.9096 - val_loss: 0.2829 - val_acc: 0.9077\n",
      "Epoch 7/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2815 - acc: 0.9095 - val_loss: 0.2842 - val_acc: 0.9076\n",
      "Epoch 8/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2805 - acc: 0.9096 - val_loss: 0.2821 - val_acc: 0.9075\n",
      "Epoch 9/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2792 - acc: 0.9094 - val_loss: 0.2868 - val_acc: 0.9076\n",
      "Epoch 10/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2779 - acc: 0.9094 - val_loss: 0.2943 - val_acc: 0.9077\n",
      "Epoch 11/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2771 - acc: 0.9095 - val_loss: 0.2822 - val_acc: 0.9076\n",
      "Epoch 12/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2770 - acc: 0.9096 - val_loss: 0.2760 - val_acc: 0.9077\n",
      "Epoch 13/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2757 - acc: 0.9096 - val_loss: 0.2778 - val_acc: 0.9079\n",
      "Epoch 14/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2747 - acc: 0.9094 - val_loss: 0.2788 - val_acc: 0.9077\n",
      "Epoch 15/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2743 - acc: 0.9097 - val_loss: 0.2873 - val_acc: 0.9069\n",
      "Epoch 16/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2730 - acc: 0.9095 - val_loss: 0.2726 - val_acc: 0.9079\n",
      "Epoch 17/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2738 - acc: 0.9093 - val_loss: 0.2769 - val_acc: 0.9077\n",
      "Epoch 18/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2737 - acc: 0.9096 - val_loss: 0.2746 - val_acc: 0.9073\n",
      "Epoch 19/1000\n",
      "66413/66413 [==============================] - 8s 122us/step - loss: 0.2719 - acc: 0.9095 - val_loss: 0.2854 - val_acc: 0.9077\n",
      "Epoch 20/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2722 - acc: 0.9094 - val_loss: 0.2801 - val_acc: 0.9081\n",
      "Epoch 21/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2715 - acc: 0.9097 - val_loss: 0.2796 - val_acc: 0.9076\n",
      "Epoch 22/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2717 - acc: 0.9096 - val_loss: 0.2746 - val_acc: 0.9079\n",
      "Epoch 23/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2711 - acc: 0.9094 - val_loss: 0.2822 - val_acc: 0.9079\n",
      "Epoch 24/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2693 - acc: 0.9093 - val_loss: 0.2796 - val_acc: 0.9077\n",
      "Epoch 25/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2708 - acc: 0.9095 - val_loss: 0.2841 - val_acc: 0.9081ss: 0.2710 - acc: 0.909\n",
      "Epoch 26/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2697 - acc: 0.9094 - val_loss: 0.2755 - val_acc: 0.9076\n",
      "Epoch 27/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2704 - acc: 0.9094 - val_loss: 0.2800 - val_acc: 0.9076\n",
      "Epoch 28/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2697 - acc: 0.9094 - val_loss: 0.2773 - val_acc: 0.9076\n",
      "Epoch 29/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2698 - acc: 0.9095 - val_loss: 0.2768 - val_acc: 0.9077\n",
      "Epoch 30/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2684 - acc: 0.9098 - val_loss: 0.2941 - val_acc: 0.9058\n",
      "Epoch 31/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2688 - acc: 0.9098 - val_loss: 0.2783 - val_acc: 0.9075\n",
      "Epoch 32/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2685 - acc: 0.9098 - val_loss: 0.2779 - val_acc: 0.9076\n",
      "Epoch 33/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2673 - acc: 0.9096 - val_loss: 0.2717 - val_acc: 0.9073\n",
      "Epoch 34/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2676 - acc: 0.9094 - val_loss: 0.2745 - val_acc: 0.9072\n",
      "Epoch 35/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2677 - acc: 0.9095 - val_loss: 0.2762 - val_acc: 0.9077 - loss: 0.2679 -\n",
      "Epoch 36/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2679 - acc: 0.9093 - val_loss: 0.2716 - val_acc: 0.9075ss: 0.2682 - acc\n",
      "Epoch 37/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2676 - acc: 0.9096 - val_loss: 0.2836 - val_acc: 0.9081\n",
      "Epoch 38/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2670 - acc: 0.9096 - val_loss: 0.2702 - val_acc: 0.9070\n",
      "Epoch 39/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2666 - acc: 0.9095 - val_loss: 0.2723 - val_acc: 0.9072: 6s - loss: 0.2728 - acc: 0.90 - ETA: 5s - loss: 0.2\n",
      "Epoch 40/1000\n",
      "66413/66413 [==============================] - 8s 127us/step - loss: 0.2674 - acc: 0.9097 - val_loss: 0.2787 - val_acc: 0.9077\n",
      "Epoch 41/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2665 - acc: 0.9094 - val_loss: 0.2802 - val_acc: 0.9069\n",
      "Epoch 42/1000\n",
      "66413/66413 [==============================] - 9s 129us/step - loss: 0.2658 - acc: 0.9095 - val_loss: 0.2780 - val_acc: 0.9073\n",
      "Epoch 43/1000\n",
      "66413/66413 [==============================] - 8s 123us/step - loss: 0.2665 - acc: 0.9095 - val_loss: 0.2864 - val_acc: 0.9083\n",
      "Epoch 44/1000\n",
      "66413/66413 [==============================] - 8s 125us/step - loss: 0.2661 - acc: 0.9095 - val_loss: 0.2735 - val_acc: 0.9079\n",
      "Epoch 45/1000\n",
      "66413/66413 [==============================] - 8s 126us/step - loss: 0.2654 - acc: 0.9097 - val_loss: 0.2761 - val_acc: 0.9075\n",
      "Epoch 46/1000\n",
      "66413/66413 [==============================] - 8s 123us/step - loss: 0.2658 - acc: 0.9097 - val_loss: 0.2759 - val_acc: 0.9075\n",
      "Epoch 47/1000\n",
      "66413/66413 [==============================] - 8s 127us/step - loss: 0.2648 - acc: 0.9098 - val_loss: 0.2696 - val_acc: 0.9073\n",
      "Epoch 48/1000\n",
      "66413/66413 [==============================] - 8s 126us/step - loss: 0.2657 - acc: 0.9091 - val_loss: 0.2726 - val_acc: 0.9075\n",
      "Epoch 49/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2658 - acc: 0.9095 - val_loss: 0.2769 - val_acc: 0.9077\n",
      "Epoch 50/1000\n",
      "66413/66413 [==============================] - 8s 122us/step - loss: 0.2650 - acc: 0.9092 - val_loss: 0.2770 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_1.hdf5\n",
      "Epoch 51/1000\n",
      "66413/66413 [==============================] - 8s 122us/step - loss: 0.2657 - acc: 0.9097 - val_loss: 0.2804 - val_acc: 0.9077.2663 - acc: 0\n",
      "Epoch 52/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2649 - acc: 0.9096 - val_loss: 0.2785 - val_acc: 0.9075\n",
      "Epoch 53/1000\n",
      "66413/66413 [==============================] - 8s 123us/step - loss: 0.2647 - acc: 0.9094 - val_loss: 0.2729 - val_acc: 0.9080\n",
      "Epoch 54/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2640 - acc: 0.9097 - val_loss: 0.2721 - val_acc: 0.9077\n",
      "Epoch 55/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2643 - acc: 0.9095 - val_loss: 0.2721 - val_acc: 0.9080\n",
      "Epoch 56/1000\n",
      "66413/66413 [==============================] - 8s 122us/step - loss: 0.2644 - acc: 0.9099 - val_loss: 0.2710 - val_acc: 0.9077\n",
      "Epoch 57/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2642 - acc: 0.9096 - val_loss: 0.2699 - val_acc: 0.9084\n",
      "Epoch 58/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2631 - acc: 0.9094 - val_loss: 0.2711 - val_acc: 0.9081\n",
      "Epoch 59/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2641 - acc: 0.9097 - val_loss: 0.2729 - val_acc: 0.9079\n",
      "Epoch 60/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2638 - acc: 0.9090 - val_loss: 0.2775 - val_acc: 0.9084\n",
      "Epoch 61/1000\n",
      "66413/66413 [==============================] - 8s 123us/step - loss: 0.2637 - acc: 0.9093 - val_loss: 0.2790 - val_acc: 0.9080\n",
      "Epoch 62/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2641 - acc: 0.9095 - val_loss: 0.2695 - val_acc: 0.9077\n",
      "Epoch 63/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2635 - acc: 0.9096 - val_loss: 0.2741 - val_acc: 0.9077\n",
      "Epoch 64/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2630 - acc: 0.9097 - val_loss: 0.2745 - val_acc: 0.9080\n",
      "Epoch 65/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2622 - acc: 0.9096 - val_loss: 0.2730 - val_acc: 0.9079\n",
      "Epoch 66/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2631 - acc: 0.9096 - val_loss: 0.2726 - val_acc: 0.9080\n",
      "Epoch 67/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2607 - acc: 0.9097 - val_loss: 0.2789 - val_acc: 0.9075\n",
      "Epoch 68/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2629 - acc: 0.9096 - val_loss: 0.2803 - val_acc: 0.9072\n",
      "Epoch 69/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2612 - acc: 0.9095 - val_loss: 0.2728 - val_acc: 0.9081\n",
      "Epoch 70/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2621 - acc: 0.9094 - val_loss: 0.2703 - val_acc: 0.9079- loss: 0.2633 - acc: 0.9 - ETA:  - ETA: 1s -\n",
      "Epoch 71/1000\n",
      "66413/66413 [==============================] - 8s 123us/step - loss: 0.2632 - acc: 0.9096 - val_loss: 0.2729 - val_acc: 0.9080\n",
      "Epoch 72/1000\n",
      "66413/66413 [==============================] - 8s 123us/step - loss: 0.2608 - acc: 0.9094 - val_loss: 0.2787 - val_acc: 0.9083- acc: 0.91 - ET - ETA: 1s - loss: 0.\n",
      "Epoch 73/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2622 - acc: 0.9096 - val_loss: 0.2753 - val_acc: 0.9075\n",
      "Epoch 74/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2611 - acc: 0.9094 - val_loss: 0.2686 - val_acc: 0.9080\n",
      "Epoch 75/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2626 - acc: 0.9095 - val_loss: 0.2706 - val_acc: 0.9079\n",
      "Epoch 76/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2605 - acc: 0.9097 - val_loss: 0.2739 - val_acc: 0.9080\n",
      "Epoch 77/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2623 - acc: 0.9096 - val_loss: 0.2724 - val_acc: 0.9084\n",
      "Epoch 78/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2608 - acc: 0.9096 - val_loss: 0.2704 - val_acc: 0.9077\n",
      "Epoch 79/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2744 - val_acc: 0.9084\n",
      "Epoch 80/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2612 - acc: 0.9093 - val_loss: 0.2699 - val_acc: 0.9076\n",
      "Epoch 81/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2607 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9077\n",
      "Epoch 82/1000\n",
      "66413/66413 [==============================] - 8s 124us/step - loss: 0.2600 - acc: 0.9097 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 83/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2616 - acc: 0.9094 - val_loss: 0.2700 - val_acc: 0.9079\n",
      "Epoch 84/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2611 - acc: 0.9097 - val_loss: 0.2711 - val_acc: 0.9081\n",
      "Epoch 85/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2610 - acc: 0.9097 - val_loss: 0.2728 - val_acc: 0.9084\n",
      "Epoch 86/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2605 - acc: 0.9096 - val_loss: 0.2700 - val_acc: 0.9084\n",
      "Epoch 87/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2609 - acc: 0.9092 - val_loss: 0.2702 - val_acc: 0.9076\n",
      "Epoch 88/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2603 - acc: 0.9099 - val_loss: 0.2716 - val_acc: 0.9077\n",
      "Epoch 89/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2603 - acc: 0.9095 - val_loss: 0.2779 - val_acc: 0.9075\n",
      "Epoch 90/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2595 - acc: 0.9094 - val_loss: 0.2679 - val_acc: 0.9076\n",
      "Epoch 91/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2611 - acc: 0.9096 - val_loss: 0.2737 - val_acc: 0.9080\n",
      "Epoch 92/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2605 - acc: 0.9095 - val_loss: 0.2746 - val_acc: 0.9079\n",
      "Epoch 93/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2603 - acc: 0.9095 - val_loss: 0.2682 - val_acc: 0.9083\n",
      "Epoch 94/1000\n",
      "66413/66413 [==============================] - 6s 85us/step - loss: 0.2590 - acc: 0.9095 - val_loss: 0.2709 - val_acc: 0.9085\n",
      "Epoch 95/1000\n",
      "66413/66413 [==============================] - 6s 90us/step - loss: 0.2599 - acc: 0.9097 - val_loss: 0.2700 - val_acc: 0.9079\n",
      "Epoch 96/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2594 - acc: 0.9097 - val_loss: 0.2764 - val_acc: 0.9079 1s - loss:\n",
      "Epoch 97/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2584 - acc: 0.9095 - val_loss: 0.2752 - val_acc: 0.9081\n",
      "Epoch 98/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2582 - acc: 0.9095 - val_loss: 0.2692 - val_acc: 0.9073\n",
      "Epoch 99/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2597 - acc: 0.9096 - val_loss: 0.2729 - val_acc: 0.9076\n",
      "Epoch 100/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2593 - acc: 0.9095 - val_loss: 0.2712 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_1.hdf5\n",
      "Epoch 101/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2591 - acc: 0.9096 - val_loss: 0.2702 - val_acc: 0.90770.2586 -  - ETA: 1\n",
      "Epoch 102/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2599 - acc: 0.9098 - val_loss: 0.2713 - val_acc: 0.9076lo\n",
      "Epoch 103/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2592 - acc: 0.9093 - val_loss: 0.2697 - val_acc: 0.9076\n",
      "Epoch 104/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2596 - acc: 0.9092 - val_loss: 0.2676 - val_acc: 0.9080\n",
      "Epoch 105/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2595 - acc: 0.9094 - val_loss: 0.2709 - val_acc: 0.9081\n",
      "Epoch 106/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2592 - acc: 0.9096 - val_loss: 0.2690 - val_acc: 0.9080\n",
      "Epoch 107/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2587 - acc: 0.9096 - val_loss: 0.2722 - val_acc: 0.9084\n",
      "Epoch 108/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2589 - acc: 0.9098 - val_loss: 0.2661 - val_acc: 0.9083\n",
      "Epoch 109/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2576 - acc: 0.9094 - val_loss: 0.2670 - val_acc: 0.9081\n",
      "Epoch 110/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2577 - acc: 0.9096 - val_loss: 0.2708 - val_acc: 0.9083s: 0.2577 - acc: 0.90\n",
      "Epoch 111/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2597 - acc: 0.9097 - val_loss: 0.2738 - val_acc: 0.9079\n",
      "Epoch 112/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2577 - acc: 0.9095 - val_loss: 0.2702 - val_acc: 0.9083\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2583 - acc: 0.9096 - val_loss: 0.2692 - val_acc: 0.9081\n",
      "Epoch 114/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2579 - acc: 0.9098 - val_loss: 0.2721 - val_acc: 0.9080\n",
      "Epoch 115/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2565 - acc: 0.9096 - val_loss: 0.2752 - val_acc: 0.9087\n",
      "Epoch 116/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2577 - acc: 0.9100 - val_loss: 0.2687 - val_acc: 0.9080\n",
      "Epoch 117/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2575 - acc: 0.9103 - val_loss: 0.2688 - val_acc: 0.9079\n",
      "Epoch 118/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2568 - acc: 0.9098 - val_loss: 0.2711 - val_acc: 0.9077\n",
      "Epoch 119/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2587 - acc: 0.9097 - val_loss: 0.2710 - val_acc: 0.9075\n",
      "Epoch 120/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2573 - acc: 0.9098 - val_loss: 0.2690 - val_acc: 0.9079\n",
      "Epoch 121/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2569 - acc: 0.9101 - val_loss: 0.2740 - val_acc: 0.9077\n",
      "Epoch 122/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2576 - acc: 0.9096 - val_loss: 0.2698 - val_acc: 0.9079\n",
      "Epoch 123/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2567 - acc: 0.9098 - val_loss: 0.2686 - val_acc: 0.9084 - loss: \n",
      "Epoch 124/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2578 - acc: 0.9096 - val_loss: 0.2715 - val_acc: 0.9076\n",
      "Epoch 125/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2580 - acc: 0.9099 - val_loss: 0.2690 - val_acc: 0.9072\n",
      "Epoch 126/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2581 - acc: 0.9097 - val_loss: 0.2676 - val_acc: 0.9079\n",
      "Epoch 127/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2562 - acc: 0.9096 - val_loss: 0.2689 - val_acc: 0.9079\n",
      "Epoch 128/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2558 - acc: 0.9100 - val_loss: 0.2704 - val_acc: 0.9081\n",
      "Epoch 129/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2574 - acc: 0.9096 - val_loss: 0.2678 - val_acc: 0.9080\n",
      "Epoch 130/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2556 - acc: 0.9096 - val_loss: 0.2690 - val_acc: 0.9075\n",
      "Epoch 131/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2560 - acc: 0.9094 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 132/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2572 - acc: 0.9096 - val_loss: 0.2658 - val_acc: 0.9079.2585 - acc: \n",
      "Epoch 133/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2556 - acc: 0.9100 - val_loss: 0.2680 - val_acc: 0.9077\n",
      "Epoch 134/1000\n",
      "66413/66413 [==============================] - 8s 114us/step - loss: 0.2557 - acc: 0.9096 - val_loss: 0.2669 - val_acc: 0.9080\n",
      "Epoch 135/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2574 - acc: 0.9100 - val_loss: 0.2678 - val_acc: 0.9077\n",
      "Epoch 136/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2571 - acc: 0.9092 - val_loss: 0.2699 - val_acc: 0.9085\n",
      "Epoch 137/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2553 - acc: 0.9100 - val_loss: 0.2687 - val_acc: 0.9081\n",
      "Epoch 138/1000\n",
      "66413/66413 [==============================] - 8s 127us/step - loss: 0.2555 - acc: 0.9099 - val_loss: 0.2705 - val_acc: 0.9084\n",
      "Epoch 139/1000\n",
      "66413/66413 [==============================] - 8s 126us/step - loss: 0.2549 - acc: 0.9099 - val_loss: 0.2699 - val_acc: 0.9077\n",
      "Epoch 140/1000\n",
      "66413/66413 [==============================] - 8s 122us/step - loss: 0.2570 - acc: 0.9093 - val_loss: 0.2696 - val_acc: 0.9079\n",
      "Epoch 141/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2561 - acc: 0.9100 - val_loss: 0.2700 - val_acc: 0.9084\n",
      "Epoch 142/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2569 - acc: 0.9093 - val_loss: 0.2678 - val_acc: 0.9083\n",
      "Epoch 143/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2547 - acc: 0.9101 - val_loss: 0.2710 - val_acc: 0.9080\n",
      "Epoch 144/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2561 - acc: 0.9100 - val_loss: 0.2697 - val_acc: 0.9080\n",
      "Epoch 145/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2555 - acc: 0.9094 - val_loss: 0.2709 - val_acc: 0.9079\n",
      "Epoch 146/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2557 - acc: 0.9100 - val_loss: 0.2692 - val_acc: 0.9076\n",
      "Epoch 147/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2558 - acc: 0.9097 - val_loss: 0.2697 - val_acc: 0.9077\n",
      "Epoch 148/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2551 - acc: 0.9091 - val_loss: 0.2687 - val_acc: 0.9081\n",
      "Epoch 149/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2549 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9077\n",
      "Epoch 150/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2559 - acc: 0.9100 - val_loss: 0.2669 - val_acc: 0.9076.9\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_1.hdf5\n",
      "Epoch 151/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2552 - acc: 0.9098 - val_loss: 0.2686 - val_acc: 0.9083 - loss: - ETA: 0s - loss: 0.2555 - acc: 0.9 - ETA: 0s - loss: 0.2555 - acc:  - ETA: 0s - loss: 0.2550 - acc:\n",
      "Epoch 152/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2532 - acc: 0.9100 - val_loss: 0.2699 - val_acc: 0.9079\n",
      "Epoch 153/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2552 - acc: 0.9095 - val_loss: 0.2683 - val_acc: 0.9084\n",
      "Epoch 154/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2564 - acc: 0.9095 - val_loss: 0.2680 - val_acc: 0.9076\n",
      "Epoch 155/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2555 - acc: 0.9102 - val_loss: 0.2687 - val_acc: 0.9075\n",
      "Epoch 156/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2558 - acc: 0.9097 - val_loss: 0.2703 - val_acc: 0.9072\n",
      "Epoch 157/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2546 - acc: 0.9096 - val_loss: 0.2678 - val_acc: 0.9077\n",
      "Epoch 158/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2552 - acc: 0.9101 - val_loss: 0.2669 - val_acc: 0.9079\n",
      "Epoch 159/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2545 - acc: 0.9101 - val_loss: 0.2714 - val_acc: 0.9077\n",
      "Epoch 160/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2537 - acc: 0.9104 - val_loss: 0.2685 - val_acc: 0.9075\n",
      "Epoch 161/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2545 - acc: 0.9100 - val_loss: 0.2684 - val_acc: 0.9076 - acc\n",
      "Epoch 162/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2545 - acc: 0.9099 - val_loss: 0.2691 - val_acc: 0.9076\n",
      "Epoch 163/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2549 - acc: 0.9099 - val_loss: 0.2682 - val_acc: 0.9077\n",
      "Epoch 164/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2538 - acc: 0.9103 - val_loss: 0.2673 - val_acc: 0.9077\n",
      "Epoch 165/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2538 - acc: 0.9099 - val_loss: 0.2677 - val_acc: 0.9075loss: 0.2518 - ETA: 3s - \n",
      "Epoch 166/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2548 - acc: 0.9106 - val_loss: 0.2673 - val_acc: 0.9073\n",
      "Epoch 167/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2540 - acc: 0.9098 - val_loss: 0.2686 - val_acc: 0.9081\n",
      "Epoch 168/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2540 - acc: 0.9101 - val_loss: 0.2698 - val_acc: 0.9079- loss: 0.2527 - acc:  - ETA\n",
      "Epoch 169/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2540 - acc: 0.9095 - val_loss: 0.2700 - val_acc: 0.9076\n",
      "Epoch 170/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2554 - acc: 0.9096 - val_loss: 0.2714 - val_acc: 0.9079\n",
      "Epoch 171/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2547 - acc: 0.9101 - val_loss: 0.2701 - val_acc: 0.9079\n",
      "Epoch 172/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2537 - acc: 0.9095 - val_loss: 0.2709 - val_acc: 0.9077\n",
      "Epoch 173/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2528 - acc: 0.9099 - val_loss: 0.2684 - val_acc: 0.9081\n",
      "Epoch 174/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2541 - acc: 0.9102 - val_loss: 0.2717 - val_acc: 0.9076\n",
      "Epoch 175/1000\n",
      "66413/66413 [==============================] - 8s 122us/step - loss: 0.2531 - acc: 0.9100 - val_loss: 0.2694 - val_acc: 0.9084\n",
      "Epoch 176/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2538 - acc: 0.9102 - val_loss: 0.2704 - val_acc: 0.9075\n",
      "Epoch 177/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2535 - acc: 0.9102 - val_loss: 0.2687 - val_acc: 0.9076\n",
      "Epoch 178/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2538 - acc: 0.9102 - val_loss: 0.2666 - val_acc: 0.9076\n",
      "Epoch 179/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2562 - acc: 0.9101 - val_loss: 0.2686 - val_acc: 0.9077\n",
      "Epoch 180/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2529 - acc: 0.9098 - val_loss: 0.2662 - val_acc: 0.9077\n",
      "Epoch 181/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2529 - acc: 0.9098 - val_loss: 0.2704 - val_acc: 0.90832 - ETA: 2s - loss: 0. - ETA: 1s - loss: 0\n",
      "Epoch 182/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2522 - acc: 0.9099 - val_loss: 0.2711 - val_acc: 0.9081\n",
      "AUC: 0.776545\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/1000\n",
      "66413/66413 [==============================] - 9s 128us/step - loss: 0.3095 - acc: 0.9073 - val_loss: 0.3014 - val_acc: 0.9123\n",
      "Epoch 2/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2971 - acc: 0.9091 - val_loss: 0.2883 - val_acc: 0.9123\n",
      "Epoch 3/1000\n",
      "66413/66413 [==============================] - 6s 93us/step - loss: 0.2925 - acc: 0.9091 - val_loss: 0.2826 - val_acc: 0.9123\n",
      "Epoch 4/1000\n",
      "66413/66413 [==============================] - 6s 93us/step - loss: 0.2903 - acc: 0.9091 - val_loss: 0.2809 - val_acc: 0.9123\n",
      "Epoch 5/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2880 - acc: 0.9091 - val_loss: 0.2739 - val_acc: 0.9123\n",
      "Epoch 6/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2848 - acc: 0.9090 - val_loss: 0.2797 - val_acc: 0.9119\n",
      "Epoch 7/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2841 - acc: 0.9091 - val_loss: 0.2822 - val_acc: 0.9122\n",
      "Epoch 8/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2829 - acc: 0.9090 - val_loss: 0.2722 - val_acc: 0.9123\n",
      "Epoch 9/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2817 - acc: 0.9090 - val_loss: 0.2728 - val_acc: 0.9122\n",
      "Epoch 10/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2806 - acc: 0.9091 - val_loss: 0.2718 - val_acc: 0.9122\n",
      "Epoch 11/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2795 - acc: 0.9091 - val_loss: 0.2771 - val_acc: 0.9118\n",
      "Epoch 12/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2787 - acc: 0.9090 - val_loss: 0.2667 - val_acc: 0.9125\n",
      "Epoch 13/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2781 - acc: 0.9089 - val_loss: 0.2678 - val_acc: 0.9125\n",
      "Epoch 14/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2780 - acc: 0.9090 - val_loss: 0.2632 - val_acc: 0.9123\n",
      "Epoch 15/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2759 - acc: 0.9089 - val_loss: 0.2728 - val_acc: 0.9127\n",
      "Epoch 16/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2762 - acc: 0.9090 - val_loss: 0.2689 - val_acc: 0.9125\n",
      "Epoch 17/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2753 - acc: 0.9090 - val_loss: 0.2677 - val_acc: 0.9126\n",
      "Epoch 18/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2751 - acc: 0.9090 - val_loss: 0.2722 - val_acc: 0.9126\n",
      "Epoch 19/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2745 - acc: 0.9090 - val_loss: 0.2674 - val_acc: 0.9127\n",
      "Epoch 20/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2753 - acc: 0.9090 - val_loss: 0.2642 - val_acc: 0.9127\n",
      "Epoch 21/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2748 - acc: 0.9089 - val_loss: 0.2651 - val_acc: 0.9125\n",
      "Epoch 22/1000\n",
      "66413/66413 [==============================] - 8s 122us/step - loss: 0.2741 - acc: 0.9089 - val_loss: 0.2644 - val_acc: 0.9129s - loss: 0.2743 - acc:\n",
      "Epoch 23/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2738 - acc: 0.9091 - val_loss: 0.2786 - val_acc: 0.9127\n",
      "Epoch 24/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2734 - acc: 0.9090 - val_loss: 0.2744 - val_acc: 0.9136\n",
      "Epoch 25/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2721 - acc: 0.9090 - val_loss: 0.2693 - val_acc: 0.9130\n",
      "Epoch 26/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2718 - acc: 0.9092 - val_loss: 0.2657 - val_acc: 0.9130\n",
      "Epoch 27/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2718 - acc: 0.9091 - val_loss: 0.2723 - val_acc: 0.9133\n",
      "Epoch 28/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2714 - acc: 0.9091 - val_loss: 0.2704 - val_acc: 0.9126\n",
      "Epoch 29/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2716 - acc: 0.9092 - val_loss: 0.2674 - val_acc: 0.9127\n",
      "Epoch 30/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2708 - acc: 0.9088 - val_loss: 0.2608 - val_acc: 0.9125- loss: 0.2702 - acc:  - ETA: 0s - loss: 0.2707 - acc: 0\n",
      "Epoch 31/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2709 - acc: 0.9091 - val_loss: 0.2667 - val_acc: 0.9131\n",
      "Epoch 32/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2699 - acc: 0.9090 - val_loss: 0.2700 - val_acc: 0.9131\n",
      "Epoch 33/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2702 - acc: 0.9090 - val_loss: 0.2785 - val_acc: 0.9129\n",
      "Epoch 34/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2699 - acc: 0.9088 - val_loss: 0.2594 - val_acc: 0.9129\n",
      "Epoch 35/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2706 - acc: 0.9092 - val_loss: 0.2656 - val_acc: 0.9133\n",
      "Epoch 36/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2695 - acc: 0.9089 - val_loss: 0.2665 - val_acc: 0.9130\n",
      "Epoch 37/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2687 - acc: 0.9091 - val_loss: 0.2668 - val_acc: 0.9134\n",
      "Epoch 38/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2681 - acc: 0.9089 - val_loss: 0.2644 - val_acc: 0.9130\n",
      "Epoch 39/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2677 - acc: 0.9089 - val_loss: 0.2641 - val_acc: 0.9130\n",
      "Epoch 40/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2689 - acc: 0.9091 - val_loss: 0.2652 - val_acc: 0.9129\n",
      "Epoch 41/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2677 - acc: 0.9091 - val_loss: 0.2662 - val_acc: 0.9131\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2681 - acc: 0.9090 - val_loss: 0.2645 - val_acc: 0.9127\n",
      "Epoch 43/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2682 - acc: 0.9094 - val_loss: 0.2723 - val_acc: 0.9129\n",
      "Epoch 44/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2675 - acc: 0.9088 - val_loss: 0.2690 - val_acc: 0.9127\n",
      "Epoch 45/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2678 - acc: 0.9092 - val_loss: 0.2669 - val_acc: 0.9127\n",
      "Epoch 46/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2673 - acc: 0.9088 - val_loss: 0.2717 - val_acc: 0.9130\n",
      "Epoch 47/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2672 - acc: 0.9090 - val_loss: 0.2720 - val_acc: 0.9126\n",
      "Epoch 48/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2680 - acc: 0.9091 - val_loss: 0.2701 - val_acc: 0.9130\n",
      "Epoch 49/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2667 - acc: 0.9092 - val_loss: 0.2680 - val_acc: 0.9129\n",
      "Epoch 50/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2665 - acc: 0.9091 - val_loss: 0.2658 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_2.hdf5\n",
      "Epoch 51/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2663 - acc: 0.9091 - val_loss: 0.2676 - val_acc: 0.9131\n",
      "Epoch 52/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2662 - acc: 0.9091 - val_loss: 0.2633 - val_acc: 0.9126\n",
      "Epoch 53/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2653 - acc: 0.9089 - val_loss: 0.2669 - val_acc: 0.9127\n",
      "Epoch 54/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2654 - acc: 0.9089 - val_loss: 0.2701 - val_acc: 0.9134\n",
      "Epoch 55/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2658 - acc: 0.9091 - val_loss: 0.2649 - val_acc: 0.9131\n",
      "Epoch 56/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2664 - acc: 0.9089 - val_loss: 0.2670 - val_acc: 0.9126\n",
      "Epoch 57/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2644 - acc: 0.9090 - val_loss: 0.2648 - val_acc: 0.9127\n",
      "Epoch 58/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2657 - acc: 0.9091 - val_loss: 0.2645 - val_acc: 0.9130\n",
      "Epoch 59/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2660 - acc: 0.9091 - val_loss: 0.2643 - val_acc: 0.9129\n",
      "Epoch 60/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2654 - acc: 0.9090 - val_loss: 0.2666 - val_acc: 0.9126\n",
      "Epoch 61/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2652 - acc: 0.9092 - val_loss: 0.2640 - val_acc: 0.9126\n",
      "Epoch 62/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2656 - acc: 0.9092 - val_loss: 0.2654 - val_acc: 0.9130\n",
      "Epoch 63/1000\n",
      "66413/66413 [==============================] - 7s 113us/step - loss: 0.2648 - acc: 0.9090 - val_loss: 0.2609 - val_acc: 0.9131s: 0.2648 - ETA: 2s - loss: 0.2641 - acc: 0.90 \n",
      "Epoch 64/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2636 - acc: 0.9090 - val_loss: 0.2637 - val_acc: 0.9130\n",
      "Epoch 65/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2652 - acc: 0.9089 - val_loss: 0.2729 - val_acc: 0.9130\n",
      "Epoch 66/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2646 - acc: 0.9091 - val_loss: 0.2643 - val_acc: 0.9126\n",
      "Epoch 67/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2638 - acc: 0.9091 - val_loss: 0.2647 - val_acc: 0.9129\n",
      "Epoch 68/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2634 - acc: 0.9089 - val_loss: 0.2628 - val_acc: 0.9133\n",
      "Epoch 69/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2646 - acc: 0.9090 - val_loss: 0.2599 - val_acc: 0.9133\n",
      "Epoch 70/1000\n",
      "66413/66413 [==============================] - 8s 121us/step - loss: 0.2643 - acc: 0.9089 - val_loss: 0.2592 - val_acc: 0.9129\n",
      "Epoch 71/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2641 - acc: 0.9089 - val_loss: 0.2636 - val_acc: 0.9129\n",
      "Epoch 72/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2631 - acc: 0.9091 - val_loss: 0.2601 - val_acc: 0.9134: 6s - loss: 0 - E\n",
      "Epoch 73/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2632 - acc: 0.9087 - val_loss: 0.2633 - val_acc: 0.9126\n",
      "Epoch 74/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2622 - acc: 0.9089 - val_loss: 0.2616 - val_acc: 0.9122\n",
      "Epoch 75/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2625 - acc: 0.9089 - val_loss: 0.2603 - val_acc: 0.9125\n",
      "Epoch 76/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2632 - acc: 0.9090 - val_loss: 0.2621 - val_acc: 0.9127\n",
      "Epoch 77/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2640 - acc: 0.9089 - val_loss: 0.2695 - val_acc: 0.9129\n",
      "Epoch 78/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2635 - acc: 0.9088 - val_loss: 0.2610 - val_acc: 0.9130\n",
      "Epoch 79/1000\n",
      "66413/66413 [==============================] - 8s 114us/step - loss: 0.2624 - acc: 0.9089 - val_loss: 0.2651 - val_acc: 0.9130\n",
      "Epoch 80/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2623 - acc: 0.9087 - val_loss: 0.2605 - val_acc: 0.9131\n",
      "Epoch 81/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2624 - acc: 0.9088 - val_loss: 0.2647 - val_acc: 0.9131\n",
      "Epoch 82/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2614 - acc: 0.9092 - val_loss: 0.2653 - val_acc: 0.9126oss:\n",
      "Epoch 83/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2614 - acc: 0.9091 - val_loss: 0.2663 - val_acc: 0.9133\n",
      "Epoch 84/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2624 - acc: 0.9090 - val_loss: 0.2653 - val_acc: 0.9126\n",
      "Epoch 85/1000\n",
      "66413/66413 [==============================] - 7s 104us/step - loss: 0.2613 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9131\n",
      "Epoch 86/1000\n",
      "66413/66413 [==============================] - 5s 82us/step - loss: 0.2626 - acc: 0.9086 - val_loss: 0.2609 - val_acc: 0.9129\n",
      "Epoch 87/1000\n",
      "66413/66413 [==============================] - 8s 114us/step - loss: 0.2616 - acc: 0.9094 - val_loss: 0.2685 - val_acc: 0.9129\n",
      "Epoch 88/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2632 - acc: 0.9089 - val_loss: 0.2606 - val_acc: 0.9127\n",
      "Epoch 89/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2612 - acc: 0.9093 - val_loss: 0.2642 - val_acc: 0.9127\n",
      "Epoch 90/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2609 - acc: 0.9092 - val_loss: 0.2648 - val_acc: 0.9125\n",
      "Epoch 91/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2618 - acc: 0.9088 - val_loss: 0.2635 - val_acc: 0.9127\n",
      "Epoch 92/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2622 - acc: 0.9089 - val_loss: 0.2648 - val_acc: 0.9127\n",
      "Epoch 93/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2626 - acc: 0.9087 - val_loss: 0.2632 - val_acc: 0.9126\n",
      "Epoch 94/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2611 - acc: 0.9088 - val_loss: 0.2616 - val_acc: 0.9127\n",
      "Epoch 95/1000\n",
      "66413/66413 [==============================] - 8s 120us/step - loss: 0.2598 - acc: 0.9089 - val_loss: 0.2637 - val_acc: 0.9129\n",
      "Epoch 96/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2607 - acc: 0.9091 - val_loss: 0.2586 - val_acc: 0.9127\n",
      "Epoch 97/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2610 - acc: 0.9092 - val_loss: 0.2627 - val_acc: 0.9131\n",
      "Epoch 98/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2607 - acc: 0.9087 - val_loss: 0.2659 - val_acc: 0.9129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2604 - acc: 0.9092 - val_loss: 0.2616 - val_acc: 0.9131\n",
      "Epoch 100/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2610 - acc: 0.9090 - val_loss: 0.2627 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_2.hdf5\n",
      "Epoch 101/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2609 - acc: 0.9093 - val_loss: 0.2679 - val_acc: 0.9131\n",
      "Epoch 102/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2594 - acc: 0.9091 - val_loss: 0.2609 - val_acc: 0.9129\n",
      "Epoch 103/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2601 - acc: 0.9091 - val_loss: 0.2618 - val_acc: 0.9131\n",
      "Epoch 104/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2613 - acc: 0.9092 - val_loss: 0.2617 - val_acc: 0.9126\n",
      "Epoch 105/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2604 - acc: 0.9090 - val_loss: 0.2623 - val_acc: 0.9125\n",
      "Epoch 106/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2598 - acc: 0.9088 - val_loss: 0.2602 - val_acc: 0.9131\n",
      "Epoch 107/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2598 - acc: 0.9091 - val_loss: 0.2606 - val_acc: 0.9133\n",
      "Epoch 108/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2605 - acc: 0.9089 - val_loss: 0.2625 - val_acc: 0.9133\n",
      "Epoch 109/1000\n",
      "66413/66413 [==============================] - 7s 111us/step - loss: 0.2605 - acc: 0.9089 - val_loss: 0.2625 - val_acc: 0.9125\n",
      "Epoch 110/1000\n",
      "66413/66413 [==============================] - 8s 123us/step - loss: 0.2596 - acc: 0.9093 - val_loss: 0.2586 - val_acc: 0.9123\n",
      "Epoch 111/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2595 - acc: 0.9093 - val_loss: 0.2583 - val_acc: 0.9126\n",
      "Epoch 112/1000\n",
      "66413/66413 [==============================] - 8s 115us/step - loss: 0.2592 - acc: 0.9091 - val_loss: 0.2601 - val_acc: 0.9130\n",
      "Epoch 113/1000\n",
      "66413/66413 [==============================] - 9s 132us/step - loss: 0.2588 - acc: 0.9093 - val_loss: 0.2610 - val_acc: 0.9126\n",
      "Epoch 114/1000\n",
      "66413/66413 [==============================] - 8s 126us/step - loss: 0.2587 - acc: 0.9090 - val_loss: 0.2606 - val_acc: 0.9130\n",
      "Epoch 115/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2599 - acc: 0.9093 - val_loss: 0.2633 - val_acc: 0.9129\n",
      "Epoch 116/1000\n",
      "66413/66413 [==============================] - 8s 118us/step - loss: 0.2584 - acc: 0.9091 - val_loss: 0.2610 - val_acc: 0.9129\n",
      "Epoch 117/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2581 - acc: 0.9091 - val_loss: 0.2616 - val_acc: 0.9129\n",
      "Epoch 118/1000\n",
      "66413/66413 [==============================] - 8s 116us/step - loss: 0.2588 - acc: 0.9089 - val_loss: 0.2604 - val_acc: 0.9129\n",
      "Epoch 119/1000\n",
      "66413/66413 [==============================] - 8s 119us/step - loss: 0.2587 - acc: 0.9091 - val_loss: 0.2574 - val_acc: 0.9127\n",
      "Epoch 120/1000\n",
      "66413/66413 [==============================] - 8s 117us/step - loss: 0.2589 - acc: 0.9090 - val_loss: 0.2597 - val_acc: 0.9125\n",
      "Epoch 121/1000\n",
      "66413/66413 [==============================] - 29s 431us/step - loss: 0.2580 - acc: 0.9091 - val_loss: 0.2598 - val_acc: 0.9126\n",
      "Epoch 122/1000\n",
      "66413/66413 [==============================] - 31s 460us/step - loss: 0.2579 - acc: 0.9096 - val_loss: 0.2600 - val_acc: 0.9125\n",
      "Epoch 123/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2587 - acc: 0.9093 - val_loss: 0.2677 - val_acc: 0.9129\n",
      "Epoch 124/1000\n",
      "66413/66413 [==============================] - 31s 462us/step - loss: 0.2597 - acc: 0.9094 - val_loss: 0.2607 - val_acc: 0.9127\n",
      "Epoch 125/1000\n",
      "66413/66413 [==============================] - 31s 472us/step - loss: 0.2589 - acc: 0.9091 - val_loss: 0.2642 - val_acc: 0.9129\n",
      "Epoch 126/1000\n",
      "66413/66413 [==============================] - 31s 469us/step - loss: 0.2588 - acc: 0.9091 - val_loss: 0.2617 - val_acc: 0.9123\n",
      "Epoch 127/1000\n",
      "66413/66413 [==============================] - 30s 459us/step - loss: 0.2597 - acc: 0.9093 - val_loss: 0.2606 - val_acc: 0.9127\n",
      "Epoch 128/1000\n",
      "66413/66413 [==============================] - 30s 459us/step - loss: 0.2594 - acc: 0.9089 - val_loss: 0.2605 - val_acc: 0.9127\n",
      "Epoch 129/1000\n",
      "66413/66413 [==============================] - 30s 459us/step - loss: 0.2579 - acc: 0.9094 - val_loss: 0.2620 - val_acc: 0.9126\n",
      "Epoch 130/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2574 - acc: 0.9091 - val_loss: 0.2592 - val_acc: 0.9133\n",
      "Epoch 131/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2582 - acc: 0.9095 - val_loss: 0.2599 - val_acc: 0.9134\n",
      "Epoch 132/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2589 - acc: 0.9089 - val_loss: 0.2595 - val_acc: 0.9133\n",
      "Epoch 133/1000\n",
      "66413/66413 [==============================] - 30s 452us/step - loss: 0.2566 - acc: 0.9095 - val_loss: 0.2670 - val_acc: 0.9126\n",
      "Epoch 134/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2577 - acc: 0.9089 - val_loss: 0.2614 - val_acc: 0.9127\n",
      "Epoch 135/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2587 - acc: 0.9094 - val_loss: 0.2581 - val_acc: 0.9131\n",
      "Epoch 136/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2580 - acc: 0.9096 - val_loss: 0.2639 - val_acc: 0.9129\n",
      "Epoch 137/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2573 - acc: 0.9089 - val_loss: 0.2613 - val_acc: 0.9130\n",
      "Epoch 138/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2577 - acc: 0.9095 - val_loss: 0.2641 - val_acc: 0.9131\n",
      "Epoch 139/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2574 - acc: 0.9092 - val_loss: 0.2652 - val_acc: 0.9125\n",
      "Epoch 140/1000\n",
      "66413/66413 [==============================] - 31s 466us/step - loss: 0.2568 - acc: 0.9100 - val_loss: 0.2648 - val_acc: 0.9127\n",
      "Epoch 141/1000\n",
      "66413/66413 [==============================] - 31s 471us/step - loss: 0.2582 - acc: 0.9090 - val_loss: 0.2637 - val_acc: 0.9131\n",
      "Epoch 142/1000\n",
      "66413/66413 [==============================] - 31s 465us/step - loss: 0.2583 - acc: 0.9090 - val_loss: 0.2592 - val_acc: 0.9126\n",
      "Epoch 143/1000\n",
      "66413/66413 [==============================] - 31s 464us/step - loss: 0.2573 - acc: 0.9091 - val_loss: 0.2591 - val_acc: 0.9131\n",
      "Epoch 144/1000\n",
      "66413/66413 [==============================] - 31s 464us/step - loss: 0.2573 - acc: 0.9091 - val_loss: 0.2597 - val_acc: 0.9127\n",
      "Epoch 145/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2583 - acc: 0.9093 - val_loss: 0.2624 - val_acc: 0.9129\n",
      "Epoch 146/1000\n",
      "66413/66413 [==============================] - 31s 468us/step - loss: 0.2582 - acc: 0.9091 - val_loss: 0.2646 - val_acc: 0.9125\n",
      "Epoch 147/1000\n",
      "66413/66413 [==============================] - 31s 471us/step - loss: 0.2573 - acc: 0.9094 - val_loss: 0.2606 - val_acc: 0.9125\n",
      "Epoch 148/1000\n",
      "66413/66413 [==============================] - 31s 470us/step - loss: 0.2557 - acc: 0.9094 - val_loss: 0.2619 - val_acc: 0.9125\n",
      "Epoch 149/1000\n",
      "66413/66413 [==============================] - 31s 472us/step - loss: 0.2575 - acc: 0.9092 - val_loss: 0.2611 - val_acc: 0.9127\n",
      "Epoch 150/1000\n",
      "66413/66413 [==============================] - 31s 469us/step - loss: 0.2568 - acc: 0.9091 - val_loss: 0.2622 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_2.hdf5\n",
      "Epoch 151/1000\n",
      "66413/66413 [==============================] - 31s 468us/step - loss: 0.2573 - acc: 0.9094 - val_loss: 0.2642 - val_acc: 0.9125\n",
      "Epoch 152/1000\n",
      "66413/66413 [==============================] - 31s 465us/step - loss: 0.2577 - acc: 0.9092 - val_loss: 0.2590 - val_acc: 0.9129\n",
      "Epoch 153/1000\n",
      "66413/66413 [==============================] - 31s 466us/step - loss: 0.2554 - acc: 0.9096 - val_loss: 0.2601 - val_acc: 0.9125\n",
      "Epoch 154/1000\n",
      "66413/66413 [==============================] - 31s 469us/step - loss: 0.2571 - acc: 0.9093 - val_loss: 0.2606 - val_acc: 0.9122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000\n",
      "66413/66413 [==============================] - 31s 464us/step - loss: 0.2554 - acc: 0.9091 - val_loss: 0.2625 - val_acc: 0.9130\n",
      "Epoch 156/1000\n",
      "66413/66413 [==============================] - 31s 468us/step - loss: 0.2562 - acc: 0.9089 - val_loss: 0.2618 - val_acc: 0.9129\n",
      "Epoch 157/1000\n",
      "66413/66413 [==============================] - 31s 469us/step - loss: 0.2557 - acc: 0.9093 - val_loss: 0.2619 - val_acc: 0.9123\n",
      "Epoch 158/1000\n",
      "66413/66413 [==============================] - 30s 455us/step - loss: 0.2560 - acc: 0.9097 - val_loss: 0.2619 - val_acc: 0.9129\n",
      "Epoch 159/1000\n",
      "66413/66413 [==============================] - 31s 468us/step - loss: 0.2564 - acc: 0.9093 - val_loss: 0.2588 - val_acc: 0.9123\n",
      "Epoch 160/1000\n",
      "66413/66413 [==============================] - 31s 462us/step - loss: 0.2575 - acc: 0.9092 - val_loss: 0.2648 - val_acc: 0.9129\n",
      "Epoch 161/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2560 - acc: 0.9096 - val_loss: 0.2590 - val_acc: 0.9129\n",
      "Epoch 162/1000\n",
      "66413/66413 [==============================] - 31s 464us/step - loss: 0.2575 - acc: 0.9092 - val_loss: 0.2609 - val_acc: 0.9133\n",
      "Epoch 163/1000\n",
      "66413/66413 [==============================] - 31s 464us/step - loss: 0.2555 - acc: 0.9091 - val_loss: 0.2610 - val_acc: 0.9126\n",
      "Epoch 164/1000\n",
      "66413/66413 [==============================] - 31s 464us/step - loss: 0.2559 - acc: 0.9096 - val_loss: 0.2634 - val_acc: 0.9131\n",
      "Epoch 165/1000\n",
      "66413/66413 [==============================] - 31s 465us/step - loss: 0.2567 - acc: 0.9093 - val_loss: 0.2590 - val_acc: 0.9126\n",
      "Epoch 166/1000\n",
      "66413/66413 [==============================] - 31s 460us/step - loss: 0.2546 - acc: 0.9094 - val_loss: 0.2586 - val_acc: 0.9129\n",
      "Epoch 167/1000\n",
      "66413/66413 [==============================] - 31s 464us/step - loss: 0.2555 - acc: 0.9091 - val_loss: 0.2615 - val_acc: 0.9127\n",
      "Epoch 168/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2544 - acc: 0.9097 - val_loss: 0.2620 - val_acc: 0.9129\n",
      "Epoch 169/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2557 - acc: 0.9096 - val_loss: 0.2612 - val_acc: 0.9125\n",
      "AUC: 0.777688\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.3084 - acc: 0.9071 - val_loss: 0.3218 - val_acc: 0.9092\n",
      "Epoch 2/1000\n",
      "66413/66413 [==============================] - 30s 450us/step - loss: 0.2954 - acc: 0.9094 - val_loss: 0.3013 - val_acc: 0.9092\n",
      "Epoch 3/1000\n",
      "66413/66413 [==============================] - 30s 449us/step - loss: 0.2923 - acc: 0.9094 - val_loss: 0.2958 - val_acc: 0.9092\n",
      "Epoch 4/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2884 - acc: 0.9094 - val_loss: 0.3056 - val_acc: 0.9092\n",
      "Epoch 5/1000\n",
      "66413/66413 [==============================] - 30s 449us/step - loss: 0.2868 - acc: 0.9094 - val_loss: 0.3121 - val_acc: 0.9092\n",
      "Epoch 6/1000\n",
      "66413/66413 [==============================] - 30s 452us/step - loss: 0.2848 - acc: 0.9094 - val_loss: 0.2850 - val_acc: 0.9092\n",
      "Epoch 7/1000\n",
      "66413/66413 [==============================] - 31s 459us/step - loss: 0.2837 - acc: 0.9094 - val_loss: 0.2790 - val_acc: 0.9092\n",
      "Epoch 8/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2814 - acc: 0.9094 - val_loss: 0.2875 - val_acc: 0.9091\n",
      "Epoch 9/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2805 - acc: 0.9094 - val_loss: 0.2975 - val_acc: 0.9092\n",
      "Epoch 10/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2795 - acc: 0.9093 - val_loss: 0.2775 - val_acc: 0.9092\n",
      "Epoch 11/1000\n",
      "66413/66413 [==============================] - 31s 461us/step - loss: 0.2780 - acc: 0.9093 - val_loss: 0.2763 - val_acc: 0.9092\n",
      "Epoch 12/1000\n",
      "66413/66413 [==============================] - 30s 452us/step - loss: 0.2773 - acc: 0.9093 - val_loss: 0.2777 - val_acc: 0.9095\n",
      "Epoch 13/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2776 - acc: 0.9094 - val_loss: 0.2770 - val_acc: 0.9092\n",
      "Epoch 14/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2764 - acc: 0.9092 - val_loss: 0.2866 - val_acc: 0.9093\n",
      "Epoch 15/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2751 - acc: 0.9093 - val_loss: 0.2919 - val_acc: 0.9092\n",
      "Epoch 16/1000\n",
      "66413/66413 [==============================] - 30s 452us/step - loss: 0.2742 - acc: 0.9092 - val_loss: 0.2776 - val_acc: 0.9092\n",
      "Epoch 17/1000\n",
      "66413/66413 [==============================] - 30s 455us/step - loss: 0.2743 - acc: 0.9093 - val_loss: 0.2707 - val_acc: 0.9093\n",
      "Epoch 18/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2743 - acc: 0.9094 - val_loss: 0.2807 - val_acc: 0.9091\n",
      "Epoch 19/1000\n",
      "66413/66413 [==============================] - 30s 455us/step - loss: 0.2741 - acc: 0.9094 - val_loss: 0.2785 - val_acc: 0.9092\n",
      "Epoch 20/1000\n",
      "66413/66413 [==============================] - 30s 456us/step - loss: 0.2734 - acc: 0.9093 - val_loss: 0.2710 - val_acc: 0.9093\n",
      "Epoch 21/1000\n",
      "66413/66413 [==============================] - 32s 475us/step - loss: 0.2730 - acc: 0.9094 - val_loss: 0.2746 - val_acc: 0.9092\n",
      "Epoch 22/1000\n",
      "66413/66413 [==============================] - 31s 466us/step - loss: 0.2719 - acc: 0.9091 - val_loss: 0.2700 - val_acc: 0.9092\n",
      "Epoch 23/1000\n",
      "66413/66413 [==============================] - 31s 469us/step - loss: 0.2719 - acc: 0.9094 - val_loss: 0.2746 - val_acc: 0.9095\n",
      "Epoch 24/1000\n",
      "66413/66413 [==============================] - 31s 469us/step - loss: 0.2721 - acc: 0.9092 - val_loss: 0.2778 - val_acc: 0.9098\n",
      "Epoch 25/1000\n",
      "66413/66413 [==============================] - 30s 457us/step - loss: 0.2711 - acc: 0.9092 - val_loss: 0.2767 - val_acc: 0.9093\n",
      "Epoch 26/1000\n",
      "66413/66413 [==============================] - 30s 456us/step - loss: 0.2700 - acc: 0.9095 - val_loss: 0.2725 - val_acc: 0.9099\n",
      "Epoch 27/1000\n",
      "66413/66413 [==============================] - 30s 455us/step - loss: 0.2700 - acc: 0.9091 - val_loss: 0.2829 - val_acc: 0.9095\n",
      "Epoch 28/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2699 - acc: 0.9095 - val_loss: 0.2763 - val_acc: 0.9100\n",
      "Epoch 29/1000\n",
      "66413/66413 [==============================] - 30s 456us/step - loss: 0.2701 - acc: 0.9092 - val_loss: 0.2681 - val_acc: 0.9095\n",
      "Epoch 30/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2699 - acc: 0.9093 - val_loss: 0.2803 - val_acc: 0.9102\n",
      "Epoch 31/1000\n",
      "66413/66413 [==============================] - 30s 458us/step - loss: 0.2696 - acc: 0.9092 - val_loss: 0.2720 - val_acc: 0.9099\n",
      "Epoch 32/1000\n",
      "66413/66413 [==============================] - 30s 459us/step - loss: 0.2686 - acc: 0.9097 - val_loss: 0.2765 - val_acc: 0.9098\n",
      "Epoch 33/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2700 - acc: 0.9091 - val_loss: 0.2708 - val_acc: 0.9096\n",
      "Epoch 34/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2678 - acc: 0.9093 - val_loss: 0.2785 - val_acc: 0.9099\n",
      "Epoch 35/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2680 - acc: 0.9094 - val_loss: 0.2768 - val_acc: 0.9100\n",
      "Epoch 36/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2678 - acc: 0.9092 - val_loss: 0.2830 - val_acc: 0.9104\n",
      "Epoch 37/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2678 - acc: 0.9093 - val_loss: 0.2762 - val_acc: 0.9102\n",
      "Epoch 38/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2676 - acc: 0.9092 - val_loss: 0.2771 - val_acc: 0.9104\n",
      "Epoch 39/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2678 - acc: 0.9094 - val_loss: 0.2735 - val_acc: 0.9102\n",
      "Epoch 40/1000\n",
      "66413/66413 [==============================] - 31s 465us/step - loss: 0.2673 - acc: 0.9088 - val_loss: 0.2741 - val_acc: 0.9095\n",
      "Epoch 41/1000\n",
      "66413/66413 [==============================] - 30s 448us/step - loss: 0.2669 - acc: 0.9093 - val_loss: 0.2801 - val_acc: 0.9103\n",
      "Epoch 42/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2672 - acc: 0.9091 - val_loss: 0.2742 - val_acc: 0.9099\n",
      "Epoch 43/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2665 - acc: 0.9094 - val_loss: 0.2753 - val_acc: 0.9100\n",
      "Epoch 44/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2668 - acc: 0.9094 - val_loss: 0.2717 - val_acc: 0.9098\n",
      "Epoch 45/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2655 - acc: 0.9092 - val_loss: 0.2718 - val_acc: 0.9093\n",
      "Epoch 46/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2664 - acc: 0.9092 - val_loss: 0.2739 - val_acc: 0.9099\n",
      "Epoch 47/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2660 - acc: 0.9095 - val_loss: 0.2737 - val_acc: 0.9103\n",
      "Epoch 48/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2659 - acc: 0.9093 - val_loss: 0.2789 - val_acc: 0.9102\n",
      "Epoch 49/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2653 - acc: 0.9094 - val_loss: 0.2753 - val_acc: 0.9104\n",
      "Epoch 50/1000\n",
      "66413/66413 [==============================] - 30s 449us/step - loss: 0.2653 - acc: 0.9091 - val_loss: 0.2719 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_3.hdf5\n",
      "Epoch 51/1000\n",
      "66413/66413 [==============================] - 28s 422us/step - loss: 0.2661 - acc: 0.9094 - val_loss: 0.2695 - val_acc: 0.9100\n",
      "Epoch 52/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2663 - acc: 0.9092 - val_loss: 0.2788 - val_acc: 0.9100\n",
      "Epoch 53/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2654 - acc: 0.9093 - val_loss: 0.2726 - val_acc: 0.9103\n",
      "Epoch 54/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2650 - acc: 0.9092 - val_loss: 0.2754 - val_acc: 0.9100\n",
      "Epoch 55/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2649 - acc: 0.9091 - val_loss: 0.2728 - val_acc: 0.9098\n",
      "Epoch 56/1000\n",
      "66413/66413 [==============================] - 29s 440us/step - loss: 0.2641 - acc: 0.9091 - val_loss: 0.2676 - val_acc: 0.9098\n",
      "Epoch 57/1000\n",
      "66413/66413 [==============================] - 29s 436us/step - loss: 0.2641 - acc: 0.9094 - val_loss: 0.2745 - val_acc: 0.9100\n",
      "Epoch 58/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2635 - acc: 0.9091 - val_loss: 0.2684 - val_acc: 0.9100\n",
      "Epoch 59/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2635 - acc: 0.9089 - val_loss: 0.2717 - val_acc: 0.9099\n",
      "Epoch 60/1000\n",
      "66413/66413 [==============================] - 31s 462us/step - loss: 0.2642 - acc: 0.9091 - val_loss: 0.2748 - val_acc: 0.9098\n",
      "Epoch 61/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2632 - acc: 0.9091 - val_loss: 0.2732 - val_acc: 0.9099\n",
      "Epoch 62/1000\n",
      "66413/66413 [==============================] - 30s 452us/step - loss: 0.2634 - acc: 0.9095 - val_loss: 0.2707 - val_acc: 0.9099\n",
      "Epoch 63/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2646 - acc: 0.9094 - val_loss: 0.2712 - val_acc: 0.9100\n",
      "Epoch 64/1000\n",
      "66413/66413 [==============================] - 30s 456us/step - loss: 0.2630 - acc: 0.9090 - val_loss: 0.2698 - val_acc: 0.9100\n",
      "Epoch 65/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2638 - acc: 0.9091 - val_loss: 0.2685 - val_acc: 0.9099\n",
      "Epoch 66/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2629 - acc: 0.9089 - val_loss: 0.2759 - val_acc: 0.9099\n",
      "Epoch 67/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2630 - acc: 0.9093 - val_loss: 0.2727 - val_acc: 0.9095\n",
      "Epoch 68/1000\n",
      "66413/66413 [==============================] - 30s 450us/step - loss: 0.2641 - acc: 0.9092 - val_loss: 0.2695 - val_acc: 0.9096\n",
      "Epoch 69/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2631 - acc: 0.9094 - val_loss: 0.2709 - val_acc: 0.9098\n",
      "Epoch 70/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2629 - acc: 0.9091 - val_loss: 0.2767 - val_acc: 0.9099\n",
      "Epoch 71/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2627 - acc: 0.9094 - val_loss: 0.2786 - val_acc: 0.9095\n",
      "Epoch 72/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2630 - acc: 0.9094 - val_loss: 0.2778 - val_acc: 0.9095\n",
      "Epoch 73/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2620 - acc: 0.9092 - val_loss: 0.2736 - val_acc: 0.9099\n",
      "Epoch 74/1000\n",
      "66413/66413 [==============================] - 30s 448us/step - loss: 0.2611 - acc: 0.9093 - val_loss: 0.2693 - val_acc: 0.9095\n",
      "Epoch 75/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2611 - acc: 0.9091 - val_loss: 0.2669 - val_acc: 0.9092\n",
      "Epoch 76/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2621 - acc: 0.9093 - val_loss: 0.2670 - val_acc: 0.9095\n",
      "Epoch 77/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2616 - acc: 0.9097 - val_loss: 0.2710 - val_acc: 0.9095\n",
      "Epoch 78/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2626 - acc: 0.9094 - val_loss: 0.2692 - val_acc: 0.9096\n",
      "Epoch 79/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2616 - acc: 0.9094 - val_loss: 0.2756 - val_acc: 0.9099\n",
      "Epoch 80/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2607 - acc: 0.9094 - val_loss: 0.2699 - val_acc: 0.9095\n",
      "Epoch 81/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2608 - acc: 0.9094 - val_loss: 0.2720 - val_acc: 0.9093\n",
      "Epoch 82/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2613 - acc: 0.9092 - val_loss: 0.2708 - val_acc: 0.9093\n",
      "Epoch 83/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2609 - acc: 0.9093 - val_loss: 0.2711 - val_acc: 0.9092\n",
      "Epoch 84/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2614 - acc: 0.9089 - val_loss: 0.2711 - val_acc: 0.9092\n",
      "Epoch 85/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2622 - acc: 0.9098 - val_loss: 0.2660 - val_acc: 0.9095\n",
      "Epoch 86/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2605 - acc: 0.9096 - val_loss: 0.2696 - val_acc: 0.9095\n",
      "Epoch 87/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2606 - acc: 0.9093 - val_loss: 0.2722 - val_acc: 0.9096\n",
      "Epoch 88/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2604 - acc: 0.9095 - val_loss: 0.2732 - val_acc: 0.9096\n",
      "Epoch 89/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2603 - acc: 0.9092 - val_loss: 0.2673 - val_acc: 0.9096\n",
      "Epoch 90/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2605 - acc: 0.9090 - val_loss: 0.2694 - val_acc: 0.9098\n",
      "Epoch 91/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2611 - acc: 0.9096 - val_loss: 0.2679 - val_acc: 0.9095\n",
      "Epoch 92/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2607 - acc: 0.9091 - val_loss: 0.2697 - val_acc: 0.9096\n",
      "Epoch 93/1000\n",
      "66413/66413 [==============================] - 30s 448us/step - loss: 0.2611 - acc: 0.9095 - val_loss: 0.2760 - val_acc: 0.9095\n",
      "Epoch 94/1000\n",
      "66413/66413 [==============================] - 30s 448us/step - loss: 0.2589 - acc: 0.9093 - val_loss: 0.2665 - val_acc: 0.9092\n",
      "Epoch 95/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2600 - acc: 0.9098 - val_loss: 0.2725 - val_acc: 0.9100\n",
      "Epoch 96/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2594 - acc: 0.9095 - val_loss: 0.2657 - val_acc: 0.9098\n",
      "Epoch 97/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2584 - acc: 0.9092 - val_loss: 0.2705 - val_acc: 0.9095\n",
      "Epoch 98/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2606 - acc: 0.9096 - val_loss: 0.2693 - val_acc: 0.9096\n",
      "Epoch 99/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2603 - acc: 0.9089 - val_loss: 0.2727 - val_acc: 0.9092\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2592 - acc: 0.9089 - val_loss: 0.2710 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_3.hdf5\n",
      "Epoch 101/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2594 - acc: 0.9091 - val_loss: 0.2679 - val_acc: 0.9095\n",
      "Epoch 102/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2585 - acc: 0.9094 - val_loss: 0.2717 - val_acc: 0.9096\n",
      "Epoch 103/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2588 - acc: 0.9092 - val_loss: 0.2765 - val_acc: 0.9102\n",
      "Epoch 104/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2596 - acc: 0.9096 - val_loss: 0.2696 - val_acc: 0.9100\n",
      "Epoch 105/1000\n",
      "66413/66413 [==============================] - 28s 422us/step - loss: 0.2566 - acc: 0.9094 - val_loss: 0.2716 - val_acc: 0.9095\n",
      "Epoch 106/1000\n",
      "66413/66413 [==============================] - 29s 440us/step - loss: 0.2596 - acc: 0.9098 - val_loss: 0.2712 - val_acc: 0.9095\n",
      "Epoch 107/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2592 - acc: 0.9096 - val_loss: 0.2732 - val_acc: 0.9096\n",
      "Epoch 108/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2577 - acc: 0.9094 - val_loss: 0.2693 - val_acc: 0.9096\n",
      "Epoch 109/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2588 - acc: 0.9094 - val_loss: 0.2725 - val_acc: 0.9100\n",
      "Epoch 110/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2582 - acc: 0.9091 - val_loss: 0.2771 - val_acc: 0.9096\n",
      "Epoch 111/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2596 - acc: 0.9093 - val_loss: 0.2724 - val_acc: 0.9095\n",
      "Epoch 112/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2571 - acc: 0.9093 - val_loss: 0.2680 - val_acc: 0.9095\n",
      "Epoch 113/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2586 - acc: 0.9095 - val_loss: 0.2667 - val_acc: 0.9096\n",
      "Epoch 114/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2592 - acc: 0.9099 - val_loss: 0.2679 - val_acc: 0.9095\n",
      "Epoch 115/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2593 - acc: 0.9101 - val_loss: 0.2675 - val_acc: 0.9092\n",
      "Epoch 116/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2586 - acc: 0.9094 - val_loss: 0.2747 - val_acc: 0.9095\n",
      "Epoch 117/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2578 - acc: 0.9097 - val_loss: 0.2711 - val_acc: 0.9095\n",
      "Epoch 118/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2582 - acc: 0.9095 - val_loss: 0.2725 - val_acc: 0.9098\n",
      "Epoch 119/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2580 - acc: 0.9095 - val_loss: 0.2701 - val_acc: 0.9093\n",
      "Epoch 120/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2579 - acc: 0.9092 - val_loss: 0.2703 - val_acc: 0.9095\n",
      "Epoch 121/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2578 - acc: 0.9094 - val_loss: 0.2713 - val_acc: 0.9093\n",
      "Epoch 122/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2580 - acc: 0.9095 - val_loss: 0.2702 - val_acc: 0.9096\n",
      "Epoch 123/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2578 - acc: 0.9095 - val_loss: 0.2662 - val_acc: 0.9095\n",
      "Epoch 124/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2571 - acc: 0.9094 - val_loss: 0.2713 - val_acc: 0.9095\n",
      "Epoch 125/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2567 - acc: 0.9097 - val_loss: 0.2696 - val_acc: 0.9096\n",
      "Epoch 126/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2562 - acc: 0.9096 - val_loss: 0.2695 - val_acc: 0.9098\n",
      "Epoch 127/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2559 - acc: 0.9099 - val_loss: 0.2706 - val_acc: 0.9100\n",
      "Epoch 128/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2576 - acc: 0.9096 - val_loss: 0.2685 - val_acc: 0.9102\n",
      "Epoch 129/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2578 - acc: 0.9096 - val_loss: 0.2724 - val_acc: 0.9099\n",
      "Epoch 130/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2565 - acc: 0.9096 - val_loss: 0.2708 - val_acc: 0.9098\n",
      "Epoch 131/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2562 - acc: 0.9095 - val_loss: 0.2650 - val_acc: 0.9093\n",
      "Epoch 132/1000\n",
      "66413/66413 [==============================] - 30s 456us/step - loss: 0.2564 - acc: 0.9100 - val_loss: 0.2709 - val_acc: 0.9100\n",
      "Epoch 133/1000\n",
      "66413/66413 [==============================] - 31s 465us/step - loss: 0.2563 - acc: 0.9099 - val_loss: 0.2674 - val_acc: 0.9092\n",
      "Epoch 134/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2572 - acc: 0.9089 - val_loss: 0.2712 - val_acc: 0.9095\n",
      "Epoch 135/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2562 - acc: 0.9096 - val_loss: 0.2674 - val_acc: 0.9098\n",
      "Epoch 136/1000\n",
      "66413/66413 [==============================] - 30s 450us/step - loss: 0.2560 - acc: 0.9099 - val_loss: 0.2699 - val_acc: 0.9092\n",
      "Epoch 137/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2558 - acc: 0.9096 - val_loss: 0.2657 - val_acc: 0.9096\n",
      "Epoch 138/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2560 - acc: 0.9096 - val_loss: 0.2662 - val_acc: 0.9098\n",
      "Epoch 139/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2570 - acc: 0.9095 - val_loss: 0.2664 - val_acc: 0.9098\n",
      "Epoch 140/1000\n",
      "66413/66413 [==============================] - 30s 452us/step - loss: 0.2560 - acc: 0.9095 - val_loss: 0.2714 - val_acc: 0.9098\n",
      "Epoch 141/1000\n",
      "66413/66413 [==============================] - 31s 468us/step - loss: 0.2559 - acc: 0.9093 - val_loss: 0.2711 - val_acc: 0.9093\n",
      "Epoch 142/1000\n",
      "66413/66413 [==============================] - 30s 456us/step - loss: 0.2548 - acc: 0.9102 - val_loss: 0.2683 - val_acc: 0.9098\n",
      "Epoch 143/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2568 - acc: 0.9091 - val_loss: 0.2675 - val_acc: 0.9093\n",
      "Epoch 144/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2547 - acc: 0.9099 - val_loss: 0.2661 - val_acc: 0.9092\n",
      "Epoch 145/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2571 - acc: 0.9092 - val_loss: 0.2714 - val_acc: 0.9095\n",
      "Epoch 146/1000\n",
      "66413/66413 [==============================] - 31s 463us/step - loss: 0.2554 - acc: 0.9099 - val_loss: 0.2687 - val_acc: 0.9093\n",
      "Epoch 147/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2560 - acc: 0.9097 - val_loss: 0.2687 - val_acc: 0.9095\n",
      "Epoch 148/1000\n",
      "66413/66413 [==============================] - 30s 448us/step - loss: 0.2562 - acc: 0.9096 - val_loss: 0.2725 - val_acc: 0.9093\n",
      "Epoch 149/1000\n",
      "66413/66413 [==============================] - 30s 455us/step - loss: 0.2549 - acc: 0.9095 - val_loss: 0.2693 - val_acc: 0.9095\n",
      "Epoch 150/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2549 - acc: 0.9098 - val_loss: 0.2663 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_3.hdf5\n",
      "Epoch 151/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2546 - acc: 0.9097 - val_loss: 0.2692 - val_acc: 0.9095\n",
      "Epoch 152/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2542 - acc: 0.9096 - val_loss: 0.2687 - val_acc: 0.9092\n",
      "Epoch 153/1000\n",
      "66413/66413 [==============================] - 30s 454us/step - loss: 0.2548 - acc: 0.9098 - val_loss: 0.2730 - val_acc: 0.9091\n",
      "Epoch 154/1000\n",
      "66413/66413 [==============================] - 31s 461us/step - loss: 0.2554 - acc: 0.9098 - val_loss: 0.2663 - val_acc: 0.9093\n",
      "Epoch 155/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2543 - acc: 0.9096 - val_loss: 0.2690 - val_acc: 0.9095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2554 - acc: 0.9098 - val_loss: 0.2668 - val_acc: 0.9095\n",
      "Epoch 157/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2544 - acc: 0.9097 - val_loss: 0.2742 - val_acc: 0.9092\n",
      "Epoch 158/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2562 - acc: 0.9095 - val_loss: 0.2712 - val_acc: 0.9095\n",
      "Epoch 159/1000\n",
      "66413/66413 [==============================] - 29s 434us/step - loss: 0.2540 - acc: 0.9095 - val_loss: 0.2713 - val_acc: 0.9093\n",
      "Epoch 160/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2551 - acc: 0.9094 - val_loss: 0.2670 - val_acc: 0.9095\n",
      "Epoch 161/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2554 - acc: 0.9099 - val_loss: 0.2672 - val_acc: 0.9098\n",
      "Epoch 162/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2535 - acc: 0.9098 - val_loss: 0.2698 - val_acc: 0.9099\n",
      "Epoch 163/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2544 - acc: 0.9094 - val_loss: 0.2683 - val_acc: 0.9093\n",
      "Epoch 164/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2535 - acc: 0.9099 - val_loss: 0.2736 - val_acc: 0.9102\n",
      "Epoch 165/1000\n",
      "66413/66413 [==============================] - 30s 448us/step - loss: 0.2549 - acc: 0.9099 - val_loss: 0.2678 - val_acc: 0.9100\n",
      "Epoch 166/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2542 - acc: 0.9092 - val_loss: 0.2671 - val_acc: 0.9100\n",
      "Epoch 167/1000\n",
      "66413/66413 [==============================] - 30s 455us/step - loss: 0.2534 - acc: 0.9100 - val_loss: 0.2681 - val_acc: 0.9099\n",
      "Epoch 168/1000\n",
      "66413/66413 [==============================] - 34s 507us/step - loss: 0.2539 - acc: 0.9096 - val_loss: 0.2678 - val_acc: 0.9098\n",
      "Epoch 169/1000\n",
      "66413/66413 [==============================] - 30s 450us/step - loss: 0.2538 - acc: 0.9096 - val_loss: 0.2721 - val_acc: 0.9093\n",
      "Epoch 170/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2525 - acc: 0.9094 - val_loss: 0.2692 - val_acc: 0.9098\n",
      "Epoch 171/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2531 - acc: 0.9096 - val_loss: 0.2665 - val_acc: 0.9098\n",
      "Epoch 172/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2544 - acc: 0.9097 - val_loss: 0.2710 - val_acc: 0.9098\n",
      "Epoch 173/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2532 - acc: 0.9098 - val_loss: 0.2683 - val_acc: 0.9093\n",
      "Epoch 174/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2542 - acc: 0.9098 - val_loss: 0.2689 - val_acc: 0.9099\n",
      "Epoch 175/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2541 - acc: 0.9096 - val_loss: 0.2724 - val_acc: 0.9099\n",
      "Epoch 176/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2538 - acc: 0.9096 - val_loss: 0.2697 - val_acc: 0.9098\n",
      "Epoch 177/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2543 - acc: 0.9099 - val_loss: 0.2704 - val_acc: 0.9095\n",
      "Epoch 178/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2528 - acc: 0.9095 - val_loss: 0.2675 - val_acc: 0.9092\n",
      "Epoch 179/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2534 - acc: 0.9093 - val_loss: 0.2679 - val_acc: 0.9096\n",
      "Epoch 180/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2520 - acc: 0.9098 - val_loss: 0.2642 - val_acc: 0.9093\n",
      "Epoch 181/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2533 - acc: 0.9097 - val_loss: 0.2675 - val_acc: 0.9092\n",
      "Epoch 182/1000\n",
      "66413/66413 [==============================] - 30s 451us/step - loss: 0.2538 - acc: 0.9100 - val_loss: 0.2683 - val_acc: 0.9093\n",
      "Epoch 183/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2538 - acc: 0.9097 - val_loss: 0.2673 - val_acc: 0.9096\n",
      "Epoch 184/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2541 - acc: 0.9094 - val_loss: 0.2662 - val_acc: 0.9095\n",
      "Epoch 185/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2524 - acc: 0.9098 - val_loss: 0.2671 - val_acc: 0.9099\n",
      "Epoch 186/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2527 - acc: 0.9103 - val_loss: 0.2657 - val_acc: 0.9100\n",
      "Epoch 187/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2527 - acc: 0.9096 - val_loss: 0.2668 - val_acc: 0.9098\n",
      "Epoch 188/1000\n",
      "66413/66413 [==============================] - 30s 453us/step - loss: 0.2512 - acc: 0.9098 - val_loss: 0.2675 - val_acc: 0.9092\n",
      "Epoch 189/1000\n",
      "66413/66413 [==============================] - 30s 456us/step - loss: 0.2535 - acc: 0.9090 - val_loss: 0.2669 - val_acc: 0.9095\n",
      "Epoch 190/1000\n",
      "66413/66413 [==============================] - 30s 452us/step - loss: 0.2528 - acc: 0.9104 - val_loss: 0.2665 - val_acc: 0.9095\n",
      "Epoch 191/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2527 - acc: 0.9099 - val_loss: 0.2671 - val_acc: 0.9095\n",
      "Epoch 192/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2533 - acc: 0.9101 - val_loss: 0.2674 - val_acc: 0.9100\n",
      "Epoch 193/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2535 - acc: 0.9100 - val_loss: 0.2675 - val_acc: 0.9096\n",
      "Epoch 194/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2520 - acc: 0.9100 - val_loss: 0.2635 - val_acc: 0.9095\n",
      "Epoch 195/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2519 - acc: 0.9097 - val_loss: 0.2688 - val_acc: 0.9093\n",
      "Epoch 196/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2508 - acc: 0.9098 - val_loss: 0.2684 - val_acc: 0.9096\n",
      "Epoch 197/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2507 - acc: 0.9098 - val_loss: 0.2683 - val_acc: 0.9093\n",
      "Epoch 198/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2524 - acc: 0.9096 - val_loss: 0.2675 - val_acc: 0.9098\n",
      "Epoch 199/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2521 - acc: 0.9094 - val_loss: 0.2678 - val_acc: 0.9093\n",
      "Epoch 200/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2517 - acc: 0.9101 - val_loss: 0.2674 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00200: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_3.hdf5\n",
      "Epoch 201/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2532 - acc: 0.9094 - val_loss: 0.2713 - val_acc: 0.9099\n",
      "Epoch 202/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2512 - acc: 0.9102 - val_loss: 0.2663 - val_acc: 0.9098\n",
      "Epoch 203/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2523 - acc: 0.9096 - val_loss: 0.2701 - val_acc: 0.9095\n",
      "Epoch 204/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2510 - acc: 0.9094 - val_loss: 0.2681 - val_acc: 0.9093\n",
      "Epoch 205/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2520 - acc: 0.9097 - val_loss: 0.2700 - val_acc: 0.9096\n",
      "Epoch 206/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2516 - acc: 0.9094 - val_loss: 0.2686 - val_acc: 0.9093\n",
      "Epoch 207/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2507 - acc: 0.9098 - val_loss: 0.2673 - val_acc: 0.9092\n",
      "Epoch 208/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2518 - acc: 0.9095 - val_loss: 0.2673 - val_acc: 0.9099\n",
      "Epoch 209/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2518 - acc: 0.9095 - val_loss: 0.2676 - val_acc: 0.9096\n",
      "Epoch 210/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2506 - acc: 0.9097 - val_loss: 0.2687 - val_acc: 0.9099\n",
      "Epoch 211/1000\n",
      "66413/66413 [==============================] - 30s 447us/step - loss: 0.2515 - acc: 0.9101 - val_loss: 0.2672 - val_acc: 0.9095\n",
      "Epoch 212/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2510 - acc: 0.9100 - val_loss: 0.2675 - val_acc: 0.9098\n",
      "Epoch 213/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2507 - acc: 0.9104 - val_loss: 0.2661 - val_acc: 0.9096\n",
      "Epoch 214/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2510 - acc: 0.9092 - val_loss: 0.2672 - val_acc: 0.9095\n",
      "Epoch 215/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2501 - acc: 0.9103 - val_loss: 0.2674 - val_acc: 0.9096\n",
      "Epoch 216/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2511 - acc: 0.9094 - val_loss: 0.2662 - val_acc: 0.9096\n",
      "Epoch 217/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2507 - acc: 0.9104 - val_loss: 0.2692 - val_acc: 0.9092\n",
      "Epoch 218/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2512 - acc: 0.9101 - val_loss: 0.2660 - val_acc: 0.9096\n",
      "Epoch 219/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2499 - acc: 0.9099 - val_loss: 0.2677 - val_acc: 0.9096\n",
      "Epoch 220/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2504 - acc: 0.9103 - val_loss: 0.2658 - val_acc: 0.9095\n",
      "Epoch 221/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2497 - acc: 0.9098 - val_loss: 0.2657 - val_acc: 0.9099\n",
      "Epoch 222/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2514 - acc: 0.9099 - val_loss: 0.2667 - val_acc: 0.9098\n",
      "Epoch 223/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2519 - acc: 0.9102 - val_loss: 0.2648 - val_acc: 0.9099\n",
      "Epoch 224/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2513 - acc: 0.9103 - val_loss: 0.2690 - val_acc: 0.9098\n",
      "Epoch 225/1000\n",
      "66413/66413 [==============================] - 30s 444us/step - loss: 0.2510 - acc: 0.9104 - val_loss: 0.2665 - val_acc: 0.9095\n",
      "Epoch 226/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2502 - acc: 0.9100 - val_loss: 0.2696 - val_acc: 0.9092\n",
      "Epoch 227/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2500 - acc: 0.9105 - val_loss: 0.2662 - val_acc: 0.9099\n",
      "Epoch 228/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2487 - acc: 0.9102 - val_loss: 0.2671 - val_acc: 0.9099\n",
      "Epoch 229/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2518 - acc: 0.9102 - val_loss: 0.2664 - val_acc: 0.9098\n",
      "Epoch 230/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2492 - acc: 0.9104 - val_loss: 0.2659 - val_acc: 0.9096\n",
      "Epoch 231/1000\n",
      "66413/66413 [==============================] - 29s 436us/step - loss: 0.2514 - acc: 0.9100 - val_loss: 0.2662 - val_acc: 0.9100\n",
      "Epoch 232/1000\n",
      "66413/66413 [==============================] - 26s 384us/step - loss: 0.2494 - acc: 0.9102 - val_loss: 0.2692 - val_acc: 0.9099\n",
      "Epoch 233/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2497 - acc: 0.9100 - val_loss: 0.2677 - val_acc: 0.9098\n",
      "Epoch 234/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2506 - acc: 0.9099 - val_loss: 0.2656 - val_acc: 0.9099\n",
      "Epoch 235/1000\n",
      "66413/66413 [==============================] - 30s 448us/step - loss: 0.2505 - acc: 0.9107 - val_loss: 0.2723 - val_acc: 0.9099\n",
      "Epoch 236/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2489 - acc: 0.9103 - val_loss: 0.2678 - val_acc: 0.9103\n",
      "Epoch 237/1000\n",
      "66413/66413 [==============================] - 29s 444us/step - loss: 0.2505 - acc: 0.9104 - val_loss: 0.2642 - val_acc: 0.9099\n",
      "Epoch 238/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2503 - acc: 0.9101 - val_loss: 0.2683 - val_acc: 0.9096\n",
      "Epoch 239/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2495 - acc: 0.9103 - val_loss: 0.2676 - val_acc: 0.9096\n",
      "Epoch 240/1000\n",
      "66413/66413 [==============================] - 29s 441us/step - loss: 0.2486 - acc: 0.9102 - val_loss: 0.2661 - val_acc: 0.9099\n",
      "Epoch 241/1000\n",
      "66413/66413 [==============================] - 29s 442us/step - loss: 0.2501 - acc: 0.9104 - val_loss: 0.2678 - val_acc: 0.9096\n",
      "Epoch 242/1000\n",
      "66413/66413 [==============================] - 30s 446us/step - loss: 0.2494 - acc: 0.9102 - val_loss: 0.2688 - val_acc: 0.9096\n",
      "Epoch 243/1000\n",
      "66413/66413 [==============================] - 29s 443us/step - loss: 0.2499 - acc: 0.9101 - val_loss: 0.2671 - val_acc: 0.9096\n",
      "Epoch 244/1000\n",
      "66413/66413 [==============================] - 30s 445us/step - loss: 0.2490 - acc: 0.9102 - val_loss: 0.2695 - val_acc: 0.9096\n",
      "AUC: 0.774448\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 34s 508us/step - loss: 0.3065 - acc: 0.9072 - val_loss: 0.3125 - val_acc: 0.9053\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 30s 448us/step - loss: 0.2954 - acc: 0.9098 - val_loss: 0.3084 - val_acc: 0.9053\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2927 - acc: 0.9098 - val_loss: 0.2963 - val_acc: 0.9053\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2890 - acc: 0.9098 - val_loss: 0.2933 - val_acc: 0.9053\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2865 - acc: 0.9099 - val_loss: 0.2911 - val_acc: 0.9054\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2847 - acc: 0.9098 - val_loss: 0.2906 - val_acc: 0.9053\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2825 - acc: 0.9098 - val_loss: 0.2814 - val_acc: 0.9053\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2816 - acc: 0.9098 - val_loss: 0.2881 - val_acc: 0.9053\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2803 - acc: 0.9098 - val_loss: 0.2795 - val_acc: 0.9053\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2788 - acc: 0.9098 - val_loss: 0.2831 - val_acc: 0.9055\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2789 - acc: 0.9098 - val_loss: 0.2884 - val_acc: 0.9051\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 30s 454us/step - loss: 0.2776 - acc: 0.9098 - val_loss: 0.2820 - val_acc: 0.9051\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2769 - acc: 0.9099 - val_loss: 0.2816 - val_acc: 0.9053\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2770 - acc: 0.9098 - val_loss: 0.2796 - val_acc: 0.9053\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2762 - acc: 0.9097 - val_loss: 0.2762 - val_acc: 0.9058\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2741 - acc: 0.9098 - val_loss: 0.2768 - val_acc: 0.9051\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2743 - acc: 0.9097 - val_loss: 0.2780 - val_acc: 0.9050\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2738 - acc: 0.9098 - val_loss: 0.2742 - val_acc: 0.9053\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2748 - acc: 0.9097 - val_loss: 0.2741 - val_acc: 0.9053\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2727 - acc: 0.9097 - val_loss: 0.2709 - val_acc: 0.9053\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 30s 456us/step - loss: 0.2731 - acc: 0.9096 - val_loss: 0.2745 - val_acc: 0.9055\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2723 - acc: 0.9098 - val_loss: 0.2807 - val_acc: 0.9055\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2718 - acc: 0.9099 - val_loss: 0.2759 - val_acc: 0.9057\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2715 - acc: 0.9099 - val_loss: 0.2790 - val_acc: 0.9055\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2709 - acc: 0.9098 - val_loss: 0.2800 - val_acc: 0.9055\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 30s 447us/step - loss: 0.2706 - acc: 0.9097 - val_loss: 0.2743 - val_acc: 0.9055\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2707 - acc: 0.9098 - val_loss: 0.2699 - val_acc: 0.9053\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 30s 447us/step - loss: 0.2701 - acc: 0.9098 - val_loss: 0.2887 - val_acc: 0.9055\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2692 - acc: 0.9099 - val_loss: 0.2701 - val_acc: 0.9055\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2708 - acc: 0.9098 - val_loss: 0.2810 - val_acc: 0.9057\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2683 - acc: 0.9097 - val_loss: 0.2709 - val_acc: 0.9055\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 30s 448us/step - loss: 0.2690 - acc: 0.9098 - val_loss: 0.2752 - val_acc: 0.9055\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2684 - acc: 0.9097 - val_loss: 0.2710 - val_acc: 0.9054\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 30s 447us/step - loss: 0.2698 - acc: 0.9097 - val_loss: 0.2783 - val_acc: 0.9058\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2682 - acc: 0.9097 - val_loss: 0.2695 - val_acc: 0.9057\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 30s 448us/step - loss: 0.2679 - acc: 0.9098 - val_loss: 0.2767 - val_acc: 0.9055\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2686 - acc: 0.9094 - val_loss: 0.2704 - val_acc: 0.9057\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2676 - acc: 0.9098 - val_loss: 0.2836 - val_acc: 0.9051\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2663 - acc: 0.9099 - val_loss: 0.2706 - val_acc: 0.9054\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2660 - acc: 0.9099 - val_loss: 0.2706 - val_acc: 0.9054\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2676 - acc: 0.9098 - val_loss: 0.2729 - val_acc: 0.9055\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2662 - acc: 0.9098 - val_loss: 0.2716 - val_acc: 0.9055\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2665 - acc: 0.9095 - val_loss: 0.2785 - val_acc: 0.9053\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 30s 447us/step - loss: 0.2675 - acc: 0.9096 - val_loss: 0.2763 - val_acc: 0.9053\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2661 - acc: 0.9098 - val_loss: 0.2749 - val_acc: 0.9050\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 28s 427us/step - loss: 0.2660 - acc: 0.9095 - val_loss: 0.2718 - val_acc: 0.9046\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2656 - acc: 0.9096 - val_loss: 0.2708 - val_acc: 0.9049\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2659 - acc: 0.9096 - val_loss: 0.2710 - val_acc: 0.9051\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2648 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9051\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2640 - acc: 0.9098 - val_loss: 0.2719 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_4.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 30s 456us/step - loss: 0.2649 - acc: 0.9096 - val_loss: 0.2729 - val_acc: 0.9050\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2647 - acc: 0.9099 - val_loss: 0.2778 - val_acc: 0.9046\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2644 - acc: 0.9100 - val_loss: 0.2763 - val_acc: 0.9051\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2636 - acc: 0.9098 - val_loss: 0.2742 - val_acc: 0.9047\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2643 - acc: 0.9097 - val_loss: 0.2771 - val_acc: 0.9047\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2645 - acc: 0.9098 - val_loss: 0.2728 - val_acc: 0.9051\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2658 - acc: 0.9096 - val_loss: 0.2762 - val_acc: 0.9051\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2647 - acc: 0.9098 - val_loss: 0.2760 - val_acc: 0.9050\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2636 - acc: 0.9096 - val_loss: 0.2759 - val_acc: 0.9046\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2638 - acc: 0.9097 - val_loss: 0.2715 - val_acc: 0.9047\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 30s 456us/step - loss: 0.2629 - acc: 0.9097 - val_loss: 0.2703 - val_acc: 0.9053\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2637 - acc: 0.9098 - val_loss: 0.2756 - val_acc: 0.9055\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 30s 454us/step - loss: 0.2637 - acc: 0.9097 - val_loss: 0.2754 - val_acc: 0.9051\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2630 - acc: 0.9097 - val_loss: 0.2697 - val_acc: 0.9051\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2626 - acc: 0.9094 - val_loss: 0.2752 - val_acc: 0.9051\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2634 - acc: 0.9099 - val_loss: 0.2735 - val_acc: 0.9049\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 30s 456us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2741 - val_acc: 0.9047\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2623 - acc: 0.9098 - val_loss: 0.2752 - val_acc: 0.9051\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2624 - acc: 0.9097 - val_loss: 0.2737 - val_acc: 0.9050\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2630 - acc: 0.9098 - val_loss: 0.2671 - val_acc: 0.9050\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2615 - acc: 0.9094 - val_loss: 0.2707 - val_acc: 0.9053\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2619 - acc: 0.9098 - val_loss: 0.2741 - val_acc: 0.9049\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 30s 456us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9049\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 30s 448us/step - loss: 0.2615 - acc: 0.9101 - val_loss: 0.2708 - val_acc: 0.9047\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2621 - acc: 0.9099 - val_loss: 0.2709 - val_acc: 0.9049\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 30s 448us/step - loss: 0.2614 - acc: 0.9097 - val_loss: 0.2676 - val_acc: 0.9050\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 30s 454us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2754 - val_acc: 0.9051\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2607 - acc: 0.9098 - val_loss: 0.2729 - val_acc: 0.9050\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 30s 454us/step - loss: 0.2616 - acc: 0.9100 - val_loss: 0.2685 - val_acc: 0.9054\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2612 - acc: 0.9102 - val_loss: 0.2694 - val_acc: 0.9050\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2614 - acc: 0.9100 - val_loss: 0.2714 - val_acc: 0.9050\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2606 - acc: 0.9095 - val_loss: 0.2676 - val_acc: 0.9051\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2610 - acc: 0.9098 - val_loss: 0.2687 - val_acc: 0.9049\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2605 - acc: 0.9098 - val_loss: 0.2673 - val_acc: 0.9050\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2602 - acc: 0.9099 - val_loss: 0.2708 - val_acc: 0.9051\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2595 - acc: 0.9097 - val_loss: 0.2652 - val_acc: 0.9051\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2601 - acc: 0.9098 - val_loss: 0.2735 - val_acc: 0.9051\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 30s 447us/step - loss: 0.2613 - acc: 0.9096 - val_loss: 0.2707 - val_acc: 0.9049\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 30s 453us/step - loss: 0.2595 - acc: 0.9096 - val_loss: 0.2681 - val_acc: 0.9049\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 30s 448us/step - loss: 0.2598 - acc: 0.9099 - val_loss: 0.2696 - val_acc: 0.9054\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2600 - acc: 0.9098 - val_loss: 0.2667 - val_acc: 0.9049\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 30s 450us/step - loss: 0.2609 - acc: 0.9101 - val_loss: 0.2687 - val_acc: 0.9050\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 30s 451us/step - loss: 0.2609 - acc: 0.9101 - val_loss: 0.2681 - val_acc: 0.9051\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2585 - acc: 0.9100 - val_loss: 0.2698 - val_acc: 0.9051\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2591 - acc: 0.9099 - val_loss: 0.2703 - val_acc: 0.9049\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2599 - acc: 0.9099 - val_loss: 0.2704 - val_acc: 0.9053\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 30s 454us/step - loss: 0.2595 - acc: 0.9098 - val_loss: 0.2671 - val_acc: 0.9050\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2596 - acc: 0.9094 - val_loss: 0.2691 - val_acc: 0.9054\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 30s 456us/step - loss: 0.2579 - acc: 0.9102 - val_loss: 0.2696 - val_acc: 0.9051\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 30s 449us/step - loss: 0.2587 - acc: 0.9101 - val_loss: 0.2710 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_4.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2598 - acc: 0.9097 - val_loss: 0.2692 - val_acc: 0.9050\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 30s 452us/step - loss: 0.2588 - acc: 0.9101 - val_loss: 0.2711 - val_acc: 0.9047\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 30s 454us/step - loss: 0.2594 - acc: 0.9099 - val_loss: 0.2708 - val_acc: 0.9051\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2578 - acc: 0.9097 - val_loss: 0.2668 - val_acc: 0.9047\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2582 - acc: 0.9097 - val_loss: 0.2686 - val_acc: 0.9054\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2589 - acc: 0.9099 - val_loss: 0.2696 - val_acc: 0.9054\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2582 - acc: 0.9100 - val_loss: 0.2679 - val_acc: 0.9049TA: 4s - loss: 0.2575 - acc:  - E - ETA: 0s - loss: 0.2585 - acc\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2590 - acc: 0.9098 - val_loss: 0.2689 - val_acc: 0.9049ss: 0.2589 - acc:\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2587 - acc: 0.9096 - val_loss: 0.2716 - val_acc: 0.9047ss: 0.2585 - acc: 0.9\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2588 - acc: 0.9093 - val_loss: 0.2703 - val_acc: 0.9047 4s - loss: - ETA: \n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2578 - acc: 0.9098 - val_loss: 0.2670 - val_acc: 0.9054\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2579 - acc: 0.9099 - val_loss: 0.2705 - val_acc: 0.9051\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2585 - acc: 0.9101 - val_loss: 0.2679 - val_acc: 0.9050 4s - loss: 0.2575  - ETA: - ETA: 0s - loss: 0.2587 - acc: 0.91\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2579 - acc: 0.9098 - val_loss: 0.2710 - val_acc: 0.9051- loss: 0.2571 -\n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2585 - acc: 0.9096 - val_loss: 0.2726 - val_acc: 0.9049\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2584 - acc: 0.9100 - val_loss: 0.2701 - val_acc: 0.9051 - acc\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2593 - acc: 0.9100 - val_loss: 0.2720 - val_acc: 0.9054\n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2571 - acc: 0.9098 - val_loss: 0.2668 - val_acc: 0.9053- acc: 0.9 - ETA: 2s - loss: 0.2578 - acc - ETA: 2s - loss\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2570 - acc: 0.9097 - val_loss: 0.2715 - val_acc: 0.9049\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2582 - acc: 0.9099 - val_loss: 0.2697 - val_acc: 0.9050: - ETA: 2s -  - ETA: 0s - loss: 0.2589 - acc: 0\n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2564 - acc: 0.9100 - val_loss: 0.2720 - val_acc: 0.9054TA: \n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2573 - acc: 0.9100 - val_loss: 0.2685 - val_acc: 0.9054 6 - ETA: 4s - lo - ETA: 1s - loss: \n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2570 - acc: 0.9097 - val_loss: 0.2717 - val_acc: 0.9054 acc: 0.909 - ETA: 7s - loss: 0.2566 - a - ETA:  -\n",
      "Epoch 124/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2586 - acc: 0.9099 - val_loss: 0.2699 - val_acc: 0.9050\n",
      "Epoch 125/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2575 - acc: 0.9102 - val_loss: 0.2668 - val_acc: 0.9051\n",
      "Epoch 126/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2561 - acc: 0.9101 - val_loss: 0.2680 - val_acc: 0.9049\n",
      "Epoch 127/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2569 - acc: 0.9097 - val_loss: 0.2693 - val_acc: 0.9047 ETA: 1s - loss: 0.2571\n",
      "Epoch 128/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2558 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9049\n",
      "Epoch 129/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2574 - acc: 0.9103 - val_loss: 0.2698 - val_acc: 0.9050 - - ETA: 0s - loss: 0.2571 - acc\n",
      "Epoch 130/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2576 - acc: 0.9099 - val_loss: 0.2667 - val_acc: 0.9051\n",
      "Epoch 131/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2571 - acc: 0.9094 - val_loss: 0.2675 - val_acc: 0.9047  - ETA: 7s - loss - ETA: 1s - loss: 0.25\n",
      "Epoch 132/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2573 - acc: 0.9104 - val_loss: 0.2690 - val_acc: 0.9046\n",
      "Epoch 133/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2564 - acc: 0.9096 - val_loss: 0.2682 - val_acc: 0.9051\n",
      "Epoch 134/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2573 - acc: 0.9104 - val_loss: 0.2720 - val_acc: 0.9054\n",
      "Epoch 135/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2554 - acc: 0.9098 - val_loss: 0.2683 - val_acc: 0.9045\n",
      "Epoch 136/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2550 - acc: 0.9100 - val_loss: 0.2728 - val_acc: 0.9051\n",
      "AUC: 0.791647\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 383us/step - loss: 0.3053 - acc: 0.9078 - val_loss: 0.3038 - val_acc: 0.9064\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2945 - acc: 0.9097 - val_loss: 0.3033 - val_acc: 0.9064\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2913 - acc: 0.9097 - val_loss: 0.2949 - val_acc: 0.9064\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2875 - acc: 0.9097 - val_loss: 0.2906 - val_acc: 0.9064\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2846 - acc: 0.9097 - val_loss: 0.2886 - val_acc: 0.9064: 0.2825 - acc - ETA: 2\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2841 - acc: 0.9097 - val_loss: 0.2878 - val_acc: 0.9064s: 0.2840 - acc: 0.909\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2816 - acc: 0.9097 - val_loss: 0.2841 - val_acc: 0.9064\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2807 - acc: 0.9097 - val_loss: 0.2888 - val_acc: 0.9064\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2795 - acc: 0.9097 - val_loss: 0.2805 - val_acc: 0.9064\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2788 - acc: 0.9097 - val_loss: 0.2795 - val_acc: 0.9064\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2779 - acc: 0.9096 - val_loss: 0.2764 - val_acc: 0.9064. - ETA: 10s - ETA: 8s - loss: - ET \n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2764 - acc: 0.9097 - val_loss: 0.2872 - val_acc: 0.9064\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2773 - acc: 0.9097 - val_loss: 0.2927 - val_acc: 0.9065- ETA: 4s - loss: 0.2795 - acc: 0.908 - ETA: 4s - loss: 0.2 - ETA: 2\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2755 - acc: 0.9097 - val_loss: 0.2814 - val_acc: 0.9065\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2750 - acc: 0.9096 - val_loss: 0.2779 - val_acc: 0.9065: 0.2750 - acc:\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2745 - acc: 0.9096 - val_loss: 0.2787 - val_acc: 0.9065.2746 - acc: 0 - ETA: 0s - loss: 0.2744 - acc: 0.90\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2738 - acc: 0.9097 - val_loss: 0.2781 - val_acc: 0.9064A:  - ETA: 1s - loss: 0.2731\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2741 - acc: 0.9097 - val_loss: 0.2750 - val_acc: 0.9064\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2727 - acc: 0.9098 - val_loss: 0.2794 - val_acc: 0.9065 0s - loss: 0.2731 - acc: 0.\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2731 - acc: 0.9098 - val_loss: 0.2786 - val_acc: 0.9064\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2720 - acc: 0.9097 - val_loss: 0.2741 - val_acc: 0.9066\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2716 - acc: 0.9095 - val_loss: 0.2780 - val_acc: 0.9065\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2699 - acc: 0.9097 - val_loss: 0.2817 - val_acc: 0.9066\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2712 - acc: 0.9099 - val_loss: 0.2709 - val_acc: 0.9064\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2703 - acc: 0.9095 - val_loss: 0.2722 - val_acc: 0.9064: 0.2717\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2712 - acc: 0.9095 - val_loss: 0.2807 - val_acc: 0.9061\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2710 - acc: 0.9096 - val_loss: 0.2718 - val_acc: 0.9064 - acc\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2690 - acc: 0.9095 - val_loss: 0.2753 - val_acc: 0.9062\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2700 - acc: 0.9096 - val_loss: 0.2826 - val_acc: 0.9064\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2693 - acc: 0.9099 - val_loss: 0.2724 - val_acc: 0.9066\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2687 - acc: 0.9097 - val_loss: 0.2768 - val_acc: 0.9062\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2695 - acc: 0.9095 - val_loss: 0.2793 - val_acc: 0.9066\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2692 - acc: 0.9098 - val_loss: 0.2702 - val_acc: 0.9064\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2692 - acc: 0.9097 - val_loss: 0.2852 - val_acc: 0.9078: 0.9\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2691 - acc: 0.9095 - val_loss: 0.2816 - val_acc: 0.9069 loss - ETA: 4s - loss: 0.2673  - \n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2667 - acc: 0.9098 - val_loss: 0.2793 - val_acc: 0.9064 loss: 0.2684 - acc: 0.908 - ETA: 9s - loss: 0.26 - ETA: 7s - loss - ETA: 5s - loss: 0.2681 - acc - ETA: 4s - loss: 0.2669 - a - ETA: 4s - lo - ETA: 1s - loss: 0\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2667 - acc: 0.9096 - val_loss: 0.2763 - val_acc: 0.9070oss: 0.2666 - acc: 0.90\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2672 - acc: 0.9094 - val_loss: 0.2751 - val_acc: 0.9065\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2672 - acc: 0.9098 - val_loss: 0.2711 - val_acc: 0.9065\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2675 - acc: 0.9097 - val_loss: 0.2783 - val_acc: 0.9066 - loss: 0.2636 - acc: 0.91 - ETA: 10s - loss: 0.2635 - ETA: 9s - loss: 0.2641 - acc: 0.911 - ETA: 9s - loss: 0.2644 - - ETA: 8s - loss: 0.2661 -  - ETA: 7s - loss:  - ETA: 2s - loss: 0.2659 - acc: 0.910 - ETA: 1s - loss:\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2665 - acc: 0.9094 - val_loss: 0.2748 - val_acc: 0.9069 7s - loss: 0.2660 - acc: 0.9 - ETA: 7s - loss: 0.2660 - acc: 0.910 \n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2667 - acc: 0.9097 - val_loss: 0.2741 - val_acc: 0.9064: 7s - loss: 0. - ETA: 1s - loss:\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2666 - acc: 0.9095 - val_loss: 0.2711 - val_acc: 0.9064\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2662 - acc: 0.9095 - val_loss: 0.2712 - val_acc: 0.9064: 0.2 - ETA: 4s - loss: 0.266 - ETA: 2s - loss: 0.2666 - acc: 0.909 - ETA: 2s\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2664 - acc: 0.9099 - val_loss: 0.2749 - val_acc: 0.9065\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2651 - acc: 0.9099 - val_loss: 0.2801 - val_acc: 0.9069 10s - loss: 0.2672 - acc: 0.90 - ETA: 10 - ETA: 8s - - ETA: 2s\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2662 - acc: 0.9099 - val_loss: 0.2776 - val_acc: 0.9068\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2647 - acc: 0.9099 - val_loss: 0.2775 - val_acc: 0.9062 - - ETA: 5s - loss: 0.263\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2654 - acc: 0.9096 - val_loss: 0.2766 - val_acc: 0.90616 - ETA: 11s - loss: 0.2 - ETA: 7s - loss: 0.2657 - acc - ETA: - \n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2665 - acc: 0.9096 - val_loss: 0.2818 - val_acc: 0.9062oss: 0.2676 - acc: - ETA: 1s - loss: 0.2667 - a - ETA: 0s - loss: 0.2663 - acc - ETA: 0s - loss: 0.2665 - acc: 0.909\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_5.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2666 - acc: 0.9096 - val_loss: 0.2796 - val_acc: 0.9064 - loss: 0.2636 - acc:\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2645 - acc: 0.9094 - val_loss: 0.2721 - val_acc: 0.9066\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2645 - acc: 0.9094 - val_loss: 0.2775 - val_acc: 0.9066\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2650 - acc: 0.9094 - val_loss: 0.2708 - val_acc: 0.9066s - loss: 0.26 - ETA: 3s - loss: 0.2644 - acc: 0.9 - ETA: 3s - loss: - ETA: 1s - loss: 0.26\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2655 - acc: 0.9097 - val_loss: 0.2719 - val_acc: 0.9064 1s - loss: 0.2\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2651 - acc: 0.9100 - val_loss: 0.2752 - val_acc: 0.9065\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2645 - acc: 0.9100 - val_loss: 0.2793 - val_acc: 0.9068oss - ETA: 3s - loss: 0.2638 - acc: 0.910 - ETA: 3s - l - ETA: 0s - loss: 0.2643 - a\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2640 - acc: 0.9096 - val_loss: 0.2732 - val_acc: 0.9068\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2648 - acc: 0.9098 - val_loss: 0.2792 - val_acc: 0.9072 - ETA: 3s - loss:  - ETA: 1s - loss: 0.2\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2632 - acc: 0.9096 - val_loss: 0.2728 - val_acc: 0.9069 loss: 0.2628 - ac - ETA: 0s - loss: 0.2634 - acc\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2639 - acc: 0.9096 - val_loss: 0.2714 - val_acc: 0.9066652 - acc: 0.90 - ETA: 1\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2629 - acc: 0.9096 - val_loss: 0.2701 - val_acc: 0.9066ETA: 0s - loss: 0.2627 - acc: \n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2645 - acc: 0.9096 - val_loss: 0.2683 - val_acc: 0.9064\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2639 - acc: 0.9096 - val_loss: 0.2751 - val_acc: 0.9068\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2636 - acc: 0.9096 - val_loss: 0.2754 - val_acc: 0.9069\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2636 - acc: 0.9095 - val_loss: 0.2775 - val_acc: 0.9066A: 14s - loss: 0.26 \n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2636 - acc: 0.9094 - val_loss: 0.2757 - val_acc: 0.9066\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2629 - acc: 0.9096 - val_loss: 0.2728 - val_acc: 0.9070 - ETA: 0s - loss: 0.2631 - acc:\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2627 - acc: 0.9096 - val_loss: 0.2715 - val_acc: 0.9065\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2629 - acc: 0.9097 - val_loss: 0.2748 - val_acc: 0.9069 8s - l - ETA: 2s - loss: 0.2631 - ETA: 1s - loss: 0.2630\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2625 - acc: 0.9096 - val_loss: 0.2727 - val_acc: 0.9065\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2625 - acc: 0.9096 - val_loss: 0.2768 - val_acc: 0.9066\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2630 - acc: 0.9097 - val_loss: 0.2710 - val_acc: 0.9066- acc: 0.909 - ETA:  - ETA: 3s - loss: 0.2645 - acc: 0.909 - ETA: 3s - loss: 0.2647 - acc: - ETA: 3s - loss - ETA: 1s - loss: 0.2637 -\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2624 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9065A: 14s - loss: - ETA: 1s - loss: 0.2\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2621 - acc: 0.9096 - val_loss: 0.2771 - val_acc: 0.9068A: 0s - loss: 0.2619 - acc: 0.9\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2622 - acc: 0.9094 - val_loss: 0.2730 - val_acc: 0.9068\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2605 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9066\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2611 - acc: 0.9098 - val_loss: 0.2717 - val_acc: 0.9064\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2611 - acc: 0.9099 - val_loss: 0.2764 - val_acc: 0.9062\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2621 - acc: 0.9098 - val_loss: 0.2707 - val_acc: 0.9064\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2617 - acc: 0.9092 - val_loss: 0.2748 - val_acc: 0.9069c: 0.91 - ETA: 10s - loss: 0.2605 - a - ETA: 9s - loss: 0.2607 -  - ETA: 8s - loss: 0.2601 - acc: 0.910 - ETA: 8s - loss: 0.2603 - ac - ETA: 7s - loss: 0.2603 - acc: 0.910 - ETA: 7s - loss: 0.2606  - ETA: 6s - loss: 0.2 - ETA: 5s - loss: 0.2623 - acc: 0. - ETA:  - ETA: 1s - loss: 0\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2611 - acc: 0.9097 - val_loss: 0.2709 - val_acc: 0.9068\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2618 - acc: 0.9098 - val_loss: 0.2743 - val_acc: 0.9064 ETA: 0s - loss: 0.2622 - acc: 0\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2614 - acc: 0.9099 - val_loss: 0.2736 - val_acc: 0.9064 loss: 0.2616 - acc - ETA - ETA: 11s - loss: 0.2615 - acc: 0.90 - ETA: 1 - ETA: 5s  - ET\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2619 - acc: 0.9094 - val_loss: 0.2723 - val_acc: 0.9064 - loss: 0. - ETA: 12s - loss: 0.2640 - acc: 0.90 - ETA: 12s\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2619 - acc: 0.9096 - val_loss: 0.2739 - val_acc: 0.9066loss - ETA: 0s - loss: 0.2620 - acc - ETA: 0s - loss: 0.2619 - acc: 0.9\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2607 - acc: 0.9095 - val_loss: 0.2691 - val_acc: 0.9065a - ETA: 4s - loss: 0.2595 - acc: 0.909 - ETA:  - ETA: 1s - loss: 0.2607 - acc - ETA: 1s - loss: 0.2611 \n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2607 - acc: 0.9094 - val_loss: 0.2741 - val_acc: 0.9066\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2598 - acc: 0.9096 - val_loss: 0.2739 - val_acc: 0.9068loss: 0.2588 - acc: 0.910 - ETA: 5s - loss: 0.2588 - acc: 0 -  - ETA: 1s - loss: 0.2591 - ac - ETA: 0s - loss: 0.2603 - acc - ETA: 0s - loss: 0.2597 - acc: 0.909\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2600 - acc: 0.9096 - val_loss: 0.2733 - val_acc: 0.9068 0s - loss: 0.2601 - acc: 0.90\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2608 - acc: 0.9096 - val_loss: 0.2725 - val_acc: 0.9065\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2602 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9072\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2589 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9065 ETA: 4s - loss: 0.2578 - acc: 0.911 - ETA: 4 - ETA: 1s - loss: 0.2594 -  - ETA: 0s - loss: 0.2592 - ac\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2610 - acc: 0.9100 - val_loss: 0.2697 - val_acc: 0.9068 4s - loss: 0.2623 - ac - ETA: 3s - loss: 0.2622 - acc: 0.909 - ET\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2607 - acc: 0.9101 - val_loss: 0.2738 - val_acc: 0.9066- ETA: 3s - loss: 0.26 - ETA: 1s - loss: 0.2\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2612 - acc: 0.9097 - val_loss: 0.2750 - val_acc: 0.9069 - ETA: 6s - loss: 0.2622 - acc: 0.9 - ETA: 5s - loss: 0.2616 - acc: - ETA: 5s - loss: 0.26 - ETA: 0s - loss: 0.2612 - acc: 0.90\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2596 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9068\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2598 - acc: 0.9099 - val_loss: 0.2724 - val_acc: 0.9065s: 0.2617 - acc - ETA: 4s - loss: - ETA: 2s - loss: 0.2603 - acc: 0.909 - ETA: 2s -\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2601 - acc: 0.9096 - val_loss: 0.2729 - val_acc: 0.9069597 -\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2598 - acc: 0.9095 - val_loss: 0.2734 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_5.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2594 - acc: 0.9094 - val_loss: 0.2752 - val_acc: 0.9066\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2589 - acc: 0.9099 - val_loss: 0.2713 - val_acc: 0.9064\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2585 - acc: 0.9098 - val_loss: 0.2755 - val_acc: 0.9066A: 5s - loss: 0.2552 - a - ETA: - ETA: 1s - loss: 0\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2594 - acc: 0.9098 - val_loss: 0.2712 - val_acc: 0.9064\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2588 - acc: 0.9096 - val_loss: 0.2736 - val_acc: 0.9066\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2594 - acc: 0.9093 - val_loss: 0.2757 - val_acc: 0.9068\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2597 - acc: 0.9098 - val_loss: 0.2733 - val_acc: 0.9066\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2586 - acc: 0.9098 - val_loss: 0.2687 - val_acc: 0.9069ss: 0.2582  - ETA: 0s - loss: 0.2591 - acc: 0\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2599 - acc: 0.9095 - val_loss: 0.2727 - val_acc: 0.9065\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2587 - acc: 0.9097 - val_loss: 0.2704 - val_acc: 0.9064 0.90\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2581 - acc: 0.9096 - val_loss: 0.2691 - val_acc: 0.9066\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2573 - acc: 0.9094 - val_loss: 0.2723 - val_acc: 0.9065cc: 0.909\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2587 - acc: 0.9098 - val_loss: 0.2719 - val_acc: 0.9065\n",
      "AUC: 0.783296\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 382us/step - loss: 0.3064 - acc: 0.9086 - val_loss: 0.2919 - val_acc: 0.9125\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2961 - acc: 0.9090 - val_loss: 0.2909 - val_acc: 0.9125\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2914 - acc: 0.9090 - val_loss: 0.2906 - val_acc: 0.9125\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2882 - acc: 0.9090 - val_loss: 0.2773 - val_acc: 0.9125\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2864 - acc: 0.9090 - val_loss: 0.2729 - val_acc: 0.9125 - loss: 0.2871 - ac\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2852 - acc: 0.9090 - val_loss: 0.2762 - val_acc: 0.9125858  - ETA: 1s - loss: 0.\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2829 - acc: 0.9090 - val_loss: 0.2699 - val_acc: 0.9125\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2819 - acc: 0.9090 - val_loss: 0.2691 - val_acc: 0.9125TA: 1s - loss: 0.2830\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2799 - acc: 0.9090 - val_loss: 0.2688 - val_acc: 0.9125\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2784 - acc: 0.9091 - val_loss: 0.2696 - val_acc: 0.9125\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2774 - acc: 0.9089 - val_loss: 0.2906 - val_acc: 0.9129\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2773 - acc: 0.9090 - val_loss: 0.2682 - val_acc: 0.9125A: 9s - loss: \n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2770 - acc: 0.9089 - val_loss: 0.2711 - val_acc: 0.9125\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2770 - acc: 0.9091 - val_loss: 0.2824 - val_acc: 0.9127 2s - lo\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2751 - acc: 0.9091 - val_loss: 0.2802 - val_acc: 0.9127\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2748 - acc: 0.9090 - val_loss: 0.2671 - val_acc: 0.9125\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2738 - acc: 0.9089 - val_loss: 0.2772 - val_acc: 0.9126oss: 0.2739 \n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2743 - acc: 0.9089 - val_loss: 0.2753 - val_acc: 0.9125\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2729 - acc: 0.9090 - val_loss: 0.2716 - val_acc: 0.9126TA: 1s - loss: 0.2734 - acc: 0.908 - ETA: 1s - loss: \n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2725 - acc: 0.9090 - val_loss: 0.2805 - val_acc: 0.9130\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2729 - acc: 0.9089 - val_loss: 0.2743 - val_acc: 0.9129loss: 0.2735 - a\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2717 - acc: 0.9089 - val_loss: 0.2741 - val_acc: 0.9125\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2722 - acc: 0.9089 - val_loss: 0.2720 - val_acc: 0.9127\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2709 - acc: 0.9089 - val_loss: 0.2704 - val_acc: 0.91250. - ETA: 0s - loss: 0.2710 - acc\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2707 - acc: 0.9090 - val_loss: 0.2737 - val_acc: 0.9131\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2700 - acc: 0.9088 - val_loss: 0.2656 - val_acc: 0.9125 4s - loss: 0.2706 -  - ETA: 0s - loss: 0.2702 - acc: 0.90\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2705 - acc: 0.9086 - val_loss: 0.2715 - val_acc: 0.9131\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2711 - acc: 0.9089 - val_loss: 0.2749 - val_acc: 0.9131\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2697 - acc: 0.9088 - val_loss: 0.2676 - val_acc: 0.9127\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2690 - acc: 0.9088 - val_loss: 0.2770 - val_acc: 0.9127\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2689 - acc: 0.9088 - val_loss: 0.2727 - val_acc: 0.9131\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2695 - acc: 0.9088 - val_loss: 0.2710 - val_acc: 0.9131: 0.2698 - a\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2693 - acc: 0.9089 - val_loss: 0.2659 - val_acc: 0.9130\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2691 - acc: 0.9090 - val_loss: 0.2725 - val_acc: 0.9122s: 0.2687 - - ETA: 0s - loss: 0.2690 - acc\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2680 - acc: 0.9088 - val_loss: 0.2683 - val_acc: 0.9131\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2690 - acc: 0.9088 - val_loss: 0.2696 - val_acc: 0.9122\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2677 - acc: 0.9091 - val_loss: 0.2689 - val_acc: 0.9123\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2676 - acc: 0.9089 - val_loss: 0.2663 - val_acc: 0.9130: 0.2674 - acc: \n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2686 - acc: 0.9089 - val_loss: 0.2779 - val_acc: 0.9131\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2680 - acc: 0.9090 - val_loss: 0.2711 - val_acc: 0.9129s: 0.2701  - ETA: 5s - loss: 0.2687 -  - ETA: 4s - loss: 0.2695 - acc: 0.9 - ETA: 4s - loss: 0.2697 - acc: - ETA: 3s - loss: 0.26 - ETA: 2s - loss: 0.2686 - acc: 0.908 - ETA: 2s - loss\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2672 - acc: 0.9089 - val_loss: 0.2648 - val_acc: 0.9130\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2685 - acc: 0.9088 - val_loss: 0.2693 - val_acc: 0.9133acc: 0.90 - ETA: 9s - loss: 0.2659 - acc: 0. - ETA: 8 - ETA: 2s \n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2687 - acc: 0.9088 - val_loss: 0.2619 - val_acc: 0.9126s - loss: 0.2694 - acc: 0.908 - ETA: 7s - - ETA: 5s - loss: 0.2694 - acc: 0.908 - ETA: 5s - loss: 0.269\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2672 - acc: 0.9089 - val_loss: 0.2723 - val_acc: 0.9130\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2663 - acc: 0.9094 - val_loss: 0.2663 - val_acc: 0.912909 - ETA: 0s - loss: 0.2659 - a\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2662 - acc: 0.9090 - val_loss: 0.2631 - val_acc: 0.9127\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2664 - acc: 0.9087 - val_loss: 0.2718 - val_acc: 0.9131\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2667 - acc: 0.9088 - val_loss: 0.2723 - val_acc: 0.9126 0\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2662 - acc: 0.9088 - val_loss: 0.2637 - val_acc: 0.9126\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2656 - acc: 0.9087 - val_loss: 0.2784 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_6.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2661 - acc: 0.9092 - val_loss: 0.2665 - val_acc: 0.9130\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2655 - acc: 0.9089 - val_loss: 0.2710 - val_acc: 0.9120 - loss: 0.2650\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2657 - acc: 0.9087 - val_loss: 0.2665 - val_acc: 0.9127 7s - loss: 0.2638 - acc: 0. - ETA: 7s - loss: 0.2 - ETA: 5s - loss: 0.2632 - a - ETA: 4s - - ETA: 2s - loss: 0.2656 - acc: 0. - ETA: 1s - loss: \n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2644 - acc: 0.9091 - val_loss: 0.2677 - val_acc: 0.9126\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2651 - acc: 0.9089 - val_loss: 0.2659 - val_acc: 0.9125\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2648 - acc: 0.9089 - val_loss: 0.2622 - val_acc: 0.9127\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2643 - acc: 0.9086 - val_loss: 0.2661 - val_acc: 0.9127\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2650 - acc: 0.9088 - val_loss: 0.2692 - val_acc: 0.9130\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2640 - acc: 0.9092 - val_loss: 0.2762 - val_acc: 0.9129\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2643 - acc: 0.9091 - val_loss: 0.2710 - val_acc: 0.9131A: 5s - loss: 0.2627 - acc: 0.9 - ETA: 5s - loss: 0.2626 -  - ETA: 4s - loss: 0.2622 - acc: 0\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2642 - acc: 0.9089 - val_loss: 0.2625 - val_acc: 0.9126- acc: 0. - ETA: 3s - loss: 0.2646 - a - ETA: 2s - los\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2641 - acc: 0.9088 - val_loss: 0.2656 - val_acc: 0.9130\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2633 - acc: 0.9092 - val_loss: 0.2690 - val_acc: 0.9131. - ETA: 1s - loss: 0.2626 - acc: 0.909 - ETA: 1s - loss: 0.2628\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2635 - acc: 0.9086 - val_loss: 0.2738 - val_acc: 0.9127\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2646 - acc: 0.9089 - val_loss: 0.2722 - val_acc: 0.9125- ET\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2637 - acc: 0.9088 - val_loss: 0.2716 - val_acc: 0.9134\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2635 - acc: 0.9087 - val_loss: 0.2657 - val_acc: 0.9129\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2627 - acc: 0.9092 - val_loss: 0.2636 - val_acc: 0.9127\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2623 - acc: 0.9089 - val_loss: 0.2721 - val_acc: 0.9127 0s - loss: 0.2622 - acc:\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2637 - acc: 0.9086 - val_loss: 0.2742 - val_acc: 0.9130: 9s -  - ETA: 7  - ETA: 0s - loss: 0.2630 - acc: 0.9 - ETA: 0s - loss: 0.2630 - acc\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2630 - acc: 0.9091 - val_loss: 0.2664 - val_acc: 0.9129\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2624 - acc: 0.9093 - val_loss: 0.2710 - val_acc: 0.9119\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2630 - acc: 0.9090 - val_loss: 0.2655 - val_acc: 0.9129\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2621 - acc: 0.9089 - val_loss: 0.2664 - val_acc: 0.9129 6s - loss: 0.26 - ETA: 4s - - ETA: 2s - loss:  - ETA: 0s - loss: 0.2619 - acc: 0.\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2621 - acc: 0.9089 - val_loss: 0.2764 - val_acc: 0.9125\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2622 - acc: 0.9088 - val_loss: 0.2668 - val_acc: 0.9130loss: 0.2632 - acc: 0. - ETA: 1s - loss: 0.\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2640 - acc: 0.9092 - val_loss: 0.2661 - val_acc: 0.9129\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2619 - acc: 0.9086 - val_loss: 0.2704 - val_acc: 0.9126\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2615 - acc: 0.9087 - val_loss: 0.2634 - val_acc: 0.9127\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2613 - acc: 0.9086 - val_loss: 0.2660 - val_acc: 0.9126\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2624 - acc: 0.9091 - val_loss: 0.2680 - val_acc: 0.9127ss: \n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2627 - acc: 0.9087 - val_loss: 0.2650 - val_acc: 0.9127A - ETA: 2s - lo - ETA: 0s - loss: 0.2630 - acc\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2625 - acc: 0.9090 - val_loss: 0.2628 - val_acc: 0.9126\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2627 - acc: 0.9091 - val_loss: 0.2672 - val_acc: 0.9126\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2618 - acc: 0.9087 - val_loss: 0.2654 - val_acc: 0.9127\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2605 - acc: 0.9088 - val_loss: 0.2666 - val_acc: 0.9125 - loss: 0.2589 - ac -  - ETA: 3s - loss: 0.2616 - ETA: 2s - loss: 0.2610 - a - ETA: 1s - loss: 0.2603 - ac - ETA: 0s - loss: 0.2611 - a\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2610 - acc: 0.9093 - val_loss: 0.2665 - val_acc: 0.9126  - ETA: 2s - loss: 0.2618 - acc:  - ETA: 2s - \n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2610 - acc: 0.9093 - val_loss: 0.2645 - val_acc: 0.9130- loss: 0.2607\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2615 - acc: 0.9086 - val_loss: 0.2643 - val_acc: 0.9127\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2618 - acc: 0.9089 - val_loss: 0.2602 - val_acc: 0.9127 0s - loss: 0.2616 - acc: 0.\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2599 - acc: 0.9089 - val_loss: 0.2678 - val_acc: 0.9126TA: 1s - loss\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2612 - acc: 0.9091 - val_loss: 0.2661 - val_acc: 0.9131ETA: 2s - loss: 0.26 - ETA: 1s - loss: 0.2604 -\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2607 - acc: 0.9091 - val_loss: 0.2671 - val_acc: 0.9129\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2604 - acc: 0.9089 - val_loss: 0.2610 - val_acc: 0.9129\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2607 - acc: 0.9094 - val_loss: 0.2644 - val_acc: 0.9127.909 - ETA: 5s - lo\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2587 - acc: 0.9097 - val_loss: 0.2631 - val_acc: 0.9129s - loss: 0.2 - ETA: 5s - loss: - ETA: - ETA: 0s - loss: 0.2580 - acc: 0\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2595 - acc: 0.9088 - val_loss: 0.2609 - val_acc: 0.9130: 0.2586  - ETA: 3s - loss: 0.2592  - ETA: 1s - loss: 0.260 - ETA: 0s - loss: 0.2598 - acc: 0\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2588 - acc: 0.9091 - val_loss: 0.2624 - val_acc: 0.9129\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2597 - acc: 0.9090 - val_loss: 0.2670 - val_acc: 0.9127\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2591 - acc: 0.9087 - val_loss: 0.2659 - val_acc: 0.91310.2588 - acc: 0.\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_6.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2584 - acc: 0.9089 - val_loss: 0.2646 - val_acc: 0.9129\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2601 - acc: 0.9093 - val_loss: 0.2689 - val_acc: 0.9133\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2603 - acc: 0.9091 - val_loss: 0.2635 - val_acc: 0.9127\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2584 - acc: 0.9096 - val_loss: 0.2643 - val_acc: 0.912983 - acc: 0.909\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2582 - acc: 0.9091 - val_loss: 0.2656 - val_acc: 0.9126TA: 5s - loss: 0.259 - ETA: 4s - l - ETA: 1s - loss: 0.2587 - a - ETA: 0s - loss: 0.2579 - a\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2595 - acc: 0.9092 - val_loss: 0.2634 - val_acc: 0.9131A: 3s - loss: 0.2599 - acc: 0.908 -\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2592 - acc: 0.9096 - val_loss: 0.2656 - val_acc: 0.9130 0. - ETA: 1s - loss: 0.2587 - - ETA: 0s - loss: 0.2590 - acc: 0.909\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2577 - acc: 0.9089 - val_loss: 0.2653 - val_acc: 0.9130 8s - loss: 0.2546 - acc - ETA: 7s - loss: 0.2546 - acc - ETA:\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2604 - acc: 0.9092 - val_loss: 0.2641 - val_acc: 0.9129\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2579 - acc: 0.9093 - val_loss: 0.2652 - val_acc: 0.9127\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2582 - acc: 0.9090 - val_loss: 0.2668 - val_acc: 0.9127\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2576 - acc: 0.9091 - val_loss: 0.2658 - val_acc: 0.9126\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2582 - acc: 0.9089 - val_loss: 0.2659 - val_acc: 0.91310.9 - ETA: 0s - loss: 0.2582 - acc: 0.90\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2570 - acc: 0.9092 - val_loss: 0.2630 - val_acc: 0.9131ETA: 6s - loss: 0.2568 - acc - ETA: 5s - lo -\n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2600 - acc: 0.9092 - val_loss: 0.2677 - val_acc: 0.9125\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2581 - acc: 0.9090 - val_loss: 0.2674 - val_acc: 0.9127\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2581 - acc: 0.9094 - val_loss: 0.2623 - val_acc: 0.9126\n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2583 - acc: 0.9092 - val_loss: 0.2652 - val_acc: 0.9123\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2602 - acc: 0.9093 - val_loss: 0.2642 - val_acc: 0.9130\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2576 - acc: 0.9089 - val_loss: 0.2632 - val_acc: 0.9130\n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2567 - acc: 0.9095 - val_loss: 0.2683 - val_acc: 0.9130\n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2588 - acc: 0.9089 - val_loss: 0.2683 - val_acc: 0.9134\n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2572 - acc: 0.9089 - val_loss: 0.2670 - val_acc: 0.9131\n",
      "Epoch 124/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2567 - acc: 0.9093 - val_loss: 0.2639 - val_acc: 0.91302567 - acc: 0.909\n",
      "Epoch 125/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2585 - acc: 0.9096 - val_loss: 0.2656 - val_acc: 0.9126\n",
      "Epoch 126/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2576 - acc: 0.9089 - val_loss: 0.2625 - val_acc: 0.9137\n",
      "Epoch 127/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2567 - acc: 0.9094 - val_loss: 0.2630 - val_acc: 0.9133\n",
      "Epoch 128/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2571 - acc: 0.9093 - val_loss: 0.2643 - val_acc: 0.9134 - loss: 0.2545 - acc: 0 -  - ETA: 0s - loss: 0.2573 - acc: 0.\n",
      "Epoch 129/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2565 - acc: 0.9093 - val_loss: 0.2628 - val_acc: 0.9130ss: 0.2\n",
      "Epoch 130/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2567 - acc: 0.9092 - val_loss: 0.2685 - val_acc: 0.9133\n",
      "Epoch 131/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2570 - acc: 0.9088 - val_loss: 0.2681 - val_acc: 0.9125\n",
      "Epoch 132/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2561 - acc: 0.9094 - val_loss: 0.2634 - val_acc: 0.9131\n",
      "Epoch 133/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2579 - acc: 0.9091 - val_loss: 0.2663 - val_acc: 0.9137\n",
      "Epoch 134/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2568 - acc: 0.9090 - val_loss: 0.2648 - val_acc: 0.9135loss: 0 - ETA: 0s - loss: 0.2566 - acc: 0.9\n",
      "Epoch 135/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2560 - acc: 0.9101 - val_loss: 0.2680 - val_acc: 0.9130\n",
      "Epoch 136/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2557 - acc: 0.9094 - val_loss: 0.2631 - val_acc: 0.9126\n",
      "Epoch 137/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2553 - acc: 0.9098 - val_loss: 0.2661 - val_acc: 0.9131oss: 0.2553 - acc: 0.909\n",
      "Epoch 138/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2575 - acc: 0.9092 - val_loss: 0.2667 - val_acc: 0.9133\n",
      "Epoch 139/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2559 - acc: 0.9095 - val_loss: 0.2633 - val_acc: 0.9133lo\n",
      "Epoch 140/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2554 - acc: 0.9093 - val_loss: 0.2673 - val_acc: 0.91332544 - acc: 0.909 - ETA: 3s - ETA: 1s - loss: 0.2543\n",
      "AUC: 0.769771\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 26s 387us/step - loss: 0.3075 - acc: 0.9079 - val_loss: 0.3003 - val_acc: 0.9068 10s - loss:  - ETA: 0s - loss: 0.3078 - acc: \n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2957 - acc: 0.9097 - val_loss: 0.2966 - val_acc: 0.9068\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2919 - acc: 0.9097 - val_loss: 0.3005 - val_acc: 0.9068\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2894 - acc: 0.9097 - val_loss: 0.2908 - val_acc: 0.9068\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2864 - acc: 0.9097 - val_loss: 0.2860 - val_acc: 0.9068\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.2849 - acc: 0.9097 - val_loss: 0.2958 - val_acc: 0.9068 2s - loss: 0.2 - ETA: 0s - loss: 0.2841 - acc\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2829 - acc: 0.9097 - val_loss: 0.2819 - val_acc: 0.9068TA:\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2816 - acc: 0.9097 - val_loss: 0.2885 - val_acc: 0.9068: 0. - ETA: 3s - lo - ETA: 1s - loss: 0.2817 -\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2804 - acc: 0.9096 - val_loss: 0.2876 - val_acc: 0.9068\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2801 - acc: 0.9097 - val_loss: 0.2953 - val_acc: 0.9065\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2795 - acc: 0.9097 - val_loss: 0.2795 - val_acc: 0.9068\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2781 - acc: 0.9096 - val_loss: 0.2852 - val_acc: 0.9062\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 25s 383us/step - loss: 0.2780 - acc: 0.9096 - val_loss: 0.2803 - val_acc: 0.9066\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2766 - acc: 0.9096 - val_loss: 0.2752 - val_acc: 0.9068\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2769 - acc: 0.9097 - val_loss: 0.2786 - val_acc: 0.9066\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2757 - acc: 0.9096 - val_loss: 0.2803 - val_acc: 0.9065\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2747 - acc: 0.9097 - val_loss: 0.2893 - val_acc: 0.9062\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2741 - acc: 0.9096 - val_loss: 0.2849 - val_acc: 0.9062\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2737 - acc: 0.9096 - val_loss: 0.2747 - val_acc: 0.9065\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2732 - acc: 0.9095 - val_loss: 0.2813 - val_acc: 0.9062\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2726 - acc: 0.9096 - val_loss: 0.2881 - val_acc: 0.9064\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.2731 - acc: 0.9095 - val_loss: 0.2736 - val_acc: 0.9066\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2726 - acc: 0.9095 - val_loss: 0.2700 - val_acc: 0.9065\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2720 - acc: 0.9096 - val_loss: 0.2807 - val_acc: 0.9066\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2712 - acc: 0.9096 - val_loss: 0.2774 - val_acc: 0.9064\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2708 - acc: 0.9096 - val_loss: 0.2747 - val_acc: 0.9065\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2701 - acc: 0.9095 - val_loss: 0.2784 - val_acc: 0.9064\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2713 - acc: 0.9097 - val_loss: 0.2787 - val_acc: 0.9069\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2699 - acc: 0.9094 - val_loss: 0.2856 - val_acc: 0.9066\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2708 - acc: 0.9097 - val_loss: 0.2768 - val_acc: 0.9069\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2690 - acc: 0.9098 - val_loss: 0.2718 - val_acc: 0.9062\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2702 - acc: 0.9095 - val_loss: 0.2690 - val_acc: 0.9066\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2686 - acc: 0.9098 - val_loss: 0.2805 - val_acc: 0.9065\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2677 - acc: 0.9097 - val_loss: 0.2801 - val_acc: 0.9068\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2681 - acc: 0.9094 - val_loss: 0.2841 - val_acc: 0.9068\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2686 - acc: 0.9100 - val_loss: 0.2775 - val_acc: 0.9062\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2687 - acc: 0.9094 - val_loss: 0.2704 - val_acc: 0.9066\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2679 - acc: 0.9095 - val_loss: 0.2693 - val_acc: 0.9065\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2668 - acc: 0.9094 - val_loss: 0.2712 - val_acc: 0.9064\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2678 - acc: 0.9096 - val_loss: 0.2747 - val_acc: 0.9068\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2678 - acc: 0.9096 - val_loss: 0.2752 - val_acc: 0.9064\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2673 - acc: 0.9099 - val_loss: 0.2784 - val_acc: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2667 - acc: 0.9093 - val_loss: 0.2715 - val_acc: 0.9065\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2665 - acc: 0.9097 - val_loss: 0.2732 - val_acc: 0.9065: 0.2661 \n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2667 - acc: 0.9097 - val_loss: 0.2756 - val_acc: 0.9065\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2661 - acc: 0.9094 - val_loss: 0.2783 - val_acc: 0.9065\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2666 - acc: 0.9096 - val_loss: 0.2716 - val_acc: 0.9065 4s - lo - ETA: 2s - loss\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2655 - acc: 0.9093 - val_loss: 0.2687 - val_acc: 0.9062\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2651 - acc: 0.9097 - val_loss: 0.2718 - val_acc: 0.906557 - acc: \n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2649 - acc: 0.9093 - val_loss: 0.2728 - val_acc: 0.9059 14s - loss: 0.2639 - - ETA: 14s - loss: 0.2634 - a - ETA:  - ETA: - ETA: 7s - loss: 0.2681 - acc: 0. - ETA: 7s - loss:  - ETA: 5s - loss: - ETA: 3s - loss: 0.2649 - ac - ETA: 2s - loss: 0.2654 - ac - ETA: 2s - loss: 0.2652 - acc: 0.909 - ETA: 2s - loss\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_7.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2655 - acc: 0.9092 - val_loss: 0.2674 - val_acc: 0.9065\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2654 - acc: 0.9097 - val_loss: 0.2708 - val_acc: 0.9062\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2646 - acc: 0.9095 - val_loss: 0.2759 - val_acc: 0.9062\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2647 - acc: 0.9095 - val_loss: 0.2693 - val_acc: 0.9064: 0.2648 - ETA: 0s - loss: 0.2650 - acc: 0.909 - ETA: 0s - loss: 0.2648 - acc\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2649 - acc: 0.9097 - val_loss: 0.2695 - val_acc: 0.9065 - loss: 0.2643 - acc: 0. - ETA: 1s - loss:\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2649 - acc: 0.9095 - val_loss: 0.2736 - val_acc: 0.9064 - acc: 0.909 - ETA: 2s - lo\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2642 - acc: 0.9095 - val_loss: 0.2723 - val_acc: 0.9065\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2647 - acc: 0.9094 - val_loss: 0.2739 - val_acc: 0.9062\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2643 - acc: 0.9098 - val_loss: 0.2757 - val_acc: 0.9062\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2638 - acc: 0.9097 - val_loss: 0.2711 - val_acc: 0.9065 3s - loss: 0.2667 - acc: 0 - ETA: 3s - loss: 0.2658 - acc: 0. - ETA: \n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2627 - acc: 0.9097 - val_loss: 0.2752 - val_acc: 0.9061\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2641 - acc: 0.9097 - val_loss: 0.2723 - val_acc: 0.9064\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2745 - val_acc: 0.9064\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2637 - acc: 0.9099 - val_loss: 0.2714 - val_acc: 0.9065\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2632 - acc: 0.9099 - val_loss: 0.2694 - val_acc: 0.9061\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2639 - acc: 0.9095 - val_loss: 0.2699 - val_acc: 0.9062\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2630 - acc: 0.9095 - val_loss: 0.2676 - val_acc: 0.9059\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2632 - acc: 0.9095 - val_loss: 0.2704 - val_acc: 0.90640.2633 - acc: 0.909\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2626 - acc: 0.9098 - val_loss: 0.2693 - val_acc: 0.9062\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2630 - acc: 0.9094 - val_loss: 0.2688 - val_acc: 0.9061\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9061\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2631 - acc: 0.9096 - val_loss: 0.2708 - val_acc: 0.9065\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2621 - acc: 0.9098 - val_loss: 0.2710 - val_acc: 0.9065ETA: 3s - loss: 0.2625 - acc: 0.9\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2633 - acc: 0.9095 - val_loss: 0.2726 - val_acc: 0.9065 loss: 0.2634 - ETA: 8s - loss: 0.2636 - acc: 0.909 - ETA: 8s - loss: 0.2637 - ac - ETA: 7s - loss: 0.2644 - acc: 0.909\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2621 - acc: 0.9104 - val_loss: 0.2712 - val_acc: 0.9062 10s - l - ETA: 8s - loss: 0.2607 - acc - ETA: 7s - loss: 0.2612 -  - ETA: 6s - loss - ETA: 4s - l - ETA: 2s - loss: 0.2621 - acc: 0.910 - ETA: 1s - loss: 0.2621 - a - ETA: 1s - loss: 0.2615 -\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2620 - acc: 0.9094 - val_loss: 0.2700 - val_acc: 0.9064 9s - loss: 0.264 - - ETA: 0s - loss: 0.2623 - \n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2619 - acc: 0.9096 - val_loss: 0.2722 - val_acc: 0.9061.2625 - acc - ETA: 7s - loss: 0.2623 -  - ETA: 2s \n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2625 - acc: 0.9097 - val_loss: 0.2709 - val_acc: 0.9065s - loss: 0.2604 - ETA:\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2613 - acc: 0.9097 - val_loss: 0.2712 - val_acc: 0.9066 2s -  - ETA: 0s - loss: 0.2615 - acc: 0.909 - ETA: 0s - loss: 0.2614 - acc: 0.9\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 25s 371us/step - loss: 0.2627 - acc: 0.9097 - val_loss: 0.2732 - val_acc: 0.9064\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2631 - acc: 0.9096 - val_loss: 0.2684 - val_acc: 0.9065\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2618 - acc: 0.9097 - val_loss: 0.2708 - val_acc: 0.9062 13s - loss: 0.2653 - ETA: 12s - loss: 0. - ET\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2710 - val_acc: 0.9064\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2603 - acc: 0.9094 - val_loss: 0.2651 - val_acc: 0.9066\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2600 - acc: 0.9095 - val_loss: 0.2719 - val_acc: 0.9064 10s - loss: 0.2589 - acc - ETA: 9s - loss: 0.2582 - ac - ETA: 8s - loss: 0.25 - ETA: 7s - loss: 0.2597 - acc: 0 - ETA: 6s - l - ET - ETA: 1s - loss: 0.2593 - - ETA: 0s - loss: 0.2599 - acc: 0.\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2626 - acc: 0.9096 - val_loss: 0.2708 - val_acc: 0.9064\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2602 - acc: 0.9096 - val_loss: 0.2724 - val_acc: 0.9064\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2601 - acc: 0.9098 - val_loss: 0.2716 - val_acc: 0.9065 -  - ETA: 20s - loss: 0.2593 - acc: 0.90 - ETA: 19s - - ETA: 5s - loss:  - ETA: 3s - loss: 0.2597  - ETA: 2s - loss: 0.2603 - a - ETA: 1s - loss: 0.2602 \n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2614 - acc: 0.9097 - val_loss: 0.2721 - val_acc: 0.9062\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2603 - acc: 0.9099 - val_loss: 0.2700 - val_acc: 0.9065\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2622 - acc: 0.9097 - val_loss: 0.2695 - val_acc: 0.9064loss: 0.2  - ETA: 1s - loss: 0.2626 -\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2596 - acc: 0.9096 - val_loss: 0.2683 - val_acc: 0.90620s - loss: 0.262 - ETA: 2s - lo\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2599 - acc: 0.9096 - val_loss: 0.2689 - val_acc: 0.9062 - - ETA: 7s - loss: 0.26 - ETA: 5s - loss\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2614 - acc: 0.9094 - val_loss: 0.2743 - val_acc: 0.9065loss: 0.2614 - acc: 0.\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2600 - acc: 0.9094 - val_loss: 0.2721 - val_acc: 0.9065\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.2603 - acc: 0.9100 - val_loss: 0.2670 - val_acc: 0.9064oss: 0.2610 \n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2600 - acc: 0.9095 - val_loss: 0.2713 - val_acc: 0.9062\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 26s 388us/step - loss: 0.2603 - acc: 0.9094 - val_loss: 0.2677 - val_acc: 0.9061\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.2600 - acc: 0.9100 - val_loss: 0.2689 - val_acc: 0.9064\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 26s 390us/step - loss: 0.2592 - acc: 0.9101 - val_loss: 0.2763 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_7.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2595 - acc: 0.9097 - val_loss: 0.2745 - val_acc: 0.9068\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.2585 - acc: 0.9099 - val_loss: 0.2707 - val_acc: 0.9064 - loss: 0.2584 - acc: 0.909 - ETA: 2s - loss\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2598 - acc: 0.9097 - val_loss: 0.2679 - val_acc: 0.9062\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2591 - acc: 0.9093 - val_loss: 0.2678 - val_acc: 0.9062 3s -  - ETA: 1s - loss: 0.2597 - acc: 0.909 - ETA: 1s - loss: 0.2595 - acc - ETA: 0s - loss: 0.2595 - acc\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2589 - acc: 0.9098 - val_loss: 0.2682 - val_acc: 0.9065- ac\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2599 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9064\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2596 - acc: 0.9093 - val_loss: 0.2724 - val_acc: 0.9064ss: 0.26 - ETA: 2s - loss: 0.2595 -  - ETA: 1s - loss: 0\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2582 - acc: 0.9098 - val_loss: 0.2723 - val_acc: 0.9061\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2585 - acc: 0.9095 - val_loss: 0.2709 - val_acc: 0.9062\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2598 - acc: 0.9101 - val_loss: 0.2667 - val_acc: 0.9064 - acc: 0.909 -  - ETA: 4s - loss: 0 - ETA: 2s - l\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.2572 - acc: 0.9097 - val_loss: 0.2716 - val_acc: 0.9062\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2587 - acc: 0.9097 - val_loss: 0.2693 - val_acc: 0.9062\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2583 - acc: 0.9095 - val_loss: 0.2660 - val_acc: 0.9062 4s - lo - ETA: 2s - loss: 0.2574 - acc: 0.909 - ETA: 2s - loss: 0. - ETA: 0s - loss: 0.2589 - acc: 0.9 - ETA: 0s - loss: 0.2590 - acc: 0.9 - ETA: 0s - loss: 0.2586 - acc: 0\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2579 - acc: 0.9099 - val_loss: 0.2670 - val_acc: 0.9059\n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2576 - acc: 0.9100 - val_loss: 0.2659 - val_acc: 0.9062  - ETA: 5s - l - ETA\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2580 - acc: 0.9095 - val_loss: 0.2715 - val_acc: 0.9061\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2585 - acc: 0.9097 - val_loss: 0.2696 - val_acc: 0.90664s - loss: 0.2592 - - ETA: 3s - loss: 0.2585 - acc: 0.9 - ETA: 3s - loss: 0 - ETA: 1s - loss: 0.2582 - ETA: 0s - loss: 0.2586 - acc: \n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2567 - acc: 0.9097 - val_loss: 0.2687 - val_acc: 0.9064\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2576 - acc: 0.9098 - val_loss: 0.2751 - val_acc: 0.9064loss: 0.2575 - acc: 0\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2592 - acc: 0.9099 - val_loss: 0.2704 - val_acc: 0.9065: 0.2582 -  - ETA: 4s - loss: 0.2579 - acc: 0.910 - ETA: 4s - loss: 0 - ETA: 3s - loss - ETA: 0s - loss: 0.2590 - \n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2581 - acc: 0.9100 - val_loss: 0.2694 - val_acc: 0.9065 2s - l\n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2578 - acc: 0.9097 - val_loss: 0.2690 - val_acc: 0.9065\n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2559 - acc: 0.9101 - val_loss: 0.2685 - val_acc: 0.9065\n",
      "Epoch 124/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2563 - acc: 0.9099 - val_loss: 0.2682 - val_acc: 0.9064 23s  - ETA: 14s - loss: 0. - ETA:  - ETA: 12s  - ETA: 10s - loss: 0.2528 - ET - ETA: 3s - loss: 0.2552 - acc:  - ETA: 3s - loss: 0.2557 - acc: 0.910 - ETA\n",
      "Epoch 125/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2570 - acc: 0.9096 - val_loss: 0.2672 - val_acc: 0.9065\n",
      "Epoch 126/1000\n",
      "66414/66414 [==============================] - 25s 373us/step - loss: 0.2588 - acc: 0.9096 - val_loss: 0.2723 - val_acc: 0.9068\n",
      "Epoch 127/1000\n",
      "66414/66414 [==============================] - 25s 375us/step - loss: 0.2571 - acc: 0.9098 - val_loss: 0.2689 - val_acc: 0.9062\n",
      "Epoch 128/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2577 - acc: 0.9099 - val_loss: 0.2694 - val_acc: 0.9065s - los - ETA: 2s - loss: 0.2567 - acc: 0.910 - ETA: 2s - loss: 0.25 - ETA: 1s - loss: 0.2571 -  - ETA: 0s - loss: 0.2577 - acc: 0.90\n",
      "Epoch 129/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2560 - acc: 0.9100 - val_loss: 0.2677 - val_acc: 0.9066\n",
      "Epoch 130/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2570 - acc: 0.9101 - val_loss: 0.2694 - val_acc: 0.9065\n",
      "Epoch 131/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2573 - acc: 0.9095 - val_loss: 0.2671 - val_acc: 0.9068s: 0.2549 - acc: 0.910 - ETA - ETA: 2s - loss: 0.2581  - ETA: 0s - loss: 0.2579 - \n",
      "Epoch 132/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2569 - acc: 0.9096 - val_loss: 0.2647 - val_acc: 0.9068\n",
      "Epoch 133/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2582 - acc: 0.9098 - val_loss: 0.2696 - val_acc: 0.9068 loss: 0.2588 -\n",
      "Epoch 134/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2567 - acc: 0.9096 - val_loss: 0.2690 - val_acc: 0.9068s: 0.2574 - acc:  - ETA: 3s - loss: 0.2572 - acc: 0.9 - ETA: 3s - loss: 0.2573 - acc: 0.908 - E\n",
      "Epoch 135/1000\n",
      "66414/66414 [==============================] - 25s 376us/step - loss: 0.2579 - acc: 0.9096 - val_loss: 0.2687 - val_acc: 0.9068\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2575 - acc: 0.9098 - val_loss: 0.2694 - val_acc: 0.9068\n",
      "Epoch 137/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2577 - acc: 0.9096 - val_loss: 0.2672 - val_acc: 0.9064\n",
      "Epoch 138/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2573 - acc: 0.9101 - val_loss: 0.2707 - val_acc: 0.9064\n",
      "Epoch 139/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2566 - acc: 0.9101 - val_loss: 0.2680 - val_acc: 0.9062\n",
      "Epoch 140/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2576 - acc: 0.9093 - val_loss: 0.2702 - val_acc: 0.9062\n",
      "Epoch 141/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2561 - acc: 0.9098 - val_loss: 0.2730 - val_acc: 0.9065- loss: 0.2535 - acc: - ETA: 3s - loss: 0 - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.2558 - acc: 0.909 - ETA: 0s - loss: 0.2559 - acc: 0.9\n",
      "Epoch 142/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2554 - acc: 0.9096 - val_loss: 0.2705 - val_acc: 0.9066oss: 0.2538 - ETA: 0s - loss: 0.2552 - acc: 0\n",
      "Epoch 143/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2567 - acc: 0.9101 - val_loss: 0.2671 - val_acc: 0.9066 0.2569 - acc: 0 - ETA: 5s - los\n",
      "Epoch 144/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2572 - acc: 0.9095 - val_loss: 0.2672 - val_acc: 0.9064ss: 0.2575 - a - ETA: 5s - loss: - ETA: 3s - loss - ETA: 1s - loss: 0.2573 - ETA: 0s - loss: 0.2566 - acc: 0.909 - ETA: 0s - loss: 0.2564 - acc: 0\n",
      "Epoch 145/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2561 - acc: 0.9098 - val_loss: 0.2712 - val_acc: 0.9068 loss: 0.2556 - acc: 0 - ETA: 2s - loss: 0.2557 - acc: 0.910 - ETA: 2s - loss: 0.2558 - - ETA: 1s - loss: 0.2558 -  - ETA: 0s - loss: 0.2560 - acc: 0.90\n",
      "Epoch 146/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2567 - acc: 0.9102 - val_loss: 0.2685 - val_acc: 0.9066 loss: 0.2561 - acc: 0.910 - ETA: 7s - lo - ETA: 1s - loss: 0.257\n",
      "Epoch 147/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2562 - acc: 0.9095 - val_loss: 0.2692 - val_acc: 0.9066 0.2562 - - ETA: 0s - loss: 0.2557 - \n",
      "Epoch 148/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2561 - acc: 0.9101 - val_loss: 0.2702 - val_acc: 0.9066\n",
      "Epoch 149/1000\n",
      "66414/66414 [==============================] - 25s 374us/step - loss: 0.2556 - acc: 0.9099 - val_loss: 0.2691 - val_acc: 0.9064\n",
      "Epoch 150/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2558 - acc: 0.9099 - val_loss: 0.2700 - val_acc: 0.9064s: 0.2559 - acc: 0.9 - ETA: 1s - loss: 0.25\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_7.hdf5\n",
      "Epoch 151/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2574 - acc: 0.9100 - val_loss: 0.2706 - val_acc: 0.9066s - loss: 0.2571 - acc: - ETA: 6s - loss: 0.2566  - ETA: 5s - loss:\n",
      "Epoch 152/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2551 - acc: 0.9098 - val_loss: 0.2695 - val_acc: 0.9065: 1s - loss: 0.2548 -  - ETA: 0s - loss: 0.2544 - acc\n",
      "Epoch 153/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2557 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9066\n",
      "Epoch 154/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2555 - acc: 0.9097 - val_loss: 0.2672 - val_acc: 0.9068: - ETA: 5s - loss: 0.2571 -  - ETA - ETA: 1s - loss: 0.2559 - acc: 0.9 - ETA: 0s - loss: 0.2558 - \n",
      "Epoch 155/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2552 - acc: 0.9100 - val_loss: 0.2670 - val_acc: 0.9068s: 0.2537 - acc: 0.911 - ETA: 7s - loss:  - ETA: 5s - loss: 0.2537 - acc - ETA: 0s - loss: 0.2555 - acc:  - ETA: 0s - loss: 0.2553 - acc: 0.\n",
      "Epoch 156/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2566 - acc: 0.9099 - val_loss: 0.2683 - val_acc: 0.9069\n",
      "Epoch 157/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2564 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9068\n",
      "Epoch 158/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2535 - acc: 0.9099 - val_loss: 0.2666 - val_acc: 0.9066ss: 0.253 - ETA: 3s - loss:  - ETA: 1s - loss: 0.2532 \n",
      "Epoch 159/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2552 - acc: 0.9099 - val_loss: 0.2690 - val_acc: 0.9069\n",
      "Epoch 160/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2560 - acc: 0.9101 - val_loss: 0.2686 - val_acc: 0.9068\n",
      "Epoch 161/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2565 - acc: 0.9104 - val_loss: 0.2684 - val_acc: 0.90622565 - acc: 0.9 - ETA: 0s - loss: 0.2563 - acc: 0\n",
      "Epoch 162/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2553 - acc: 0.9102 - val_loss: 0.2667 - val_acc: 0.9066loss: 0.2542 - acc: 0.9 - ETA: 3s - loss: 0.2541 - acc: - ETA: 2s - loss: 0.2547 - acc: 0. - ETA: 2s - loss: 0. - ETA: 0s - loss: 0.2557 - ac\n",
      "Epoch 163/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2549 - acc: 0.9104 - val_loss: 0.2710 - val_acc: 0.9062550 - acc: 0.910\n",
      "Epoch 164/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2555 - acc: 0.9095 - val_loss: 0.2670 - val_acc: 0.9064TA: 3s - ETA: 0s - loss: 0.2561 - acc: \n",
      "Epoch 165/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2554 - acc: 0.9101 - val_loss: 0.2656 - val_acc: 0.9065\n",
      "Epoch 166/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2571 - acc: 0.9098 - val_loss: 0.2692 - val_acc: 0.9065\n",
      "Epoch 167/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2542 - acc: 0.9094 - val_loss: 0.2667 - val_acc: 0.9064\n",
      "Epoch 168/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2554 - acc: 0.9099 - val_loss: 0.2729 - val_acc: 0.9064\n",
      "Epoch 169/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2543 - acc: 0.9099 - val_loss: 0.2675 - val_acc: 0.9061 2\n",
      "Epoch 170/1000\n",
      "66414/66414 [==============================] - 25s 378us/step - loss: 0.2547 - acc: 0.9103 - val_loss: 0.2659 - val_acc: 0.9062\n",
      "Epoch 171/1000\n",
      "66414/66414 [==============================] - 25s 372us/step - loss: 0.2539 - acc: 0.9099 - val_loss: 0.2668 - val_acc: 0.9065\n",
      "Epoch 172/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2558 - acc: 0.9093 - val_loss: 0.2677 - val_acc: 0.90660 - ETA: 5 - ETA: 2s \n",
      "Epoch 173/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2555 - acc: 0.9099 - val_loss: 0.2676 - val_acc: 0.9062 17s - loss: 0. - ETA: 16s - loss - ETA: 9s - loss: 0.2569  - ETA: 8s - loss: 0.2574 - acc: 0.9 - E - ETA: 0s - loss: 0.2561 - a\n",
      "Epoch 174/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2539 - acc: 0.9104 - val_loss: 0.2684 - val_acc: 0.9066\n",
      "Epoch 175/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2540 - acc: 0.9101 - val_loss: 0.2690 - val_acc: 0.9069oss: 0.2531  - ETA: 0s - loss: 0.2535 - acc:\n",
      "Epoch 176/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2530 - acc: 0.9100 - val_loss: 0.2679 - val_acc: 0.9065\n",
      "Epoch 177/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2555 - acc: 0.9100 - val_loss: 0.2692 - val_acc: 0.9065cc: 0. - ETA: 0s - loss: 0.2553 - acc\n",
      "Epoch 178/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2555 - acc: 0.9100 - val_loss: 0.2704 - val_acc: 0.9068\n",
      "Epoch 179/1000\n",
      "66414/66414 [==============================] - 24s 363us/step - loss: 0.2535 - acc: 0.9095 - val_loss: 0.2679 - val_acc: 0.9065\n",
      "Epoch 180/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2542 - acc: 0.9098 - val_loss: 0.2673 - val_acc: 0.9069\n",
      "Epoch 181/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2527 - acc: 0.9101 - val_loss: 0.2677 - val_acc: 0.9068\n",
      "Epoch 182/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2537 - acc: 0.9100 - val_loss: 0.2678 - val_acc: 0.9068\n",
      "AUC: 0.787256\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 24s 354us/step - loss: 0.3078 - acc: 0.9082 - val_loss: 0.3372 - val_acc: 0.9087.3070 \n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 23s 344us/step - loss: 0.2951 - acc: 0.9095 - val_loss: 0.2922 - val_acc: 0.9087\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2928 - acc: 0.9095 - val_loss: 0.2977 - val_acc: 0.9087\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2897 - acc: 0.9095 - val_loss: 0.2879 - val_acc: 0.9087\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2858 - acc: 0.9095 - val_loss: 0.2905 - val_acc: 0.9087\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2840 - acc: 0.9094 - val_loss: 0.2848 - val_acc: 0.9087\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 23s 344us/step - loss: 0.2821 - acc: 0.9094 - val_loss: 0.2852 - val_acc: 0.9088\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2813 - acc: 0.9094 - val_loss: 0.2774 - val_acc: 0.90872806 - acc: 0. - ETA: 0s - loss: 0.2807 - a\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2803 - acc: 0.9094 - val_loss: 0.2810 - val_acc: 0.9088\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2785 - acc: 0.9094 - val_loss: 0.2858 - val_acc: 0.9088\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2792 - acc: 0.9094 - val_loss: 0.2829 - val_acc: 0.9088\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2768 - acc: 0.9094 - val_loss: 0.2997 - val_acc: 0.9085\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2759 - acc: 0.9094 - val_loss: 0.2732 - val_acc: 0.9089\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2764 - acc: 0.9094 - val_loss: 0.2799 - val_acc: 0.9089\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 355us/step - loss: 0.2746 - acc: 0.9092 - val_loss: 0.2751 - val_acc: 0.9087\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2737 - acc: 0.9095 - val_loss: 0.2803 - val_acc: 0.9083 0.2\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 23s 343us/step - loss: 0.2735 - acc: 0.9094 - val_loss: 0.2732 - val_acc: 0.9088 - loss: 0.2741 - acc: 0 - ETA: 7s - loss: 0.2737 - ac - ETA: 6s - loss: - ETA: - ETA: 2s \n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 23s 343us/step - loss: 0.2729 - acc: 0.9094 - val_loss: 0.2744 - val_acc: 0.90890s - loss: 0.2736 - acc:\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2739 - acc: 0.9094 - val_loss: 0.2714 - val_acc: 0.9091 - loss - ETA: 8s - loss: 0. - ETA: 0s - loss: 0.2741 - acc: \n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2729 - acc: 0.9093 - val_loss: 0.2720 - val_acc: 0.9088\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 23s 344us/step - loss: 0.2719 - acc: 0.9095 - val_loss: 0.2781 - val_acc: 0.90840s - loss: 0.2718 - ac\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2717 - acc: 0.9093 - val_loss: 0.2761 - val_acc: 0.9091\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2710 - acc: 0.9095 - val_loss: 0.2681 - val_acc: 0.9087\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2709 - acc: 0.9094 - val_loss: 0.2694 - val_acc: 0.9088\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2696 - acc: 0.9093 - val_loss: 0.2752 - val_acc: 0.9088\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2701 - acc: 0.9092 - val_loss: 0.2804 - val_acc: 0.9085\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2703 - acc: 0.9094 - val_loss: 0.2722 - val_acc: 0.9088\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2692 - acc: 0.9093 - val_loss: 0.2706 - val_acc: 0.9085\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2689 - acc: 0.9091 - val_loss: 0.2801 - val_acc: 0.9091\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2685 - acc: 0.9096 - val_loss: 0.2730 - val_acc: 0.9085oss: 0.2692 - ac\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2687 - acc: 0.9093 - val_loss: 0.2772 - val_acc: 0.9085\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2689 - acc: 0.9093 - val_loss: 0.2834 - val_acc: 0.9085\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2682 - acc: 0.9095 - val_loss: 0.2760 - val_acc: 0.90911s - loss:\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2679 - acc: 0.9095 - val_loss: 0.2811 - val_acc: 0.9088\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2679 - acc: 0.9095 - val_loss: 0.2767 - val_acc: 0.908990 - ETA: 6s - loss: 0.2679 - acc - ETA: 6s - loss: 0.2675  - ETA: 5s -  - ETA: 2s - loss: 0.2671 - acc: 0.91 - ETA: 2s - loss: 0.2674 -  - ETA: 1s - loss: \n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2675 - acc: 0.9094 - val_loss: 0.2817 - val_acc: 0.9088\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2668 - acc: 0.9093 - val_loss: 0.2814 - val_acc: 0.9087\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2685 - acc: 0.9095 - val_loss: 0.2740 - val_acc: 0.9087\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2676 - acc: 0.9093 - val_loss: 0.2779 - val_acc: 0.90899s - loss: 0.2679 - acc: 0 - ETA: 9s - l - ETA: 0s - loss: 0.2681 - acc: 0.\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 23s 344us/step - loss: 0.2661 - acc: 0.9093 - val_loss: 0.2732 - val_acc: 0.9093\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2665 - acc: 0.9097 - val_loss: 0.2714 - val_acc: 0.9085\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2665 - acc: 0.9095 - val_loss: 0.2784 - val_acc: 0.9088\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2655 - acc: 0.9096 - val_loss: 0.2761 - val_acc: 0.90910.2655 - ac - ETA: 0s - loss: 0.2651 - acc: 0\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 23s 340us/step - loss: 0.2663 - acc: 0.9094 - val_loss: 0.2767 - val_acc: 0.9088\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2669 - acc: 0.9092 - val_loss: 0.2781 - val_acc: 0.9091\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2659 - acc: 0.9092 - val_loss: 0.2697 - val_acc: 0.9087acc: 0.9 - ETA: 2s \n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2666 - acc: 0.9091 - val_loss: 0.2710 - val_acc: 0.9087loss: 0.2689 - acc: 0. - ETA: 5s - loss: 0.2677 - acc: 0. - ETA: 5s - \n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2665 - acc: 0.9092 - val_loss: 0.2794 - val_acc: 0.9089\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2659 - acc: 0.9092 - val_loss: 0.2757 - val_acc: 0.9092\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 23s 344us/step - loss: 0.2656 - acc: 0.9093 - val_loss: 0.2719 - val_acc: 0.9093669 - acc: 0.90 - ETA: 7s - loss: 0 - ETA: 2s - loss: 0.2672  - ETA: 1s - loss\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_8.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2646 - acc: 0.9091 - val_loss: 0.2771 - val_acc: 0.9093\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 23s 343us/step - loss: 0.2635 - acc: 0.9094 - val_loss: 0.2787 - val_acc: 0.9089\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2635 - acc: 0.9096 - val_loss: 0.2757 - val_acc: 0.90880s - loss: 0.2635 - acc:  - ETA: 0s - loss: 0.2635 - acc: 0.9\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 23s 343us/step - loss: 0.2647 - acc: 0.9092 - val_loss: 0.2710 - val_acc: 0.9088 ETA: 4s - loss: 0.2637  - ETA: 0s - loss: 0.2654 - acc: 0.9\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2647 - acc: 0.9095 - val_loss: 0.2756 - val_acc: 0.9087\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2649 - acc: 0.9094 - val_loss: 0.2734 - val_acc: 0.9087\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 23s 339us/step - loss: 0.2646 - acc: 0.9093 - val_loss: 0.2771 - val_acc: 0.9089\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2631 - acc: 0.9095 - val_loss: 0.2772 - val_acc: 0.9091A: 1s - loss:\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2626 - acc: 0.9093 - val_loss: 0.2803 - val_acc: 0.9097\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2635 - acc: 0.9092 - val_loss: 0.2733 - val_acc: 0.9088\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2624 - acc: 0.9094 - val_loss: 0.2681 - val_acc: 0.90856s - loss: 0.2636 - acc: 0 - ETA: 6s - loss: 0.2632 - acc:  - ETA: 5s - l\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2632 - acc: 0.9097 - val_loss: 0.2718 - val_acc: 0.9089\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 23s 344us/step - loss: 0.2640 - acc: 0.9091 - val_loss: 0.2741 - val_acc: 0.9083- ETA: 0s - loss: 0.2640 - acc: 0.909\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 23s 354us/step - loss: 0.2643 - acc: 0.9096 - val_loss: 0.2720 - val_acc: 0.9087loss: 0.2641 - acc: 0.90 - ETA: 1s - loss: 0.2\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2628 - acc: 0.9087 - val_loss: 0.2716 - val_acc: 0.9087\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2634 - acc: 0.9093 - val_loss: 0.2780 - val_acc: 0.9085- loss: 0.2637 - - ETA: 3s - loss: 0.2637 - ETA: 2s - loss: 0.2631 - acc: 0. - ETA: 1s - loss: \n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 24s 356us/step - loss: 0.2624 - acc: 0.9098 - val_loss: 0.2749 - val_acc: 0.90877s - ETA: 1s - loss: 0.2623 -  - ETA: 0s - loss: 0.2621 - acc: 0.9\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2627 - acc: 0.9093 - val_loss: 0.2725 - val_acc: 0.9087\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2623 - acc: 0.9095 - val_loss: 0.2707 - val_acc: 0.9085\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2620 - acc: 0.9091 - val_loss: 0.2681 - val_acc: 0.9088\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2620 - acc: 0.9093 - val_loss: 0.2734 - val_acc: 0.9087\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2623 - acc: 0.9095 - val_loss: 0.2793 - val_acc: 0.9088\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2621 - acc: 0.9094 - val_loss: 0.2757 - val_acc: 0.9092\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2615 - acc: 0.9096 - val_loss: 0.2713 - val_acc: 0.9087\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2633 - acc: 0.9090 - val_loss: 0.2749 - val_acc: 0.9088oss: 0.2640 - ac - ETA: 1s - loss: 0.2640 - ac - ETA: 0s - loss: 0.2631 - acc\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2613 - acc: 0.9091 - val_loss: 0.2732 - val_acc: 0.9085: 0.2606 - acc: \n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2617 - acc: 0.9096 - val_loss: 0.2766 - val_acc: 0.9092 lo -  - ETA: 9s - loss: 0.2588 - acc - ETA: 8s - loss: - ETA: 6s - loss: 0.2601 - acc:  - ETA: 6s - los - ETA: 3s - loss: 0.2593 - acc: 0.9 - ETA: 3s - loss: 0.2 - ETA: 2s - l\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2610 - acc: 0.9094 - val_loss: 0.2713 - val_acc: 0.9091 - loss: 0\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2604 - acc: 0.9091 - val_loss: 0.2701 - val_acc: 0.9089.25\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2619 - acc: 0.9092 - val_loss: 0.2738 - val_acc: 0.9091- ETA: 0s - loss: 0.2619 - acc:\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2613 - acc: 0.9093 - val_loss: 0.2708 - val_acc: 0.9088\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 23s 343us/step - loss: 0.2615 - acc: 0.9093 - val_loss: 0.2709 - val_acc: 0.9091\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2601 - acc: 0.9092 - val_loss: 0.2695 - val_acc: 0.9089\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2610 - acc: 0.9092 - val_loss: 0.2716 - val_acc: 0.9089\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2611 - acc: 0.9096 - val_loss: 0.2708 - val_acc: 0.90918 - acc:\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2603 - acc: 0.9093 - val_loss: 0.2710 - val_acc: 0.9083\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2607 - acc: 0.9095 - val_loss: 0.2688 - val_acc: 0.9089\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 24s 355us/step - loss: 0.2594 - acc: 0.9095 - val_loss: 0.2747 - val_acc: 0.9085\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2596 - acc: 0.9093 - val_loss: 0.2715 - val_acc: 0.9085 - \n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 23s 344us/step - loss: 0.2613 - acc: 0.9094 - val_loss: 0.2724 - val_acc: 0.9088s - loss: 0.2636 - acc:  - ETA: 9s - lo - ETA: 7s - loss: 0.2606  - ETA: 6s - loss - ETA: 4s - ETA: 1s - loss: 0\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2588 - acc: 0.9094 - val_loss: 0.2703 - val_acc: 0.9085 -  - ETA: 0s - loss: 0.2587 - acc: 0.9\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2599 - acc: 0.9092 - val_loss: 0.2715 - val_acc: 0.9088\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2606 - acc: 0.9088 - val_loss: 0.2747 - val_acc: 0.9089\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2608 - acc: 0.9097 - val_loss: 0.2746 - val_acc: 0.9085\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2599 - acc: 0.9095 - val_loss: 0.2681 - val_acc: 0.90859s - loss: 0.2624 - acc: 0.909 - ETA: 9s - los - ETA: 7s - loss: 0.2617  - ETA: 5s - loss: 0.2629 - acc: 0.90 - ETA: 5s - loss: 0.2633 - ac - ETA: 4s - loss: 0.2624 - ac - ETA: 4s - loss: 0.2620 - ac\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2594 - acc: 0.9095 - val_loss: 0.2732 - val_acc: 0.9093\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2599 - acc: 0.9093 - val_loss: 0.2734 - val_acc: 0.9091\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2586 - acc: 0.9097 - val_loss: 0.2699 - val_acc: 0.9091\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2594 - acc: 0.9093 - val_loss: 0.2736 - val_acc: 0.9088\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2602 - acc: 0.9096 - val_loss: 0.2679 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_8.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2580 - acc: 0.9095 - val_loss: 0.2740 - val_acc: 0.9087\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2596 - acc: 0.9093 - val_loss: 0.2692 - val_acc: 0.9087\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 24s 354us/step - loss: 0.2596 - acc: 0.9091 - val_loss: 0.2713 - val_acc: 0.9091 4s - loss: 0.2 - ETA: 3s - ETA: 0s - loss: 0.2599 - acc: \n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 24s 354us/step - loss: 0.2588 - acc: 0.9094 - val_loss: 0.2726 - val_acc: 0.9089 loss: 0.2577 - - ETA: 1s - loss: 0.2581 -\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2589 - acc: 0.9096 - val_loss: 0.2718 - val_acc: 0.9084\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 24s 357us/step - loss: 0.2600 - acc: 0.9096 - val_loss: 0.2714 - val_acc: 0.9091\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2577 - acc: 0.9093 - val_loss: 0.2695 - val_acc: 0.9087\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2600 - acc: 0.9094 - val_loss: 0.2702 - val_acc: 0.9088\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2594 - acc: 0.9094 - val_loss: 0.2713 - val_acc: 0.9085- loss: 0.259 - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.2591 - acc: 0.9\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2581 - acc: 0.9093 - val_loss: 0.2722 - val_acc: 0.9088\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2589 - acc: 0.9094 - val_loss: 0.2708 - val_acc: 0.9083\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2572 - acc: 0.9096 - val_loss: 0.2710 - val_acc: 0.9088\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2586 - acc: 0.9093 - val_loss: 0.2700 - val_acc: 0.9091\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 24s 356us/step - loss: 0.2589 - acc: 0.9093 - val_loss: 0.2733 - val_acc: 0.9085s - loss: 0.2 - ETA: 7s - loss: 0.2590 - acc: 0.9  - ETA: 4s - loss: 0.2581 - - ETA: 3s - loss: 0.2592 - ac - ETA: 2s - l\n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2591 - acc: 0.9096 - val_loss: 0.2718 - val_acc: 0.9089- acc: 0.90 - ETA: 3s - loss: 0.2590 -  - ETA: 2s - loss: 0.2591 - acc: 0. - ETA: 1s - loss:\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 24s 358us/step - loss: 0.2588 - acc: 0.9092 - val_loss: 0.2709 - val_acc: 0.9089\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2581 - acc: 0.9089 - val_loss: 0.2706 - val_acc: 0.9091\n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2589 - acc: 0.9093 - val_loss: 0.2738 - val_acc: 0.9092\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2578 - acc: 0.9097 - val_loss: 0.2731 - val_acc: 0.9091\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 24s 354us/step - loss: 0.2569 - acc: 0.9092 - val_loss: 0.2688 - val_acc: 0.9087\n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 24s 356us/step - loss: 0.2562 - acc: 0.9097 - val_loss: 0.2759 - val_acc: 0.90910.2 - ETA: 2s - loss: 0.2547 - ETA: 0s - loss: 0.2556 - acc: 0 - ETA: 0s - loss: 0.2561 - acc: 0\n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 24s 356us/step - loss: 0.2587 - acc: 0.9092 - val_loss: 0.2701 - val_acc: 0.9088\n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2569 - acc: 0.9100 - val_loss: 0.2707 - val_acc: 0.9085\n",
      "Epoch 124/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2573 - acc: 0.9095 - val_loss: 0.2714 - val_acc: 0.9087\n",
      "Epoch 125/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2573 - acc: 0.9094 - val_loss: 0.2731 - val_acc: 0.9091\n",
      "Epoch 126/1000\n",
      "66414/66414 [==============================] - 24s 357us/step - loss: 0.2572 - acc: 0.9100 - val_loss: 0.2705 - val_acc: 0.9089 0.2554 - acc - ETA: 13s -  - ETA: 12s -  - ETA:  - ETA: 2s - lo\n",
      "Epoch 127/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2566 - acc: 0.9102 - val_loss: 0.2725 - val_acc: 0.90920.2563 - acc:\n",
      "Epoch 128/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2560 - acc: 0.9097 - val_loss: 0.2722 - val_acc: 0.9089\n",
      "Epoch 129/1000\n",
      "66414/66414 [==============================] - 24s 358us/step - loss: 0.2574 - acc: 0.9093 - val_loss: 0.2699 - val_acc: 0.9085 14s  - ETA: 12s - loss - ETA: 6s - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.2580  - ETA: 1s - loss: 0.2580 -\n",
      "Epoch 130/1000\n",
      "66414/66414 [==============================] - 23s 354us/step - loss: 0.2565 - acc: 0.9093 - val_loss: 0.2724 - val_acc: 0.9091ss: 0.256 - ETA: 8s - loss: 0.2562 -  - ETA: 3s - loss: 0.2566 - acc: 0.9 - ETA: 3s - loss: - ETA: 1s - loss: 0.2\n",
      "Epoch 131/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2576 - acc: 0.9096 - val_loss: 0.2669 - val_acc: 0.9087s - loss: \n",
      "Epoch 132/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2562 - acc: 0.9097 - val_loss: 0.2754 - val_acc: 0.9089\n",
      "Epoch 133/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2569 - acc: 0.9093 - val_loss: 0.2695 - val_acc: 0.9093: 0s - loss: 0.2566 - acc: 0.\n",
      "Epoch 134/1000\n",
      "66414/66414 [==============================] - 24s 355us/step - loss: 0.2569 - acc: 0.9093 - val_loss: 0.2710 - val_acc: 0.9093- ETA: 5s - loss: 0.2581 - ac - ETA: 4s - loss: 0.2577 -  - ETA: 3s - loss: 0.2573 - acc: 0.90 \n",
      "Epoch 135/1000\n",
      "66414/66414 [==============================] - 24s 354us/step - loss: 0.2570 - acc: 0.9096 - val_loss: 0.2709 - val_acc: 0.9091\n",
      "Epoch 136/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2573 - acc: 0.9093 - val_loss: 0.2711 - val_acc: 0.9088\n",
      "Epoch 137/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2570 - acc: 0.9094 - val_loss: 0.2689 - val_acc: 0.9087\n",
      "Epoch 138/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2557 - acc: 0.9093 - val_loss: 0.2704 - val_acc: 0.90926s - loss: 0.2 - ETA: 4s - loss: 0.\n",
      "Epoch 139/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2561 - acc: 0.9093 - val_loss: 0.2705 - val_acc: 0.9092 - loss: 0.2572 - acc - - ETA: 2s \n",
      "Epoch 140/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2571 - acc: 0.9101 - val_loss: 0.2695 - val_acc: 0.9087\n",
      "Epoch 141/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2570 - acc: 0.9093 - val_loss: 0.2700 - val_acc: 0.9095\n",
      "Epoch 142/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2551 - acc: 0.9097 - val_loss: 0.2707 - val_acc: 0.9087oss:  - ETA: 9s -  - ETA: 6s - ETA: 4s - loss: 0.255 - ETA: 2s  - ETA: 0s - loss: 0.2551 - acc: 0\n",
      "Epoch 143/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2551 - acc: 0.9099 - val_loss: 0.2694 - val_acc: 0.9092: 0\n",
      "Epoch 144/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2564 - acc: 0.9096 - val_loss: 0.2700 - val_acc: 0.9085s - loss: 0.2537 - ETA: 7s - loss: 0.2535 - ac - ETA: 0s - loss: 0.2559 - acc: 0.9\n",
      "Epoch 145/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2570 - acc: 0.9098 - val_loss: 0.2721 - val_acc: 0.9087  - ETA: \n",
      "Epoch 146/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2572 - acc: 0.9093 - val_loss: 0.2688 - val_acc: 0.90872 - acc\n",
      "Epoch 147/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2559 - acc: 0.9093 - val_loss: 0.2700 - val_acc: 0.9088- ETA: 2s -\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2555 - acc: 0.9100 - val_loss: 0.2694 - val_acc: 0.9088\n",
      "Epoch 149/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2549 - acc: 0.9098 - val_loss: 0.2730 - val_acc: 0.9092\n",
      "Epoch 150/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2553 - acc: 0.9095 - val_loss: 0.2723 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_8.hdf5\n",
      "Epoch 151/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2556 - acc: 0.9091 - val_loss: 0.2715 - val_acc: 0.9087\n",
      "Epoch 152/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2557 - acc: 0.9095 - val_loss: 0.2717 - val_acc: 0.9089.25 - ETA: 9s \n",
      "Epoch 153/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2549 - acc: 0.9098 - val_loss: 0.2696 - val_acc: 0.9091\n",
      "Epoch 154/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2547 - acc: 0.9098 - val_loss: 0.2745 - val_acc: 0.9089: 3s - los - ETA: 0s - loss: 0.2541 -\n",
      "Epoch 155/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2542 - acc: 0.9096 - val_loss: 0.2723 - val_acc: 0.9096\n",
      "Epoch 156/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2552 - acc: 0.9092 - val_loss: 0.2706 - val_acc: 0.9088.2551 -\n",
      "Epoch 157/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2552 - acc: 0.9100 - val_loss: 0.2677 - val_acc: 0.9092\n",
      "Epoch 158/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2554 - acc: 0.9099 - val_loss: 0.2712 - val_acc: 0.90879s - lo - ETA: 4s - loss: 0. - ETA: 2s - loss: 0.2548 - - ETA: 1s - loss: \n",
      "Epoch 159/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2541 - acc: 0.9096 - val_loss: 0.2704 - val_acc: 0.9088oss: 0.2536 - acc: 0.91 - ETA - ETA: 1s - loss:\n",
      "Epoch 160/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2550 - acc: 0.9095 - val_loss: 0.2687 - val_acc: 0.9089oss: 0.2 - ETA: 0s - loss: 0.2548 - acc: 0.9\n",
      "Epoch 161/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2563 - acc: 0.9095 - val_loss: 0.2697 - val_acc: 0.9087\n",
      "Epoch 162/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2554 - acc: 0.9100 - val_loss: 0.2683 - val_acc: 0.9088oss: 0.2554 - acc: 0.910\n",
      "Epoch 163/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2551 - acc: 0.9097 - val_loss: 0.2674 - val_acc: 0.9088\n",
      "Epoch 164/1000\n",
      "66414/66414 [==============================] - 24s 359us/step - loss: 0.2538 - acc: 0.9098 - val_loss: 0.2719 - val_acc: 0.9088.2535 - acc: 0.9 - ETA: 1s - loss: 0.2538 - a - ETA: 0s - loss: 0.2539 - acc: 0.90\n",
      "Epoch 165/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2569 - acc: 0.9094 - val_loss: 0.2710 - val_acc: 0.9089\n",
      "Epoch 166/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2528 - acc: 0.9095 - val_loss: 0.2716 - val_acc: 0.9091\n",
      "Epoch 167/1000\n",
      "66414/66414 [==============================] - 23s 346us/step - loss: 0.2534 - acc: 0.9096 - val_loss: 0.2678 - val_acc: 0.9093 acc:  - ETA: 5s - - ETA: 3s - loss: 0.2538 - acc:  - ETA: \n",
      "Epoch 168/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2549 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9091\n",
      "Epoch 169/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2541 - acc: 0.9096 - val_loss: 0.2708 - val_acc: 0.9089acc: 0.9 - ETA: 0s - loss: 0.2537 - acc:\n",
      "Epoch 170/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2544 - acc: 0.9096 - val_loss: 0.2692 - val_acc: 0.9092\n",
      "Epoch 171/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2539 - acc: 0.9096 - val_loss: 0.2720 - val_acc: 0.9089- ETA: 0s - loss: 0.2537 - acc:\n",
      "Epoch 172/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2542 - acc: 0.9094 - val_loss: 0.2698 - val_acc: 0.90891s - loss: \n",
      "Epoch 173/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2536 - acc: 0.9099 - val_loss: 0.2709 - val_acc: 0.9093 9s - loss:  - ETA: 7s - loss: 0.2547 - ac - ETA:  - ETA: 3s - loss: 0.2543 - acc: 0.9 - ETA: 3s  - ETA: 1s - loss: 0.2531 - acc: 0.910 - ETA: 1s - loss: 0.2531 - - ETA: 0s - loss: 0.2535 - acc: 0.90\n",
      "Epoch 174/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2545 - acc: 0.9095 - val_loss: 0.2712 - val_acc: 0.9091\n",
      "Epoch 175/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2534 - acc: 0.9100 - val_loss: 0.2672 - val_acc: 0.9089\n",
      "Epoch 176/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2528 - acc: 0.9097 - val_loss: 0.2711 - val_acc: 0.90957 \n",
      "Epoch 177/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2549 - acc: 0.9097 - val_loss: 0.2678 - val_acc: 0.9095\n",
      "Epoch 178/1000\n",
      "66414/66414 [==============================] - 23s 345us/step - loss: 0.2546 - acc: 0.9092 - val_loss: 0.2686 - val_acc: 0.90930s - loss: 0.2545 - acc: \n",
      "Epoch 179/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2530 - acc: 0.9094 - val_loss: 0.2716 - val_acc: 0.9093 ETA: 0s - loss: 0.2528 - acc: 0.\n",
      "Epoch 180/1000\n",
      "66414/66414 [==============================] - 24s 364us/step - loss: 0.2533 - acc: 0.9101 - val_loss: 0.2718 - val_acc: 0.9095\n",
      "Epoch 181/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2532 - acc: 0.9100 - val_loss: 0.2698 - val_acc: 0.9097\n",
      "AUC: 0.769750\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.3072 - acc: 0.9084 - val_loss: 0.3142 - val_acc: 0.9088\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2966 - acc: 0.9094 - val_loss: 0.2986 - val_acc: 0.908868 - acc: 0. - ETA: 2s \n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 24s 355us/step - loss: 0.2924 - acc: 0.9094 - val_loss: 0.2902 - val_acc: 0.9088ss: - ETA: 1s - loss: 0.2933 - ETA: 0s - loss: 0.2926 - acc: 0.9\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2891 - acc: 0.9094 - val_loss: 0.2816 - val_acc: 0.9088: 0.28  - ETA: 5s - loss: 0.2901 - ac - ETA: 4s - loss: 0.2 - ET\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2868 - acc: 0.9094 - val_loss: 0.2938 - val_acc: 0.9088- loss:  - ETA: \n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2846 - acc: 0.9095 - val_loss: 0.2768 - val_acc: 0.9088\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2842 - acc: 0.9094 - val_loss: 0.2852 - val_acc: 0.9087\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2828 - acc: 0.9095 - val_loss: 0.2856 - val_acc: 0.9088: 0s - loss: 0.2830 - acc: 0.90\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2817 - acc: 0.9094 - val_loss: 0.2889 - val_acc: 0.9088\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2805 - acc: 0.9094 - val_loss: 0.2805 - val_acc: 0.9087\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2782 - acc: 0.9095 - val_loss: 0.2672 - val_acc: 0.9087\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2780 - acc: 0.9095 - val_loss: 0.2742 - val_acc: 0.9087\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2782 - acc: 0.9094 - val_loss: 0.2764 - val_acc: 0.9087\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2779 - acc: 0.9094 - val_loss: 0.2724 - val_acc: 0.9088\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2760 - acc: 0.9094 - val_loss: 0.2677 - val_acc: 0.9089\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2753 - acc: 0.9096 - val_loss: 0.2702 - val_acc: 0.90898s - lo\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2751 - acc: 0.9093 - val_loss: 0.2718 - val_acc: 0.9089\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2752 - acc: 0.9094 - val_loss: 0.2726 - val_acc: 0.9085\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2752 - acc: 0.9094 - val_loss: 0.2860 - val_acc: 0.9088s: 0.2745 \n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 23s 343us/step - loss: 0.2742 - acc: 0.9094 - val_loss: 0.2699 - val_acc: 0.9087\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2732 - acc: 0.9094 - val_loss: 0.2774 - val_acc: 0.9088\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2736 - acc: 0.9093 - val_loss: 0.2748 - val_acc: 0.9088 - loss: 0.27\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2729 - acc: 0.9093 - val_loss: 0.2696 - val_acc: 0.9088272 - ETA: 0s - loss: 0.2729 - acc\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2728 - acc: 0.9094 - val_loss: 0.2684 - val_acc: 0.9089\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2719 - acc: 0.9093 - val_loss: 0.2683 - val_acc: 0.9088\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2722 - acc: 0.9095 - val_loss: 0.2633 - val_acc: 0.9088\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2724 - acc: 0.9095 - val_loss: 0.2745 - val_acc: 0.9089\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2717 - acc: 0.9094 - val_loss: 0.2748 - val_acc: 0.9091\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2714 - acc: 0.9092 - val_loss: 0.2727 - val_acc: 0.9088\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2704 - acc: 0.9093 - val_loss: 0.2694 - val_acc: 0.9088\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2708 - acc: 0.9094 - val_loss: 0.2693 - val_acc: 0.90890s - loss: 0.2708 - acc: 0.\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2700 - acc: 0.9093 - val_loss: 0.2754 - val_acc: 0.9083\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2699 - acc: 0.9093 - val_loss: 0.2701 - val_acc: 0.9089\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2702 - acc: 0.9094 - val_loss: 0.2680 - val_acc: 0.9088\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2701 - acc: 0.9092 - val_loss: 0.2607 - val_acc: 0.9088\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2684 - acc: 0.9096 - val_loss: 0.2697 - val_acc: 0.9089\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2699 - acc: 0.9092 - val_loss: 0.2679 - val_acc: 0.9089\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2686 - acc: 0.9096 - val_loss: 0.2719 - val_acc: 0.9088 0.2685 - ac\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2697 - acc: 0.9094 - val_loss: 0.2675 - val_acc: 0.9089 - loss\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2683 - acc: 0.9095 - val_loss: 0.2657 - val_acc: 0.9089ETA: 4s - loss: 0.26 - ETA: 2s - loss:  - ETA: 0s - loss: 0.2689 - acc: - ETA: 0s - loss: 0.2682 - acc: 0\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2681 - acc: 0.9092 - val_loss: 0.2719 - val_acc: 0.9091\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2687 - acc: 0.9094 - val_loss: 0.2708 - val_acc: 0.9088\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2677 - acc: 0.9093 - val_loss: 0.2595 - val_acc: 0.9091\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2676 - acc: 0.9096 - val_loss: 0.2701 - val_acc: 0.9088ss: 0.2631 - acc: - ETA: 2s\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 23s 341us/step - loss: 0.2659 - acc: 0.9091 - val_loss: 0.2688 - val_acc: 0.9088\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2672 - acc: 0.9094 - val_loss: 0.2617 - val_acc: 0.9087\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 23s 342us/step - loss: 0.2673 - acc: 0.9091 - val_loss: 0.2673 - val_acc: 0.9088\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2669 - acc: 0.9095 - val_loss: 0.2679 - val_acc: 0.9081oss: 0.2685 - acc: 0.90 - ETA: 11s - lo\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2666 - acc: 0.9093 - val_loss: 0.2658 - val_acc: 0.90875 - ETA: 13s - loss: 0. - ETA: 12s - loss: 0.2670 - ac - ETA: 7s - loss: 0.2699 - a\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2666 - acc: 0.9094 - val_loss: 0.2646 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_9.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2658 - acc: 0.9092 - val_loss: 0.2671 - val_acc: 0.9087\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2646 - acc: 0.9096 - val_loss: 0.2681 - val_acc: 0.9091\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2652 - acc: 0.9093 - val_loss: 0.2707 - val_acc: 0.9088.2653 - acc: 0.909\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2651 - acc: 0.9093 - val_loss: 0.2712 - val_acc: 0.908874 - acc: 0.9 - ETA: 8s - l - ETA: 5s\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2659 - acc: 0.9094 - val_loss: 0.2810 - val_acc: 0.9081\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2654 - acc: 0.9092 - val_loss: 0.2701 - val_acc: 0.9087\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2658 - acc: 0.9092 - val_loss: 0.2745 - val_acc: 0.9089\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2651 - acc: 0.9093 - val_loss: 0.2687 - val_acc: 0.9085\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2655 - acc: 0.9093 - val_loss: 0.2636 - val_acc: 0.9087\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2647 - acc: 0.9095 - val_loss: 0.2680 - val_acc: 0.9087\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2658 - acc: 0.9092 - val_loss: 0.2681 - val_acc: 0.9092\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2642 - acc: 0.9094 - val_loss: 0.2662 - val_acc: 0.9087 10s - loss: 0.2643 - acc: 0. - ETA: 10s - loss: 0.2639  - ETA:  - ETA: 7s - loss: 0.2638 - acc:  - ETA: 6s - loss: 0.264 - ETA: 5s - loss: 0.2649 - acc: - ETA: 4s - loss: 0.2647 - acc: 0.90 - ETA: 4s - - ETA: 2s - loss: 0. - ETA: 0s - loss: 0.2644 - acc\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2644 - acc: 0.9095 - val_loss: 0.2651 - val_acc: 0.9089651 - -  - ETA: 6s - los - ETA: 4s - loss: 0.26 \n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2646 - acc: 0.9094 - val_loss: 0.2637 - val_acc: 0.9091: 0.26 - ETA: 2s - lo\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2633 - acc: 0.9095 - val_loss: 0.2638 - val_acc: 0.9092\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2634 - acc: 0.9098 - val_loss: 0.2616 - val_acc: 0.9087\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2641 - acc: 0.9092 - val_loss: 0.2677 - val_acc: 0.9088\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 357us/step - loss: 0.2635 - acc: 0.9096 - val_loss: 0.2607 - val_acc: 0.9091\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2631 - acc: 0.9094 - val_loss: 0.2667 - val_acc: 0.9088\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2638 - acc: 0.9092 - val_loss: 0.2612 - val_acc: 0.9091 0.2656  - ETA: 3s - loss: 0.2654 - acc: - ETA: 2s \n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2644 - acc: 0.9094 - val_loss: 0.2653 - val_acc: 0.90910.2644 - acc: 0.90\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2632 - acc: 0.9094 - val_loss: 0.2675 - val_acc: 0.9088\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2630 - acc: 0.9094 - val_loss: 0.2571 - val_acc: 0.9092\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2623 - acc: 0.9093 - val_loss: 0.2673 - val_acc: 0.9088\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2610 - acc: 0.9091 - val_loss: 0.2702 - val_acc: 0.9092\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2621 - acc: 0.9096 - val_loss: 0.2677 - val_acc: 0.9080\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 23s 352us/step - loss: 0.2620 - acc: 0.9094 - val_loss: 0.2665 - val_acc: 0.9091\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 23s 350us/step - loss: 0.2611 - acc: 0.9096 - val_loss: 0.2658 - val_acc: 0.9091\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 23s 351us/step - loss: 0.2620 - acc: 0.9095 - val_loss: 0.2667 - val_acc: 0.9084\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2612 - acc: 0.9096 - val_loss: 0.2644 - val_acc: 0.9089\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2616 - acc: 0.9093 - val_loss: 0.2682 - val_acc: 0.9089\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 355us/step - loss: 0.2613 - acc: 0.9097 - val_loss: 0.2716 - val_acc: 0.908501 - acc: 0.910  - ETA: 2s - loss: 0.2597 - - ETA: 1s - loss: 0.259\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 356us/step - loss: 0.2628 - acc: 0.9093 - val_loss: 0.2653 - val_acc: 0.9089a - ETA: 1 - ETA: 9s - loss: 0. - ETA: 4s - l - ETA: 1s - loss:\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2624 - acc: 0.9096 - val_loss: 0.2630 - val_acc: 0.9088\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2620 - acc: 0.9093 - val_loss: 0.2596 - val_acc: 0.9089- loss: 0.2623 - \n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2621 - acc: 0.9094 - val_loss: 0.2664 - val_acc: 0.9091\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2608 - acc: 0.9093 - val_loss: 0.2646 - val_acc: 0.9091\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2613 - acc: 0.9096 - val_loss: 0.2671 - val_acc: 0.9092c: 0.909\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2610 - acc: 0.9096 - val_loss: 0.2609 - val_acc: 0.9087\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2602 - acc: 0.9091 - val_loss: 0.2636 - val_acc: 0.9087\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2604 - acc: 0.9093 - val_loss: 0.2674 - val_acc: 0.9081\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2608 - acc: 0.9096 - val_loss: 0.2620 - val_acc: 0.9084\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2602 - acc: 0.9094 - val_loss: 0.2664 - val_acc: 0.9089 - loss - ETA: 1s - loss: 0.\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2608 - acc: 0.9091 - val_loss: 0.2645 - val_acc: 0.9089\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2612 - acc: 0.9090 - val_loss: 0.2683 - val_acc: 0.9084\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2597 - acc: 0.9099 - val_loss: 0.2638 - val_acc: 0.9088s: 0.2597 - acc: 0.\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2610 - acc: 0.9095 - val_loss: 0.2638 - val_acc: 0.9087 loss: 0.2 - ETA: 4s - loss: 0.\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2607 - acc: 0.9095 - val_loss: 0.2648 - val_acc: 0.9083\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2604 - acc: 0.9096 - val_loss: 0.2662 - val_acc: 0.9085\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2604 - acc: 0.9092 - val_loss: 0.2613 - val_acc: 0.9089 -\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_9.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2597 - acc: 0.9095 - val_loss: 0.2643 - val_acc: 0.9083\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2597 - acc: 0.9096 - val_loss: 0.2646 - val_acc: 0.9089\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2582 - acc: 0.9099 - val_loss: 0.2665 - val_acc: 0.9089- acc: 0.91 - ETA: 1s - loss: 0.2573 - ETA: 0s - loss: 0.2581 - acc: 0\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2598 - acc: 0.9091 - val_loss: 0.2653 - val_acc: 0.9087\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2607 - acc: 0.9094 - val_loss: 0.2672 - val_acc: 0.9088\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2599 - acc: 0.9099 - val_loss: 0.2633 - val_acc: 0.9088 8s - loss: 0.2605 - acc: 0.909 - ETA: 8s - loss: 0.2603 - acc: 0.909 - ETA:  - ETA: \n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2589 - acc: 0.9097 - val_loss: 0.2616 - val_acc: 0.9091s - loss: 0.2590 -  - ETA: 1s - loss: 0.25\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2591 - acc: 0.9094 - val_loss: 0.2656 - val_acc: 0.9085\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2589 - acc: 0.9095 - val_loss: 0.2617 - val_acc: 0.9084\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2586 - acc: 0.9095 - val_loss: 0.2630 - val_acc: 0.9089\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 23s 353us/step - loss: 0.2601 - acc: 0.9094 - val_loss: 0.2623 - val_acc: 0.9091\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 24s 354us/step - loss: 0.2581 - acc: 0.9091 - val_loss: 0.2664 - val_acc: 0.9083\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2578 - acc: 0.9099 - val_loss: 0.2627 - val_acc: 0.9087s: 0.2580 - acc: 0.90\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2580 - acc: 0.9096 - val_loss: 0.2602 - val_acc: 0.9088 - - ETA: \n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2586 - acc: 0.9095 - val_loss: 0.2601 - val_acc: 0.9085\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2587 - acc: 0.9094 - val_loss: 0.2598 - val_acc: 0.9088\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2592 - acc: 0.9093 - val_loss: 0.2616 - val_acc: 0.90890s - loss: 0.2599 - \n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2588 - acc: 0.9095 - val_loss: 0.2676 - val_acc: 0.9087\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2578 - acc: 0.9095 - val_loss: 0.2620 - val_acc: 0.9087\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 23s 349us/step - loss: 0.2576 - acc: 0.9096 - val_loss: 0.2612 - val_acc: 0.9087\n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2586 - acc: 0.9100 - val_loss: 0.2641 - val_acc: 0.9085\n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 23s 347us/step - loss: 0.2573 - acc: 0.9100 - val_loss: 0.2688 - val_acc: 0.9085\n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 23s 348us/step - loss: 0.2587 - acc: 0.9096 - val_loss: 0.2669 - val_acc: 0.9087\n",
      "AUC: 0.800217\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 18s 277us/step - loss: 0.3084 - acc: 0.9072 - val_loss: 0.3097 - val_acc: 0.9162\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2968 - acc: 0.9086 - val_loss: 0.2882 - val_acc: 0.9162\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2929 - acc: 0.9086 - val_loss: 0.2879 - val_acc: 0.9162\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2905 - acc: 0.9086 - val_loss: 0.2727 - val_acc: 0.9162\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2875 - acc: 0.9086 - val_loss: 0.2949 - val_acc: 0.9160\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2857 - acc: 0.9086 - val_loss: 0.2771 - val_acc: 0.9161\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2832 - acc: 0.9086 - val_loss: 0.2692 - val_acc: 0.9161\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2814 - acc: 0.9085 - val_loss: 0.2636 - val_acc: 0.9162\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 18s 265us/step - loss: 0.2807 - acc: 0.9087 - val_loss: 0.2632 - val_acc: 0.91620s - loss: 0.2811 - acc: 0.9\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2806 - acc: 0.9086 - val_loss: 0.2701 - val_acc: 0.9161\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2790 - acc: 0.9086 - val_loss: 0.2651 - val_acc: 0.9162\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2785 - acc: 0.9084 - val_loss: 0.2753 - val_acc: 0.9161\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2773 - acc: 0.9086 - val_loss: 0.2582 - val_acc: 0.9162\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2767 - acc: 0.9084 - val_loss: 0.2667 - val_acc: 0.9161\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2756 - acc: 0.9085 - val_loss: 0.2628 - val_acc: 0.9162\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2757 - acc: 0.9085 - val_loss: 0.2697 - val_acc: 0.9158\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2765 - acc: 0.9084 - val_loss: 0.2650 - val_acc: 0.9162\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2739 - acc: 0.9087 - val_loss: 0.2680 - val_acc: 0.9162\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2745 - acc: 0.9086 - val_loss: 0.2713 - val_acc: 0.9164\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2742 - acc: 0.9086 - val_loss: 0.2696 - val_acc: 0.9161\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2732 - acc: 0.9087 - val_loss: 0.2709 - val_acc: 0.9160\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2737 - acc: 0.9086 - val_loss: 0.2728 - val_acc: 0.9161\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2726 - acc: 0.9086 - val_loss: 0.2628 - val_acc: 0.9160\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2723 - acc: 0.9084 - val_loss: 0.2669 - val_acc: 0.9165\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2720 - acc: 0.9084 - val_loss: 0.2651 - val_acc: 0.9165\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2718 - acc: 0.9083 - val_loss: 0.2592 - val_acc: 0.9161\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2704 - acc: 0.9086 - val_loss: 0.2769 - val_acc: 0.9161\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2720 - acc: 0.9084 - val_loss: 0.2662 - val_acc: 0.9164\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2708 - acc: 0.9085 - val_loss: 0.2581 - val_acc: 0.9165\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2709 - acc: 0.9085 - val_loss: 0.2645 - val_acc: 0.9164\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2706 - acc: 0.9086 - val_loss: 0.2600 - val_acc: 0.9162\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2709 - acc: 0.9085 - val_loss: 0.2590 - val_acc: 0.9161\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2695 - acc: 0.9085 - val_loss: 0.2600 - val_acc: 0.9165\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2688 - acc: 0.9084 - val_loss: 0.2609 - val_acc: 0.9157\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2693 - acc: 0.9087 - val_loss: 0.2674 - val_acc: 0.9150\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2692 - acc: 0.9084 - val_loss: 0.2654 - val_acc: 0.9158\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2702 - acc: 0.9085 - val_loss: 0.2650 - val_acc: 0.9158\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2687 - acc: 0.9089 - val_loss: 0.2634 - val_acc: 0.9157\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2678 - acc: 0.9084 - val_loss: 0.2642 - val_acc: 0.9162\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2683 - acc: 0.9087 - val_loss: 0.2597 - val_acc: 0.9162\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2676 - acc: 0.9086 - val_loss: 0.2590 - val_acc: 0.9162\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2684 - acc: 0.9086 - val_loss: 0.2599 - val_acc: 0.9158\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2671 - acc: 0.9086 - val_loss: 0.2640 - val_acc: 0.9157\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2685 - acc: 0.9086 - val_loss: 0.2628 - val_acc: 0.9160\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2668 - acc: 0.9088 - val_loss: 0.2679 - val_acc: 0.9160\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2660 - acc: 0.9088 - val_loss: 0.2655 - val_acc: 0.9162\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2687 - acc: 0.9086 - val_loss: 0.2578 - val_acc: 0.9161\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2677 - acc: 0.9084 - val_loss: 0.2629 - val_acc: 0.9162\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2668 - acc: 0.9087 - val_loss: 0.2583 - val_acc: 0.9161\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2669 - acc: 0.9086 - val_loss: 0.2613 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_10.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2668 - acc: 0.9087 - val_loss: 0.2600 - val_acc: 0.9161\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2673 - acc: 0.9083 - val_loss: 0.2561 - val_acc: 0.9162\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2667 - acc: 0.9083 - val_loss: 0.2652 - val_acc: 0.9161\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2662 - acc: 0.9087 - val_loss: 0.2695 - val_acc: 0.9157\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2665 - acc: 0.9083 - val_loss: 0.2649 - val_acc: 0.9157\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2663 - acc: 0.9087 - val_loss: 0.2667 - val_acc: 0.9158\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2652 - acc: 0.9086 - val_loss: 0.2632 - val_acc: 0.9161\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2646 - acc: 0.9085 - val_loss: 0.2590 - val_acc: 0.9160\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2656 - acc: 0.9090 - val_loss: 0.2688 - val_acc: 0.9161\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2649 - acc: 0.9087 - val_loss: 0.2649 - val_acc: 0.9160\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2640 - acc: 0.9081 - val_loss: 0.2659 - val_acc: 0.9160\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2646 - acc: 0.9083 - val_loss: 0.2608 - val_acc: 0.9164\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2650 - acc: 0.9089 - val_loss: 0.2607 - val_acc: 0.9165\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2644 - acc: 0.9083 - val_loss: 0.2688 - val_acc: 0.9160\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2644 - acc: 0.9081 - val_loss: 0.2604 - val_acc: 0.9165\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2652 - acc: 0.9082 - val_loss: 0.2695 - val_acc: 0.9160\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2643 - acc: 0.9081 - val_loss: 0.2662 - val_acc: 0.9165\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2644 - acc: 0.9081 - val_loss: 0.2593 - val_acc: 0.9165\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2638 - acc: 0.9089 - val_loss: 0.2590 - val_acc: 0.9160\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2642 - acc: 0.9082 - val_loss: 0.2628 - val_acc: 0.9161\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2647 - acc: 0.9085 - val_loss: 0.2642 - val_acc: 0.9160\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2638 - acc: 0.9085 - val_loss: 0.2621 - val_acc: 0.9161\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2617 - acc: 0.9089 - val_loss: 0.2644 - val_acc: 0.9164\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2635 - acc: 0.9087 - val_loss: 0.2616 - val_acc: 0.9165\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2629 - acc: 0.9087 - val_loss: 0.2621 - val_acc: 0.9165\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2644 - acc: 0.9084 - val_loss: 0.2585 - val_acc: 0.9158\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2626 - acc: 0.9085 - val_loss: 0.2593 - val_acc: 0.9158\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2627 - acc: 0.9087 - val_loss: 0.2624 - val_acc: 0.9162\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2632 - acc: 0.9084 - val_loss: 0.2635 - val_acc: 0.9165\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2622 - acc: 0.9086 - val_loss: 0.2647 - val_acc: 0.9162\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2631 - acc: 0.9087 - val_loss: 0.2597 - val_acc: 0.9161\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2630 - acc: 0.9084 - val_loss: 0.2578 - val_acc: 0.9162\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2630 - acc: 0.9087 - val_loss: 0.2571 - val_acc: 0.9160\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2620 - acc: 0.9081 - val_loss: 0.2576 - val_acc: 0.9161\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2634 - acc: 0.9083 - val_loss: 0.2569 - val_acc: 0.9160\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2622 - acc: 0.9089 - val_loss: 0.2560 - val_acc: 0.9165\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2622 - acc: 0.9081 - val_loss: 0.2565 - val_acc: 0.9165\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2619 - acc: 0.9086 - val_loss: 0.2604 - val_acc: 0.9162\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2608 - acc: 0.9087 - val_loss: 0.2621 - val_acc: 0.9164\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2621 - acc: 0.9085 - val_loss: 0.2591 - val_acc: 0.9165\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2616 - acc: 0.9082 - val_loss: 0.2593 - val_acc: 0.9164\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2625 - acc: 0.9088 - val_loss: 0.2654 - val_acc: 0.9165\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2616 - acc: 0.9087 - val_loss: 0.2615 - val_acc: 0.9161\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2612 - acc: 0.9089 - val_loss: 0.2556 - val_acc: 0.9161\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2606 - acc: 0.9085 - val_loss: 0.2605 - val_acc: 0.9165\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2611 - acc: 0.9086 - val_loss: 0.2631 - val_acc: 0.9157\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2622 - acc: 0.9087 - val_loss: 0.2595 - val_acc: 0.9158\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2616 - acc: 0.9082 - val_loss: 0.2580 - val_acc: 0.9158\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2603 - acc: 0.9086 - val_loss: 0.2563 - val_acc: 0.9160\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2611 - acc: 0.9085 - val_loss: 0.2565 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_10.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2612 - acc: 0.9087 - val_loss: 0.2680 - val_acc: 0.9161\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2607 - acc: 0.9087 - val_loss: 0.2618 - val_acc: 0.9161\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2601 - acc: 0.9084 - val_loss: 0.2548 - val_acc: 0.9157\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2604 - acc: 0.9085 - val_loss: 0.2558 - val_acc: 0.9157\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2605 - acc: 0.9086 - val_loss: 0.2620 - val_acc: 0.9162\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2604 - acc: 0.9081 - val_loss: 0.2562 - val_acc: 0.9162\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2601 - acc: 0.9088 - val_loss: 0.2602 - val_acc: 0.9157\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2595 - acc: 0.9085 - val_loss: 0.2583 - val_acc: 0.9156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2591 - acc: 0.9092 - val_loss: 0.2619 - val_acc: 0.9158\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 18s 264us/step - loss: 0.2605 - acc: 0.9088 - val_loss: 0.2549 - val_acc: 0.9158\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 17s 263us/step - loss: 0.2590 - acc: 0.9093 - val_loss: 0.2593 - val_acc: 0.9158\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2601 - acc: 0.9086 - val_loss: 0.2558 - val_acc: 0.9156\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2594 - acc: 0.9086 - val_loss: 0.2553 - val_acc: 0.9158\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 18s 267us/step - loss: 0.2583 - acc: 0.9086 - val_loss: 0.2579 - val_acc: 0.9160\n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 18s 265us/step - loss: 0.2583 - acc: 0.9089 - val_loss: 0.2610 - val_acc: 0.9158\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2600 - acc: 0.9092 - val_loss: 0.2589 - val_acc: 0.9157\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2585 - acc: 0.9087 - val_loss: 0.2569 - val_acc: 0.9158\n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2574 - acc: 0.9088 - val_loss: 0.2604 - val_acc: 0.9156\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2598 - acc: 0.9086 - val_loss: 0.2564 - val_acc: 0.9161\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2594 - acc: 0.9089 - val_loss: 0.2605 - val_acc: 0.9156\n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2592 - acc: 0.9088 - val_loss: 0.2585 - val_acc: 0.9152: 0.2593 \n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2593 - acc: 0.9084 - val_loss: 0.2581 - val_acc: 0.9158\n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2584 - acc: 0.9089 - val_loss: 0.2585 - val_acc: 0.9154\n",
      "Epoch 124/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2579 - acc: 0.9087 - val_loss: 0.2577 - val_acc: 0.9158\n",
      "Epoch 125/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2585 - acc: 0.9084 - val_loss: 0.2564 - val_acc: 0.9161\n",
      "Epoch 126/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2577 - acc: 0.9091 - val_loss: 0.2553 - val_acc: 0.9160\n",
      "Epoch 127/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2583 - acc: 0.9089 - val_loss: 0.2594 - val_acc: 0.9158\n",
      "Epoch 128/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2578 - acc: 0.9091 - val_loss: 0.2591 - val_acc: 0.9160\n",
      "Epoch 129/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2575 - acc: 0.9093 - val_loss: 0.2549 - val_acc: 0.9157\n",
      "Epoch 130/1000\n",
      "66414/66414 [==============================] - 18s 264us/step - loss: 0.2581 - acc: 0.9088 - val_loss: 0.2634 - val_acc: 0.9157\n",
      "Epoch 131/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2576 - acc: 0.9088 - val_loss: 0.2634 - val_acc: 0.9160\n",
      "Epoch 132/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2572 - acc: 0.9091 - val_loss: 0.2605 - val_acc: 0.9160\n",
      "Epoch 133/1000\n",
      "66414/66414 [==============================] - 18s 264us/step - loss: 0.2592 - acc: 0.9088 - val_loss: 0.2571 - val_acc: 0.9158\n",
      "Epoch 134/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2584 - acc: 0.9087 - val_loss: 0.2588 - val_acc: 0.9156\n",
      "Epoch 135/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2576 - acc: 0.9089 - val_loss: 0.2596 - val_acc: 0.9156\n",
      "Epoch 136/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2569 - acc: 0.9088 - val_loss: 0.2591 - val_acc: 0.9156\n",
      "Epoch 137/1000\n",
      "66414/66414 [==============================] - 18s 264us/step - loss: 0.2582 - acc: 0.9088 - val_loss: 0.2585 - val_acc: 0.9158\n",
      "Epoch 138/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2567 - acc: 0.9087 - val_loss: 0.2565 - val_acc: 0.9158\n",
      "Epoch 139/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2568 - acc: 0.9087 - val_loss: 0.2597 - val_acc: 0.9162\n",
      "Epoch 140/1000\n",
      "66414/66414 [==============================] - 18s 264us/step - loss: 0.2571 - acc: 0.9090 - val_loss: 0.2600 - val_acc: 0.9158\n",
      "Epoch 141/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2554 - acc: 0.9095 - val_loss: 0.2599 - val_acc: 0.9165\n",
      "Epoch 142/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2569 - acc: 0.9085 - val_loss: 0.2598 - val_acc: 0.9161\n",
      "Epoch 143/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2581 - acc: 0.9089 - val_loss: 0.2557 - val_acc: 0.9160\n",
      "Epoch 144/1000\n",
      "66414/66414 [==============================] - 18s 268us/step - loss: 0.2566 - acc: 0.9088 - val_loss: 0.2550 - val_acc: 0.9158\n",
      "Epoch 145/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2561 - acc: 0.9091 - val_loss: 0.2558 - val_acc: 0.9158\n",
      "Epoch 146/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2569 - acc: 0.9090 - val_loss: 0.2559 - val_acc: 0.9157\n",
      "Epoch 147/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2566 - acc: 0.9088 - val_loss: 0.2605 - val_acc: 0.9162\n",
      "Epoch 148/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2558 - acc: 0.9088 - val_loss: 0.2575 - val_acc: 0.9158\n",
      "Epoch 149/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2563 - acc: 0.9091 - val_loss: 0.2535 - val_acc: 0.9157\n",
      "Epoch 150/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2555 - acc: 0.9093 - val_loss: 0.2576 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_EGAAC_gap4_10.hdf5\n",
      "Epoch 151/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2561 - acc: 0.9095 - val_loss: 0.2572 - val_acc: 0.9164\n",
      "Epoch 152/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2563 - acc: 0.9089 - val_loss: 0.2578 - val_acc: 0.9160\n",
      "Epoch 153/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2550 - acc: 0.9090 - val_loss: 0.2575 - val_acc: 0.9162\n",
      "Epoch 154/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2555 - acc: 0.9092 - val_loss: 0.2575 - val_acc: 0.9162\n",
      "Epoch 155/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2551 - acc: 0.9090 - val_loss: 0.2592 - val_acc: 0.9156\n",
      "Epoch 156/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2552 - acc: 0.9090 - val_loss: 0.2564 - val_acc: 0.9160\n",
      "Epoch 157/1000\n",
      "66414/66414 [==============================] - 17s 259us/step - loss: 0.2548 - acc: 0.9093 - val_loss: 0.2565 - val_acc: 0.9160\n",
      "Epoch 158/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2562 - acc: 0.9091 - val_loss: 0.2558 - val_acc: 0.9158\n",
      "Epoch 159/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2567 - acc: 0.9089 - val_loss: 0.2562 - val_acc: 0.9160\n",
      "Epoch 160/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2557 - acc: 0.9091 - val_loss: 0.2589 - val_acc: 0.9162\n",
      "Epoch 161/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2546 - acc: 0.9095 - val_loss: 0.2589 - val_acc: 0.9158\n",
      "Epoch 162/1000\n",
      "66414/66414 [==============================] - 17s 263us/step - loss: 0.2549 - acc: 0.9085 - val_loss: 0.2580 - val_acc: 0.9156\n",
      "Epoch 163/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2548 - acc: 0.9093 - val_loss: 0.2574 - val_acc: 0.9165\n",
      "Epoch 164/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2548 - acc: 0.9088 - val_loss: 0.2565 - val_acc: 0.9160\n",
      "Epoch 165/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2553 - acc: 0.9091 - val_loss: 0.2562 - val_acc: 0.9158\n",
      "Epoch 166/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2552 - acc: 0.9095 - val_loss: 0.2559 - val_acc: 0.9158\n",
      "Epoch 167/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2550 - acc: 0.9090 - val_loss: 0.2582 - val_acc: 0.9156\n",
      "Epoch 168/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2550 - acc: 0.9097 - val_loss: 0.2578 - val_acc: 0.9162\n",
      "Epoch 169/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2544 - acc: 0.9090 - val_loss: 0.2619 - val_acc: 0.9161\n",
      "Epoch 170/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2548 - acc: 0.9084 - val_loss: 0.2560 - val_acc: 0.9158\n",
      "Epoch 171/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2551 - acc: 0.9096 - val_loss: 0.2572 - val_acc: 0.9162\n",
      "Epoch 172/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2549 - acc: 0.9087 - val_loss: 0.2610 - val_acc: 0.9162\n",
      "Epoch 173/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2543 - acc: 0.9091 - val_loss: 0.2600 - val_acc: 0.9161\n",
      "Epoch 174/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2542 - acc: 0.9088 - val_loss: 0.2577 - val_acc: 0.9158\n",
      "Epoch 175/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2539 - acc: 0.9095 - val_loss: 0.2582 - val_acc: 0.9161\n",
      "Epoch 176/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2545 - acc: 0.9091 - val_loss: 0.2598 - val_acc: 0.9167\n",
      "Epoch 177/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2543 - acc: 0.9093 - val_loss: 0.2556 - val_acc: 0.9164\n",
      "Epoch 178/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2538 - acc: 0.9086 - val_loss: 0.2576 - val_acc: 0.9164\n",
      "Epoch 179/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2558 - acc: 0.9093 - val_loss: 0.2557 - val_acc: 0.9161\n",
      "Epoch 180/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2537 - acc: 0.9088 - val_loss: 0.2554 - val_acc: 0.9161\n",
      "Epoch 181/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2550 - acc: 0.9089 - val_loss: 0.2582 - val_acc: 0.9165\n",
      "Epoch 182/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2534 - acc: 0.9091 - val_loss: 0.2572 - val_acc: 0.9164\n",
      "Epoch 183/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2531 - acc: 0.9096 - val_loss: 0.2558 - val_acc: 0.9160\n",
      "Epoch 184/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2541 - acc: 0.9090 - val_loss: 0.2553 - val_acc: 0.9162\n",
      "Epoch 185/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2536 - acc: 0.9089 - val_loss: 0.2561 - val_acc: 0.9158\n",
      "Epoch 186/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2530 - acc: 0.9092 - val_loss: 0.2563 - val_acc: 0.9161\n",
      "Epoch 187/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2550 - acc: 0.9089 - val_loss: 0.2592 - val_acc: 0.9162\n",
      "Epoch 188/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2550 - acc: 0.9092 - val_loss: 0.2581 - val_acc: 0.9154\n",
      "Epoch 189/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2534 - acc: 0.9096 - val_loss: 0.2574 - val_acc: 0.9164\n",
      "Epoch 190/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2535 - acc: 0.9094 - val_loss: 0.2557 - val_acc: 0.9157\n",
      "Epoch 191/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2532 - acc: 0.9096 - val_loss: 0.2552 - val_acc: 0.9167\n",
      "Epoch 192/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2547 - acc: 0.9095 - val_loss: 0.2595 - val_acc: 0.9157\n",
      "Epoch 193/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2524 - acc: 0.9093 - val_loss: 0.2569 - val_acc: 0.9162\n",
      "Epoch 194/1000\n",
      "66414/66414 [==============================] - 17s 261us/step - loss: 0.2536 - acc: 0.9091 - val_loss: 0.2562 - val_acc: 0.9161\n",
      "Epoch 195/1000\n",
      "66414/66414 [==============================] - 17s 262us/step - loss: 0.2523 - acc: 0.9097 - val_loss: 0.2571 - val_acc: 0.9164\n",
      "Epoch 196/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2524 - acc: 0.9097 - val_loss: 0.2614 - val_acc: 0.9164\n",
      "Epoch 197/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2531 - acc: 0.9093 - val_loss: 0.2578 - val_acc: 0.9164\n",
      "Epoch 198/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2536 - acc: 0.9091 - val_loss: 0.2576 - val_acc: 0.9161\n",
      "Epoch 199/1000\n",
      "66414/66414 [==============================] - 17s 260us/step - loss: 0.2528 - acc: 0.9093 - val_loss: 0.2585 - val_acc: 0.9158\n",
      "AUC: 0.765156\n",
      "[0.776545428679714, 0.7776884297989257, 0.774447583246213, 0.7916465352556691, 0.7832956968958379, 0.7697710412969897, 0.7872559851310161, 0.7697500868522318, 0.8002172767595407, 0.7651560515788963]\n",
      "CV AUC: 0.779577\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 重新训练CNN word Embedding\n",
    "\n",
    "name = 'EGAAC'\n",
    "gap = '_gap4'\n",
    "auc_mean=[]\n",
    "# path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "# path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "# x_train,y_train = pep(path_train,29-2)\n",
    "# x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_29_'+ name + gap +'.txt'\n",
    "path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_29_'+ name + gap +'.txt'\n",
    "\n",
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "\n",
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2) \n",
    "x_test = np.expand_dims(x_test, axis=2) \n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model3(shape=shape,dropout=0.6)\n",
    "    \n",
    "    #filepath='C:/Users/Crow/Desktop/result/re_CNN3/model/'+ str(j) +'checkpoint-{val_loss:.2f}-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5'\n",
    "    filepath='C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_'+ name + gap+'_'+ str(j) +'.hdf5'\n",
    "    #filepath=\"C:/Users/Crow/Desktop/result/re_CNN/model/weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False,mode='auto', period=50)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    callbacks_list = [early_stopping,checkpoint]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 1000, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    auc_mean.append(auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_test_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(y_test3)):\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    if j == 10:\n",
    "        print(auc_mean)\n",
    "        print(print(\"CV AUC: %f\" % mean(auc_mean)))\n",
    "#         model.save('C:/Users/Crow/Desktop/result/re_CNN/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "#         test_pred_proba = model.predict(x_test)\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "#         print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "#         fw = open('C:/Users/Crow/Desktop/result/re_CNN/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "#         for t in range(0,len(test_pred_proba)):\n",
    "#             fw.write(str(test_pred_proba[t][0]))\n",
    "#             fw.write('\\t')\n",
    "#             fw.write(str(y_test[t]))\n",
    "#             fw.write('\\n') \n",
    "#         fw.close()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/1000\n",
      "66413/66413 [==============================] - 27s 408us/step - loss: 0.3137 - acc: 0.9069 - val_loss: 0.3153 - val_acc: 0.9077\n",
      "Epoch 2/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.3026 - acc: 0.9096 - val_loss: 0.3038 - val_acc: 0.9077\n",
      "Epoch 3/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2999 - acc: 0.9096 - val_loss: 0.3007 - val_acc: 0.9077\n",
      "Epoch 4/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2948 - acc: 0.9096 - val_loss: 0.3056 - val_acc: 0.9077\n",
      "Epoch 5/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2936 - acc: 0.9096 - val_loss: 0.2932 - val_acc: 0.9077loss: 0.2935 - ac\n",
      "Epoch 6/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2919 - acc: 0.9096 - val_loss: 0.3021 - val_acc: 0.9077 - loss: 0.2920 -  - ETA: 6\n",
      "Epoch 7/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2919 - acc: 0.9096 - val_loss: 0.2959 - val_acc: 0.9077\n",
      "Epoch 8/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2910 - acc: 0.9096 - val_loss: 0.2924 - val_acc: 0.9077\n",
      "Epoch 9/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2897 - acc: 0.9095 - val_loss: 0.2941 - val_acc: 0.9077\n",
      "Epoch 10/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2895 - acc: 0.9095 - val_loss: 0.2933 - val_acc: 0.9077\n",
      "Epoch 11/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2886 - acc: 0.9095 - val_loss: 0.2949 - val_acc: 0.9077\n",
      "Epoch 12/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2873 - acc: 0.9094 - val_loss: 0.2903 - val_acc: 0.9079\n",
      "Epoch 13/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2870 - acc: 0.9096 - val_loss: 0.2890 - val_acc: 0.9077\n",
      "Epoch 14/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2860 - acc: 0.9095 - val_loss: 0.2912 - val_acc: 0.9079\n",
      "Epoch 15/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2854 - acc: 0.9095 - val_loss: 0.2957 - val_acc: 0.9081\n",
      "Epoch 16/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2852 - acc: 0.9095 - val_loss: 0.2900 - val_acc: 0.9081\n",
      "Epoch 17/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2844 - acc: 0.9096 - val_loss: 0.2863 - val_acc: 0.9080\n",
      "Epoch 18/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2842 - acc: 0.9096 - val_loss: 0.2907 - val_acc: 0.9081\n",
      "Epoch 19/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2834 - acc: 0.9095 - val_loss: 0.2870 - val_acc: 0.9079 - los - ETA: - ETA: 2s - lo\n",
      "Epoch 20/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2835 - acc: 0.9095 - val_loss: 0.2881 - val_acc: 0.9080\n",
      "Epoch 21/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2823 - acc: 0.9096 - val_loss: 0.2854 - val_acc: 0.9079\n",
      "Epoch 22/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2821 - acc: 0.9094 - val_loss: 0.2847 - val_acc: 0.9080\n",
      "Epoch 23/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2812 - acc: 0.9093 - val_loss: 0.2851 - val_acc: 0.9079\n",
      "Epoch 24/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2807 - acc: 0.9096 - val_loss: 0.2917 - val_acc: 0.9079\n",
      "Epoch 25/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2796 - acc: 0.9094 - val_loss: 0.2868 - val_acc: 0.9077\n",
      "Epoch 26/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2789 - acc: 0.9094 - val_loss: 0.2964 - val_acc: 0.9081\n",
      "Epoch 27/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2802 - acc: 0.9097 - val_loss: 0.2850 - val_acc: 0.9080\n",
      "Epoch 28/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2778 - acc: 0.9094 - val_loss: 0.2948 - val_acc: 0.9079\n",
      "Epoch 29/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2776 - acc: 0.9097 - val_loss: 0.2834 - val_acc: 0.9079\n",
      "Epoch 30/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2777 - acc: 0.9095 - val_loss: 0.2882 - val_acc: 0.9075\n",
      "Epoch 31/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2774 - acc: 0.9095 - val_loss: 0.2862 - val_acc: 0.9083\n",
      "Epoch 32/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2769 - acc: 0.9096 - val_loss: 0.2893 - val_acc: 0.9080\n",
      "Epoch 33/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2764 - acc: 0.9095 - val_loss: 0.2844 - val_acc: 0.9085 loss: 0.2768 - a\n",
      "Epoch 34/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2769 - acc: 0.9096 - val_loss: 0.2915 - val_acc: 0.9080\n",
      "Epoch 35/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2754 - acc: 0.9096 - val_loss: 0.2924 - val_acc: 0.9083: 0s - loss: 0.2750 - acc: 0.9\n",
      "Epoch 36/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2754 - acc: 0.9098 - val_loss: 0.2831 - val_acc: 0.9077s - loss: 0.2750 - acc: 0.9\n",
      "Epoch 37/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2754 - acc: 0.9092 - val_loss: 0.2847 - val_acc: 0.9079\n",
      "Epoch 38/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2745 - acc: 0.9093 - val_loss: 0.2834 - val_acc: 0.9083- loss: 0.275\n",
      "Epoch 39/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2738 - acc: 0.9097 - val_loss: 0.2868 - val_acc: 0.9084\n",
      "Epoch 40/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2741 - acc: 0.9095 - val_loss: 0.2875 - val_acc: 0.9083\n",
      "Epoch 41/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2738 - acc: 0.9097 - val_loss: 0.2836 - val_acc: 0.9080\n",
      "Epoch 42/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2737 - acc: 0.9093 - val_loss: 0.2891 - val_acc: 0.9080\n",
      "Epoch 43/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2722 - acc: 0.9094 - val_loss: 0.2864 - val_acc: 0.9079\n",
      "Epoch 44/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2715 - acc: 0.9092 - val_loss: 0.2889 - val_acc: 0.9079\n",
      "Epoch 45/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2720 - acc: 0.9097 - val_loss: 0.2862 - val_acc: 0.9085\n",
      "Epoch 46/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2720 - acc: 0.9095 - val_loss: 0.2878 - val_acc: 0.9084\n",
      "Epoch 47/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2719 - acc: 0.9093 - val_loss: 0.2844 - val_acc: 0.9079\n",
      "Epoch 48/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2703 - acc: 0.9096 - val_loss: 0.2872 - val_acc: 0.9085\n",
      "Epoch 49/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2694 - acc: 0.9094 - val_loss: 0.2947 - val_acc: 0.9083\n",
      "Epoch 50/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2716 - acc: 0.9093 - val_loss: 0.2890 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_1.hdf5\n",
      "Epoch 51/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2693 - acc: 0.9096 - val_loss: 0.2828 - val_acc: 0.9081\n",
      "Epoch 52/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2694 - acc: 0.9092 - val_loss: 0.2851 - val_acc: 0.9083\n",
      "Epoch 53/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2688 - acc: 0.9097 - val_loss: 0.2873 - val_acc: 0.9084lo - ETA: 0s - loss: 0.2688 - a\n",
      "Epoch 54/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2684 - acc: 0.9092 - val_loss: 0.2912 - val_acc: 0.9079\n",
      "Epoch 55/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2680 - acc: 0.9097 - val_loss: 0.2833 - val_acc: 0.9081\n",
      "Epoch 56/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2666 - acc: 0.9098 - val_loss: 0.2937 - val_acc: 0.9084\n",
      "Epoch 57/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2672 - acc: 0.9098 - val_loss: 0.2887 - val_acc: 0.9084\n",
      "Epoch 58/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2668 - acc: 0.9094 - val_loss: 0.2859 - val_acc: 0.9083\n",
      "Epoch 59/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2664 - acc: 0.9100 - val_loss: 0.2923 - val_acc: 0.9084\n",
      "Epoch 60/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2655 - acc: 0.9102 - val_loss: 0.2853 - val_acc: 0.9084\n",
      "Epoch 61/1000\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2658 - acc: 0.9097 - val_loss: 0.2881 - val_acc: 0.9083\n",
      "Epoch 62/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2657 - acc: 0.9102 - val_loss: 0.2948 - val_acc: 0.9087\n",
      "Epoch 63/1000\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2645 - acc: 0.9099 - val_loss: 0.2918 - val_acc: 0.9085\n",
      "Epoch 64/1000\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2653 - acc: 0.9102 - val_loss: 0.2860 - val_acc: 0.9081\n",
      "Epoch 65/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2635 - acc: 0.9099 - val_loss: 0.2887 - val_acc: 0.9081\n",
      "Epoch 66/1000\n",
      "66413/66413 [==============================] - 25s 371us/step - loss: 0.2636 - acc: 0.9099 - val_loss: 0.2860 - val_acc: 0.9085\n",
      "Epoch 67/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2640 - acc: 0.9101 - val_loss: 0.2894 - val_acc: 0.9077\n",
      "Epoch 68/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2627 - acc: 0.9099 - val_loss: 0.2913 - val_acc: 0.9085\n",
      "Epoch 69/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2630 - acc: 0.9103 - val_loss: 0.2898 - val_acc: 0.9084\n",
      "Epoch 70/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2630 - acc: 0.9089 - val_loss: 0.2976 - val_acc: 0.9085a\n",
      "Epoch 71/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2621 - acc: 0.9094 - val_loss: 0.2880 - val_acc: 0.9083\n",
      "Epoch 72/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2633 - acc: 0.9103 - val_loss: 0.2861 - val_acc: 0.9075\n",
      "Epoch 73/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2634 - acc: 0.9099 - val_loss: 0.2959 - val_acc: 0.9075\n",
      "Epoch 74/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2622 - acc: 0.9098 - val_loss: 0.2816 - val_acc: 0.9076\n",
      "Epoch 75/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2606 - acc: 0.9103 - val_loss: 0.2905 - val_acc: 0.9070\n",
      "Epoch 76/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2597 - acc: 0.9104 - val_loss: 0.2969 - val_acc: 0.9077\n",
      "Epoch 77/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2602 - acc: 0.9103 - val_loss: 0.2881 - val_acc: 0.9076\n",
      "Epoch 78/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2592 - acc: 0.9104 - val_loss: 0.2868 - val_acc: 0.9077\n",
      "Epoch 79/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2598 - acc: 0.9105 - val_loss: 0.2886 - val_acc: 0.9079\n",
      "Epoch 80/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2590 - acc: 0.9102 - val_loss: 0.2886 - val_acc: 0.9077: 0.2\n",
      "Epoch 81/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2589 - acc: 0.9098 - val_loss: 0.2866 - val_acc: 0.9077\n",
      "Epoch 82/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2600 - acc: 0.9099 - val_loss: 0.2823 - val_acc: 0.9081\n",
      "Epoch 83/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2580 - acc: 0.9102 - val_loss: 0.2838 - val_acc: 0.9084\n",
      "Epoch 84/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2572 - acc: 0.9104 - val_loss: 0.2964 - val_acc: 0.9072\n",
      "Epoch 85/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2572 - acc: 0.9105 - val_loss: 0.2835 - val_acc: 0.9073 0.2572 - a\n",
      "Epoch 86/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2581 - acc: 0.9096 - val_loss: 0.2899 - val_acc: 0.9070\n",
      "Epoch 87/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2566 - acc: 0.9107 - val_loss: 0.2884 - val_acc: 0.9079\n",
      "Epoch 88/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2569 - acc: 0.9106 - val_loss: 0.2913 - val_acc: 0.9073\n",
      "Epoch 89/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2554 - acc: 0.9102 - val_loss: 0.2859 - val_acc: 0.9080\n",
      "Epoch 90/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2572 - acc: 0.9101 - val_loss: 0.2875 - val_acc: 0.9072\n",
      "Epoch 91/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2548 - acc: 0.9111 - val_loss: 0.2931 - val_acc: 0.9060\n",
      "Epoch 92/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2539 - acc: 0.9116 - val_loss: 0.2846 - val_acc: 0.9083\n",
      "Epoch 93/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2556 - acc: 0.9105 - val_loss: 0.2868 - val_acc: 0.9079\n",
      "Epoch 94/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2539 - acc: 0.9106 - val_loss: 0.2878 - val_acc: 0.9085\n",
      "Epoch 95/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2552 - acc: 0.9104 - val_loss: 0.2848 - val_acc: 0.9084\n",
      "Epoch 96/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2532 - acc: 0.9113 - val_loss: 0.2849 - val_acc: 0.90802536 -\n",
      "Epoch 97/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2530 - acc: 0.9108 - val_loss: 0.2830 - val_acc: 0.9079\n",
      "Epoch 98/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2541 - acc: 0.9104 - val_loss: 0.2860 - val_acc: 0.9079\n",
      "Epoch 99/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2531 - acc: 0.9105 - val_loss: 0.2835 - val_acc: 0.9073ETA: 2s  - ETA: 0s - loss: 0.2536 - acc: 0.\n",
      "Epoch 100/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2549 - acc: 0.9105 - val_loss: 0.2823 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_1.hdf5\n",
      "Epoch 101/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2519 - acc: 0.9113 - val_loss: 0.2810 - val_acc: 0.9076\n",
      "Epoch 102/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2514 - acc: 0.9110 - val_loss: 0.2845 - val_acc: 0.9077\n",
      "Epoch 103/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2523 - acc: 0.9108 - val_loss: 0.2846 - val_acc: 0.9072\n",
      "Epoch 104/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2503 - acc: 0.9106 - val_loss: 0.2883 - val_acc: 0.9070\n",
      "Epoch 105/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2508 - acc: 0.9109 - val_loss: 0.2856 - val_acc: 0.9073\n",
      "Epoch 106/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2526 - acc: 0.9116 - val_loss: 0.2847 - val_acc: 0.9073\n",
      "Epoch 107/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2506 - acc: 0.9115 - val_loss: 0.2901 - val_acc: 0.90699 - ETA: 0s - loss: 0.2508 - acc: 0.91\n",
      "Epoch 108/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2511 - acc: 0.9106 - val_loss: 0.2851 - val_acc: 0.9070\n",
      "Epoch 109/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2525 - acc: 0.9112 - val_loss: 0.2886 - val_acc: 0.9079\n",
      "Epoch 110/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2501 - acc: 0.9116 - val_loss: 0.2856 - val_acc: 0.9083\n",
      "Epoch 111/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2488 - acc: 0.9113 - val_loss: 0.2865 - val_acc: 0.9070\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2505 - acc: 0.9105 - val_loss: 0.2864 - val_acc: 0.9077\n",
      "Epoch 113/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2490 - acc: 0.9112 - val_loss: 0.2895 - val_acc: 0.9068\n",
      "Epoch 114/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2488 - acc: 0.9116 - val_loss: 0.2860 - val_acc: 0.9073s: 0.24 - ETA: 1s - loss: 0\n",
      "Epoch 115/1000\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2504 - acc: 0.9116 - val_loss: 0.2844 - val_acc: 0.9081\n",
      "Epoch 116/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2514 - acc: 0.9113 - val_loss: 0.2882 - val_acc: 0.9075\n",
      "Epoch 117/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2483 - acc: 0.9117 - val_loss: 0.2853 - val_acc: 0.9072\n",
      "Epoch 118/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2475 - acc: 0.9117 - val_loss: 0.2844 - val_acc: 0.9080\n",
      "Epoch 119/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2492 - acc: 0.9107 - val_loss: 0.2863 - val_acc: 0.9077\n",
      "Epoch 120/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2461 - acc: 0.9118 - val_loss: 0.2889 - val_acc: 0.9075\n",
      "Epoch 121/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2477 - acc: 0.9119 - val_loss: 0.2860 - val_acc: 0.9077\n",
      "Epoch 122/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2466 - acc: 0.9118 - val_loss: 0.2849 - val_acc: 0.9073\n",
      "Epoch 123/1000\n",
      "66413/66413 [==============================] - 25s 370us/step - loss: 0.2473 - acc: 0.9118 - val_loss: 0.2852 - val_acc: 0.9066\n",
      "Epoch 124/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2467 - acc: 0.9117 - val_loss: 0.2846 - val_acc: 0.9079\n",
      "Epoch 125/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2447 - acc: 0.9121 - val_loss: 0.2844 - val_acc: 0.9073\n",
      "Epoch 126/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2459 - acc: 0.9117 - val_loss: 0.2852 - val_acc: 0.9068\n",
      "Epoch 127/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2476 - acc: 0.9114 - val_loss: 0.2868 - val_acc: 0.9072\n",
      "Epoch 128/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2455 - acc: 0.9124 - val_loss: 0.2844 - val_acc: 0.9075\n",
      "Epoch 129/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2449 - acc: 0.9124 - val_loss: 0.2841 - val_acc: 0.9079\n",
      "Epoch 130/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2444 - acc: 0.9116 - val_loss: 0.2844 - val_acc: 0.9077\n",
      "Epoch 131/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2459 - acc: 0.9122 - val_loss: 0.2840 - val_acc: 0.9076\n",
      "Epoch 132/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2449 - acc: 0.9124 - val_loss: 0.2853 - val_acc: 0.9070\n",
      "Epoch 133/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2464 - acc: 0.9119 - val_loss: 0.2843 - val_acc: 0.9077\n",
      "Epoch 134/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2436 - acc: 0.9118 - val_loss: 0.2851 - val_acc: 0.9073\n",
      "Epoch 135/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2453 - acc: 0.9119 - val_loss: 0.2831 - val_acc: 0.9072\n",
      "Epoch 136/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2440 - acc: 0.9120 - val_loss: 0.2851 - val_acc: 0.9075\n",
      "Epoch 137/1000\n",
      "66413/66413 [==============================] - 25s 372us/step - loss: 0.2427 - acc: 0.9126 - val_loss: 0.2847 - val_acc: 0.90642426 - acc: 0.912\n",
      "Epoch 138/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2428 - acc: 0.9124 - val_loss: 0.2855 - val_acc: 0.9069\n",
      "Epoch 139/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2415 - acc: 0.9117 - val_loss: 0.2846 - val_acc: 0.9072\n",
      "Epoch 140/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2440 - acc: 0.9128 - val_loss: 0.2853 - val_acc: 0.9076\n",
      "Epoch 141/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2443 - acc: 0.9123 - val_loss: 0.2850 - val_acc: 0.9077 0s - loss: 0.2439 - ac\n",
      "Epoch 142/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2414 - acc: 0.9127 - val_loss: 0.2837 - val_acc: 0.9075\n",
      "Epoch 143/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2420 - acc: 0.9126 - val_loss: 0.2850 - val_acc: 0.9066\n",
      "Epoch 144/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2414 - acc: 0.9129 - val_loss: 0.2855 - val_acc: 0.9069\n",
      "Epoch 145/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2389 - acc: 0.9135 - val_loss: 0.2857 - val_acc: 0.9069\n",
      "Epoch 146/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2430 - acc: 0.9126 - val_loss: 0.2851 - val_acc: 0.9070\n",
      "Epoch 147/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2427 - acc: 0.9115 - val_loss: 0.2846 - val_acc: 0.9079\n",
      "Epoch 148/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2419 - acc: 0.9123 - val_loss: 0.2854 - val_acc: 0.9070\n",
      "Epoch 149/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2408 - acc: 0.9133 - val_loss: 0.2845 - val_acc: 0.9069\n",
      "Epoch 150/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2402 - acc: 0.9128 - val_loss: 0.2865 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_1.hdf5\n",
      "Epoch 151/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2414 - acc: 0.9124 - val_loss: 0.2848 - val_acc: 0.9072\n",
      "AUC: 0.706052\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/1000\n",
      "66413/66413 [==============================] - 25s 376us/step - loss: 0.3126 - acc: 0.9072 - val_loss: 0.3048 - val_acc: 0.9123\n",
      "Epoch 2/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.3036 - acc: 0.9090 - val_loss: 0.3014 - val_acc: 0.9123\n",
      "Epoch 3/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2980 - acc: 0.9090 - val_loss: 0.2891 - val_acc: 0.9123\n",
      "Epoch 4/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2941 - acc: 0.9090 - val_loss: 0.2868 - val_acc: 0.9123\n",
      "Epoch 5/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2931 - acc: 0.9090 - val_loss: 0.2918 - val_acc: 0.9123\n",
      "Epoch 6/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2921 - acc: 0.9091 - val_loss: 0.2862 - val_acc: 0.9123\n",
      "Epoch 7/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2902 - acc: 0.9090 - val_loss: 0.2852 - val_acc: 0.9123\n",
      "Epoch 8/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2903 - acc: 0.9090 - val_loss: 0.2844 - val_acc: 0.9123\n",
      "Epoch 9/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2885 - acc: 0.9090 - val_loss: 0.2849 - val_acc: 0.9123\n",
      "Epoch 10/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2892 - acc: 0.9090 - val_loss: 0.2873 - val_acc: 0.9123\n",
      "Epoch 11/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2882 - acc: 0.9091 - val_loss: 0.2927 - val_acc: 0.9125\n",
      "Epoch 12/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2866 - acc: 0.9089 - val_loss: 0.2844 - val_acc: 0.9123\n",
      "Epoch 13/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2851 - acc: 0.9090 - val_loss: 0.2876 - val_acc: 0.9125\n",
      "Epoch 14/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2861 - acc: 0.9089 - val_loss: 0.2852 - val_acc: 0.9123\n",
      "Epoch 15/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2850 - acc: 0.9090 - val_loss: 0.2818 - val_acc: 0.9123loss: 0.286 - ETA: 1s - loss:\n",
      "Epoch 16/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2843 - acc: 0.9090 - val_loss: 0.2896 - val_acc: 0.9125\n",
      "Epoch 17/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2831 - acc: 0.9090 - val_loss: 0.2874 - val_acc: 0.9127\n",
      "Epoch 18/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2820 - acc: 0.9090 - val_loss: 0.2852 - val_acc: 0.9125\n",
      "Epoch 19/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2818 - acc: 0.9090 - val_loss: 0.2908 - val_acc: 0.9123\n",
      "Epoch 20/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2799 - acc: 0.9091 - val_loss: 0.2945 - val_acc: 0.9126\n",
      "Epoch 21/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2787 - acc: 0.9091 - val_loss: 0.2856 - val_acc: 0.9125 ETA: 1s - loss: 0.277\n",
      "Epoch 22/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2788 - acc: 0.9089 - val_loss: 0.2796 - val_acc: 0.9126\n",
      "Epoch 23/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2783 - acc: 0.9090 - val_loss: 0.2847 - val_acc: 0.9126\n",
      "Epoch 24/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2786 - acc: 0.9089 - val_loss: 0.2818 - val_acc: 0.9125\n",
      "Epoch 25/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2782 - acc: 0.9089 - val_loss: 0.2939 - val_acc: 0.9126\n",
      "Epoch 26/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2779 - acc: 0.9093 - val_loss: 0.2975 - val_acc: 0.9125\n",
      "Epoch 27/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2760 - acc: 0.9092 - val_loss: 0.2855 - val_acc: 0.9125\n",
      "Epoch 28/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2764 - acc: 0.9091 - val_loss: 0.2912 - val_acc: 0.9119 0.\n",
      "Epoch 29/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2757 - acc: 0.9089 - val_loss: 0.2871 - val_acc: 0.9122\n",
      "Epoch 30/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2758 - acc: 0.9092 - val_loss: 0.2842 - val_acc: 0.9123\n",
      "Epoch 31/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2743 - acc: 0.9088 - val_loss: 0.2920 - val_acc: 0.9123\n",
      "Epoch 32/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2734 - acc: 0.9093 - val_loss: 0.2786 - val_acc: 0.9126\n",
      "Epoch 33/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2737 - acc: 0.9088 - val_loss: 0.2983 - val_acc: 0.9118\n",
      "Epoch 34/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2731 - acc: 0.9094 - val_loss: 0.2886 - val_acc: 0.9123\n",
      "Epoch 35/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2721 - acc: 0.9089 - val_loss: 0.2840 - val_acc: 0.9127\n",
      "Epoch 36/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2713 - acc: 0.9091 - val_loss: 0.2922 - val_acc: 0.9127\n",
      "Epoch 37/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2726 - acc: 0.9089 - val_loss: 0.3029 - val_acc: 0.9126\n",
      "Epoch 38/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2705 - acc: 0.9091 - val_loss: 0.2946 - val_acc: 0.9119\n",
      "Epoch 39/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2706 - acc: 0.9092 - val_loss: 0.3007 - val_acc: 0.9117\n",
      "Epoch 40/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2692 - acc: 0.9091 - val_loss: 0.2932 - val_acc: 0.9117\n",
      "Epoch 41/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2698 - acc: 0.9093 - val_loss: 0.2914 - val_acc: 0.9118\n",
      "Epoch 42/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2696 - acc: 0.9094 - val_loss: 0.2809 - val_acc: 0.9118\n",
      "Epoch 43/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2685 - acc: 0.9087 - val_loss: 0.2866 - val_acc: 0.9118\n",
      "Epoch 44/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2685 - acc: 0.9090 - val_loss: 0.2892 - val_acc: 0.9117\n",
      "Epoch 45/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2683 - acc: 0.9091 - val_loss: 0.2850 - val_acc: 0.9121\n",
      "Epoch 46/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2686 - acc: 0.9096 - val_loss: 0.2935 - val_acc: 0.9123\n",
      "Epoch 47/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2662 - acc: 0.9095 - val_loss: 0.2827 - val_acc: 0.9122\n",
      "Epoch 48/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2664 - acc: 0.9097 - val_loss: 0.2944 - val_acc: 0.9112\n",
      "Epoch 49/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2660 - acc: 0.9094 - val_loss: 0.2810 - val_acc: 0.9122\n",
      "Epoch 50/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2661 - acc: 0.9090 - val_loss: 0.2863 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_2.hdf5\n",
      "Epoch 51/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2647 - acc: 0.9092 - val_loss: 0.2961 - val_acc: 0.9115\n",
      "Epoch 52/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2649 - acc: 0.9092 - val_loss: 0.2866 - val_acc: 0.9121\n",
      "Epoch 53/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2641 - acc: 0.9098 - val_loss: 0.2910 - val_acc: 0.9114\n",
      "Epoch 54/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2630 - acc: 0.9095 - val_loss: 0.2825 - val_acc: 0.9123\n",
      "Epoch 55/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2651 - acc: 0.9096 - val_loss: 0.2850 - val_acc: 0.9122\n",
      "Epoch 56/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2618 - acc: 0.9095 - val_loss: 0.2849 - val_acc: 0.9115\n",
      "Epoch 57/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2624 - acc: 0.9095 - val_loss: 0.2889 - val_acc: 0.9119 4s - loss: 0.2596 - - ETA: 3s - loss: 0.259 - ETA: 2s -\n",
      "Epoch 58/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2628 - acc: 0.9092 - val_loss: 0.2901 - val_acc: 0.9118\n",
      "Epoch 59/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2626 - acc: 0.9089 - val_loss: 0.2832 - val_acc: 0.9119\n",
      "Epoch 60/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2608 - acc: 0.9095 - val_loss: 0.2882 - val_acc: 0.9103\n",
      "Epoch 61/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2610 - acc: 0.9094 - val_loss: 0.2820 - val_acc: 0.9119\n",
      "Epoch 62/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2600 - acc: 0.9098 - val_loss: 0.2853 - val_acc: 0.9114\n",
      "Epoch 63/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2608 - acc: 0.9098 - val_loss: 0.2887 - val_acc: 0.9115\n",
      "Epoch 64/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2596 - acc: 0.9100 - val_loss: 0.2795 - val_acc: 0.9115\n",
      "Epoch 65/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2605 - acc: 0.9093 - val_loss: 0.2872 - val_acc: 0.9107\n",
      "Epoch 66/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2599 - acc: 0.9100 - val_loss: 0.2777 - val_acc: 0.9121\n",
      "Epoch 67/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2592 - acc: 0.9098 - val_loss: 0.2848 - val_acc: 0.9110\n",
      "Epoch 68/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2598 - acc: 0.9097 - val_loss: 0.2809 - val_acc: 0.9117\n",
      "Epoch 69/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2582 - acc: 0.9104 - val_loss: 0.2877 - val_acc: 0.9099\n",
      "Epoch 70/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2582 - acc: 0.9097 - val_loss: 0.2829 - val_acc: 0.9115 - ETA: 0s - loss: 0.2585 - acc: 0.90\n",
      "Epoch 71/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2571 - acc: 0.9095 - val_loss: 0.2836 - val_acc: 0.9112\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2587 - acc: 0.9099 - val_loss: 0.2881 - val_acc: 0.9099\n",
      "Epoch 73/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2564 - acc: 0.9103 - val_loss: 0.2843 - val_acc: 0.9106\n",
      "Epoch 74/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2570 - acc: 0.9099 - val_loss: 0.2781 - val_acc: 0.9110\n",
      "Epoch 75/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2556 - acc: 0.9097 - val_loss: 0.2850 - val_acc: 0.9103\n",
      "Epoch 76/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2553 - acc: 0.9101 - val_loss: 0.2854 - val_acc: 0.9104\n",
      "Epoch 77/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2541 - acc: 0.9105 - val_loss: 0.2830 - val_acc: 0.9106\n",
      "Epoch 78/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2542 - acc: 0.9104 - val_loss: 0.2857 - val_acc: 0.9104\n",
      "Epoch 79/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2553 - acc: 0.9105 - val_loss: 0.2830 - val_acc: 0.9107\n",
      "Epoch 80/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2543 - acc: 0.9103 - val_loss: 0.2831 - val_acc: 0.9107\n",
      "Epoch 81/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2536 - acc: 0.9106 - val_loss: 0.2800 - val_acc: 0.9104\n",
      "Epoch 82/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2535 - acc: 0.9109 - val_loss: 0.2824 - val_acc: 0.9104\n",
      "Epoch 83/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2549 - acc: 0.9108 - val_loss: 0.2873 - val_acc: 0.9114\n",
      "Epoch 84/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2527 - acc: 0.9106 - val_loss: 0.2836 - val_acc: 0.9106\n",
      "Epoch 85/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2509 - acc: 0.9110 - val_loss: 0.2816 - val_acc: 0.9099 - loss: 0.2512 - acc:\n",
      "Epoch 86/1000\n",
      "66413/66413 [==============================] - 25s 369us/step - loss: 0.2520 - acc: 0.9105 - val_loss: 0.2829 - val_acc: 0.9103\n",
      "Epoch 87/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2512 - acc: 0.9109 - val_loss: 0.2891 - val_acc: 0.9103\n",
      "Epoch 88/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2503 - acc: 0.9111 - val_loss: 0.2832 - val_acc: 0.9100\n",
      "Epoch 89/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2505 - acc: 0.9111 - val_loss: 0.2844 - val_acc: 0.9103\n",
      "Epoch 90/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2507 - acc: 0.9109 - val_loss: 0.2859 - val_acc: 0.9104\n",
      "Epoch 91/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2495 - acc: 0.9107 - val_loss: 0.2912 - val_acc: 0.9095\n",
      "Epoch 92/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2501 - acc: 0.9107 - val_loss: 0.2832 - val_acc: 0.9111\n",
      "Epoch 93/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2502 - acc: 0.9105 - val_loss: 0.2837 - val_acc: 0.9103\n",
      "Epoch 94/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2490 - acc: 0.9115 - val_loss: 0.2817 - val_acc: 0.9106\n",
      "Epoch 95/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2480 - acc: 0.9113 - val_loss: 0.2803 - val_acc: 0.9104\n",
      "Epoch 96/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2503 - acc: 0.9105 - val_loss: 0.2822 - val_acc: 0.9104\n",
      "Epoch 97/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2493 - acc: 0.9108 - val_loss: 0.2818 - val_acc: 0.9112\n",
      "Epoch 98/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2486 - acc: 0.9116 - val_loss: 0.2804 - val_acc: 0.9108\n",
      "Epoch 99/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2486 - acc: 0.9122 - val_loss: 0.2851 - val_acc: 0.9095\n",
      "Epoch 100/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2488 - acc: 0.9113 - val_loss: 0.2843 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_2.hdf5\n",
      "Epoch 101/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2494 - acc: 0.9104 - val_loss: 0.2835 - val_acc: 0.9103- loss: 0.2494 - acc\n",
      "Epoch 102/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2462 - acc: 0.9110 - val_loss: 0.2843 - val_acc: 0.9096\n",
      "Epoch 103/1000\n",
      "66413/66413 [==============================] - 24s 369us/step - loss: 0.2481 - acc: 0.9117 - val_loss: 0.2833 - val_acc: 0.9102\n",
      "Epoch 104/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2483 - acc: 0.9110 - val_loss: 0.2885 - val_acc: 0.9087\n",
      "Epoch 105/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2468 - acc: 0.9112 - val_loss: 0.2820 - val_acc: 0.9107\n",
      "Epoch 106/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2477 - acc: 0.9117 - val_loss: 0.2812 - val_acc: 0.9111\n",
      "Epoch 107/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2474 - acc: 0.9113 - val_loss: 0.2854 - val_acc: 0.9103\n",
      "Epoch 108/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2459 - acc: 0.9121 - val_loss: 0.2836 - val_acc: 0.9107\n",
      "Epoch 109/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2467 - acc: 0.9114 - val_loss: 0.2832 - val_acc: 0.9115\n",
      "Epoch 110/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2461 - acc: 0.9114 - val_loss: 0.2846 - val_acc: 0.9103 0.245\n",
      "Epoch 111/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2451 - acc: 0.9118 - val_loss: 0.2835 - val_acc: 0.9108\n",
      "Epoch 112/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2459 - acc: 0.9114 - val_loss: 0.2805 - val_acc: 0.9118cc: 0 - ETA: 1s - loss: 0.2457 -\n",
      "Epoch 113/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2454 - acc: 0.9117 - val_loss: 0.2836 - val_acc: 0.9110\n",
      "Epoch 114/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2453 - acc: 0.9118 - val_loss: 0.2836 - val_acc: 0.9100s - los - ETA: 1s - loss: 0.245\n",
      "Epoch 115/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2452 - acc: 0.9117 - val_loss: 0.2861 - val_acc: 0.9096\n",
      "Epoch 116/1000\n",
      "66413/66413 [==============================] - 24s 368us/step - loss: 0.2425 - acc: 0.9122 - val_loss: 0.2844 - val_acc: 0.9104\n",
      "AUC: 0.690526\n",
      "Train on 66413 samples, validate on 7380 samples\n",
      "Epoch 1/1000\n",
      "66413/66413 [==============================] - 25s 376us/step - loss: 0.3137 - acc: 0.9074 - val_loss: 0.3126 - val_acc: 0.9092\n",
      "Epoch 2/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.3044 - acc: 0.9094 - val_loss: 0.3028 - val_acc: 0.9092\n",
      "Epoch 3/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.3001 - acc: 0.9094 - val_loss: 0.2974 - val_acc: 0.9092 loss:\n",
      "Epoch 4/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2943 - acc: 0.9094 - val_loss: 0.2910 - val_acc: 0.9092\n",
      "Epoch 5/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2937 - acc: 0.9094 - val_loss: 0.2963 - val_acc: 0.9092\n",
      "Epoch 6/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2925 - acc: 0.9094 - val_loss: 0.2927 - val_acc: 0.9092\n",
      "Epoch 7/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2936 - acc: 0.9094 - val_loss: 0.3011 - val_acc: 0.9093\n",
      "Epoch 8/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2911 - acc: 0.9094 - val_loss: 0.2908 - val_acc: 0.9093\n",
      "Epoch 9/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2901 - acc: 0.9094 - val_loss: 0.2878 - val_acc: 0.9092s - loss: 0.2902 - acc:\n",
      "Epoch 10/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2902 - acc: 0.9094 - val_loss: 0.2894 - val_acc: 0.9093\n",
      "Epoch 11/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2885 - acc: 0.9094 - val_loss: 0.2912 - val_acc: 0.9092\n",
      "Epoch 12/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2879 - acc: 0.9094 - val_loss: 0.2923 - val_acc: 0.9091\n",
      "Epoch 13/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2879 - acc: 0.9094 - val_loss: 0.2912 - val_acc: 0.9093\n",
      "Epoch 14/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2866 - acc: 0.9094 - val_loss: 0.2988 - val_acc: 0.9091\n",
      "Epoch 15/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2858 - acc: 0.9094 - val_loss: 0.2959 - val_acc: 0.9089\n",
      "Epoch 16/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2849 - acc: 0.9095 - val_loss: 0.2854 - val_acc: 0.9092\n",
      "Epoch 17/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2843 - acc: 0.9093 - val_loss: 0.2996 - val_acc: 0.9093\n",
      "Epoch 18/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2834 - acc: 0.9095 - val_loss: 0.2830 - val_acc: 0.9092.28 - ETA: 0s - loss: 0.2837 - acc: 0.9\n",
      "Epoch 19/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2832 - acc: 0.9094 - val_loss: 0.2961 - val_acc: 0.9089\n",
      "Epoch 20/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2819 - acc: 0.9094 - val_loss: 0.2866 - val_acc: 0.9091\n",
      "Epoch 21/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2819 - acc: 0.9095 - val_loss: 0.2968 - val_acc: 0.9095\n",
      "Epoch 22/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2805 - acc: 0.9094 - val_loss: 0.2874 - val_acc: 0.9093\n",
      "Epoch 23/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2802 - acc: 0.9092 - val_loss: 0.2835 - val_acc: 0.9092\n",
      "Epoch 24/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2807 - acc: 0.9094 - val_loss: 0.2913 - val_acc: 0.9095 1s - loss: 0.28\n",
      "Epoch 25/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2798 - acc: 0.9092 - val_loss: 0.2996 - val_acc: 0.9091\n",
      "Epoch 26/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2796 - acc: 0.9095 - val_loss: 0.2878 - val_acc: 0.9092\n",
      "Epoch 27/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2785 - acc: 0.9093 - val_loss: 0.2966 - val_acc: 0.9095\n",
      "Epoch 28/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2776 - acc: 0.9093 - val_loss: 0.2841 - val_acc: 0.9092\n",
      "Epoch 29/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2771 - acc: 0.9095 - val_loss: 0.3094 - val_acc: 0.9089\n",
      "Epoch 30/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2764 - acc: 0.9092 - val_loss: 0.2852 - val_acc: 0.9089\n",
      "Epoch 31/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2770 - acc: 0.9092 - val_loss: 0.2856 - val_acc: 0.9091\n",
      "Epoch 32/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2767 - acc: 0.9092 - val_loss: 0.2925 - val_acc: 0.9088\n",
      "Epoch 33/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2767 - acc: 0.9094 - val_loss: 0.2818 - val_acc: 0.9087\n",
      "Epoch 34/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2761 - acc: 0.9092 - val_loss: 0.2922 - val_acc: 0.9087\n",
      "Epoch 35/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2751 - acc: 0.9094 - val_loss: 0.2818 - val_acc: 0.9092\n",
      "Epoch 36/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2753 - acc: 0.9095 - val_loss: 0.2888 - val_acc: 0.9089\n",
      "Epoch 37/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2742 - acc: 0.9090 - val_loss: 0.2855 - val_acc: 0.9095\n",
      "Epoch 38/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2744 - acc: 0.9089 - val_loss: 0.2941 - val_acc: 0.9093\n",
      "Epoch 39/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2725 - acc: 0.9093 - val_loss: 0.2882 - val_acc: 0.9093\n",
      "Epoch 40/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2725 - acc: 0.9094 - val_loss: 0.2954 - val_acc: 0.9089\n",
      "Epoch 41/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2716 - acc: 0.9095 - val_loss: 0.2829 - val_acc: 0.9095\n",
      "Epoch 42/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2723 - acc: 0.9092 - val_loss: 0.2959 - val_acc: 0.9091\n",
      "Epoch 43/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2725 - acc: 0.9094 - val_loss: 0.2873 - val_acc: 0.9088\n",
      "Epoch 44/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2718 - acc: 0.9094 - val_loss: 0.2845 - val_acc: 0.9089\n",
      "Epoch 45/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2720 - acc: 0.9090 - val_loss: 0.2883 - val_acc: 0.9089\n",
      "Epoch 46/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2701 - acc: 0.9095 - val_loss: 0.2962 - val_acc: 0.9089\n",
      "Epoch 47/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2702 - acc: 0.9096 - val_loss: 0.2892 - val_acc: 0.9092\n",
      "Epoch 48/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2698 - acc: 0.9091 - val_loss: 0.2995 - val_acc: 0.90850s - loss: 0.2691 - ac\n",
      "Epoch 49/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2687 - acc: 0.9097 - val_loss: 0.2949 - val_acc: 0.9085\n",
      "Epoch 50/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2679 - acc: 0.9096 - val_loss: 0.2989 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_3.hdf5\n",
      "Epoch 51/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2697 - acc: 0.9097 - val_loss: 0.2822 - val_acc: 0.9088\n",
      "Epoch 52/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2678 - acc: 0.9094 - val_loss: 0.2798 - val_acc: 0.9085\n",
      "Epoch 53/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2678 - acc: 0.9096 - val_loss: 0.2836 - val_acc: 0.9091\n",
      "Epoch 54/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2673 - acc: 0.9097 - val_loss: 0.2833 - val_acc: 0.9088\n",
      "Epoch 55/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2673 - acc: 0.9093 - val_loss: 0.2974 - val_acc: 0.9083\n",
      "Epoch 56/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2674 - acc: 0.9094 - val_loss: 0.2843 - val_acc: 0.9091\n",
      "Epoch 57/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2654 - acc: 0.9099 - val_loss: 0.2850 - val_acc: 0.9087\n",
      "Epoch 58/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2664 - acc: 0.9096 - val_loss: 0.2888 - val_acc: 0.9088\n",
      "Epoch 59/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2647 - acc: 0.9099 - val_loss: 0.2851 - val_acc: 0.9087\n",
      "Epoch 60/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2657 - acc: 0.9097 - val_loss: 0.2866 - val_acc: 0.9084\n",
      "Epoch 61/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2655 - acc: 0.9099 - val_loss: 0.2888 - val_acc: 0.9088\n",
      "Epoch 62/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2653 - acc: 0.9090 - val_loss: 0.2793 - val_acc: 0.9093\n",
      "Epoch 63/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2635 - acc: 0.9099 - val_loss: 0.2955 - val_acc: 0.9092\n",
      "Epoch 64/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2627 - acc: 0.9098 - val_loss: 0.2901 - val_acc: 0.9084\n",
      "Epoch 65/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2652 - acc: 0.9094 - val_loss: 0.2858 - val_acc: 0.9084\n",
      "Epoch 66/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2641 - acc: 0.9094 - val_loss: 0.2935 - val_acc: 0.9089\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2631 - acc: 0.9101 - val_loss: 0.2820 - val_acc: 0.9088: - ETA: 2\n",
      "Epoch 68/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2635 - acc: 0.9095 - val_loss: 0.2927 - val_acc: 0.9088\n",
      "Epoch 69/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2629 - acc: 0.9101 - val_loss: 0.2836 - val_acc: 0.9088\n",
      "Epoch 70/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2630 - acc: 0.9096 - val_loss: 0.2844 - val_acc: 0.9087\n",
      "Epoch 71/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2615 - acc: 0.9099 - val_loss: 0.2880 - val_acc: 0.9085 0s - loss: 0.2615 - acc: 0.909\n",
      "Epoch 72/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2606 - acc: 0.9099 - val_loss: 0.2827 - val_acc: 0.9084\n",
      "Epoch 73/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2610 - acc: 0.9102 - val_loss: 0.2793 - val_acc: 0.9089\n",
      "Epoch 74/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2601 - acc: 0.9101 - val_loss: 0.2862 - val_acc: 0.9084\n",
      "Epoch 75/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2602 - acc: 0.9099 - val_loss: 0.2822 - val_acc: 0.9089\n",
      "Epoch 76/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2605 - acc: 0.9101 - val_loss: 0.2874 - val_acc: 0.9085\n",
      "Epoch 77/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2591 - acc: 0.9100 - val_loss: 0.2846 - val_acc: 0.9081\n",
      "Epoch 78/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2592 - acc: 0.9100 - val_loss: 0.2854 - val_acc: 0.9081  - ETA: 2s - \n",
      "Epoch 79/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2589 - acc: 0.9099 - val_loss: 0.2794 - val_acc: 0.9083\n",
      "Epoch 80/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2600 - acc: 0.9100 - val_loss: 0.2914 - val_acc: 0.9079\n",
      "Epoch 81/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2588 - acc: 0.9100 - val_loss: 0.2826 - val_acc: 0.9088\n",
      "Epoch 82/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2577 - acc: 0.9100 - val_loss: 0.2858 - val_acc: 0.9087\n",
      "Epoch 83/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2587 - acc: 0.9103 - val_loss: 0.2867 - val_acc: 0.9081\n",
      "Epoch 84/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2569 - acc: 0.9099 - val_loss: 0.2846 - val_acc: 0.9087: 4s - loss: 0.25 -\n",
      "Epoch 85/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2568 - acc: 0.9104 - val_loss: 0.2831 - val_acc: 0.9092\n",
      "Epoch 86/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2569 - acc: 0.9102 - val_loss: 0.2860 - val_acc: 0.9088\n",
      "Epoch 87/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2570 - acc: 0.9101 - val_loss: 0.2869 - val_acc: 0.9084\n",
      "Epoch 88/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2567 - acc: 0.9105 - val_loss: 0.2904 - val_acc: 0.9087\n",
      "Epoch 89/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2544 - acc: 0.9103 - val_loss: 0.2844 - val_acc: 0.90912s - l\n",
      "Epoch 90/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2552 - acc: 0.9102 - val_loss: 0.2818 - val_acc: 0.9081\n",
      "Epoch 91/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2554 - acc: 0.9104 - val_loss: 0.2821 - val_acc: 0.9085\n",
      "Epoch 92/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2552 - acc: 0.9108 - val_loss: 0.2853 - val_acc: 0.9089\n",
      "Epoch 93/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2552 - acc: 0.9105 - val_loss: 0.2828 - val_acc: 0.9093\n",
      "Epoch 94/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2538 - acc: 0.9106 - val_loss: 0.2816 - val_acc: 0.9092\n",
      "Epoch 95/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2546 - acc: 0.9101 - val_loss: 0.2813 - val_acc: 0.9088\n",
      "Epoch 96/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2542 - acc: 0.9113 - val_loss: 0.2815 - val_acc: 0.9092\n",
      "Epoch 97/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2542 - acc: 0.9107 - val_loss: 0.2814 - val_acc: 0.9092\n",
      "Epoch 98/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2524 - acc: 0.9117 - val_loss: 0.2939 - val_acc: 0.9076\n",
      "Epoch 99/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2533 - acc: 0.9103 - val_loss: 0.2817 - val_acc: 0.9087\n",
      "Epoch 100/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2533 - acc: 0.9105 - val_loss: 0.2816 - val_acc: 0.9084s -\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_3.hdf5\n",
      "Epoch 101/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2513 - acc: 0.9113 - val_loss: 0.2826 - val_acc: 0.9092\n",
      "Epoch 102/1000\n",
      "66413/66413 [==============================] - 24s 367us/step - loss: 0.2529 - acc: 0.9106 - val_loss: 0.2844 - val_acc: 0.9085\n",
      "Epoch 103/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2508 - acc: 0.9114 - val_loss: 0.2837 - val_acc: 0.9087 0.2 - ETA: 4s - lo - ETA: 2s - lo\n",
      "Epoch 104/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2521 - acc: 0.9113 - val_loss: 0.2886 - val_acc: 0.9080\n",
      "Epoch 105/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2501 - acc: 0.9113 - val_loss: 0.2845 - val_acc: 0.9081\n",
      "Epoch 106/1000\n",
      "66413/66413 [==============================] - 24s 365us/step - loss: 0.2505 - acc: 0.9114 - val_loss: 0.2822 - val_acc: 0.9079\n",
      "Epoch 107/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2497 - acc: 0.9121 - val_loss: 0.2818 - val_acc: 0.9084\n",
      "Epoch 108/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2504 - acc: 0.9118 - val_loss: 0.2815 - val_acc: 0.9087\n",
      "Epoch 109/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2495 - acc: 0.9118 - val_loss: 0.2846 - val_acc: 0.9076\n",
      "Epoch 110/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2522 - acc: 0.9108 - val_loss: 0.2831 - val_acc: 0.9087\n",
      "Epoch 111/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2509 - acc: 0.9115 - val_loss: 0.2839 - val_acc: 0.9083\n",
      "Epoch 112/1000\n",
      "66413/66413 [==============================] - 24s 366us/step - loss: 0.2513 - acc: 0.9108 - val_loss: 0.2826 - val_acc: 0.9083\n",
      "AUC: 0.715062\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 379us/step - loss: 0.3115 - acc: 0.9092 - val_loss: 0.3146 - val_acc: 0.9053 4s - loss: 0. - ETA: 2s\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.3007 - acc: 0.9098 - val_loss: 0.3066 - val_acc: 0.9053\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2944 - acc: 0.9098 - val_loss: 0.3100 - val_acc: 0.9053\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2937 - acc: 0.9098 - val_loss: 0.2990 - val_acc: 0.9053\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2930 - acc: 0.9098 - val_loss: 0.2988 - val_acc: 0.9053\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2908 - acc: 0.9098 - val_loss: 0.3053 - val_acc: 0.9053\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2899 - acc: 0.9098 - val_loss: 0.2967 - val_acc: 0.9053c: 0\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2888 - acc: 0.9098 - val_loss: 0.2960 - val_acc: 0.9053\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2882 - acc: 0.9099 - val_loss: 0.2940 - val_acc: 0.9053\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2873 - acc: 0.9098 - val_loss: 0.2943 - val_acc: 0.9053\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2861 - acc: 0.9099 - val_loss: 0.2962 - val_acc: 0.9053\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2846 - acc: 0.9099 - val_loss: 0.2928 - val_acc: 0.9053\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2848 - acc: 0.9099 - val_loss: 0.2919 - val_acc: 0.9054\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2842 - acc: 0.9097 - val_loss: 0.2954 - val_acc: 0.9054\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2837 - acc: 0.9096 - val_loss: 0.2945 - val_acc: 0.9038\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2809 - acc: 0.9098 - val_loss: 0.2995 - val_acc: 0.90459 -  - ETA: 1s - loss: 0.2811 \n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2819 - acc: 0.9099 - val_loss: 0.2884 - val_acc: 0.9053\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2811 - acc: 0.9098 - val_loss: 0.2883 - val_acc: 0.9049\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2806 - acc: 0.9098 - val_loss: 0.2898 - val_acc: 0.9051\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2786 - acc: 0.9098 - val_loss: 0.2866 - val_acc: 0.9053\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2787 - acc: 0.9101 - val_loss: 0.2856 - val_acc: 0.9049\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2775 - acc: 0.9101 - val_loss: 0.2883 - val_acc: 0.9047\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2762 - acc: 0.9100 - val_loss: 0.2881 - val_acc: 0.9051\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2748 - acc: 0.9097 - val_loss: 0.2884 - val_acc: 0.9049\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2764 - acc: 0.9098 - val_loss: 0.2924 - val_acc: 0.9047\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2756 - acc: 0.9097 - val_loss: 0.3022 - val_acc: 0.9042\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2751 - acc: 0.9098 - val_loss: 0.2865 - val_acc: 0.9051\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2731 - acc: 0.9100 - val_loss: 0.2923 - val_acc: 0.9034\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2735 - acc: 0.9101 - val_loss: 0.2903 - val_acc: 0.9034\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2720 - acc: 0.9099 - val_loss: 0.3058 - val_acc: 0.9024\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2707 - acc: 0.9101 - val_loss: 0.2887 - val_acc: 0.9045\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2716 - acc: 0.9099 - val_loss: 0.2885 - val_acc: 0.9051\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2709 - acc: 0.9098 - val_loss: 0.2847 - val_acc: 0.9050\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2723 - acc: 0.9097 - val_loss: 0.2895 - val_acc: 0.9045\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2701 - acc: 0.9101 - val_loss: 0.3003 - val_acc: 0.9028 loss: 0.2701 \n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2706 - acc: 0.9101 - val_loss: 0.2956 - val_acc: 0.9039\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2695 - acc: 0.9101 - val_loss: 0.2895 - val_acc: 0.9035\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2673 - acc: 0.9102 - val_loss: 0.2865 - val_acc: 0.9050\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2681 - acc: 0.9093 - val_loss: 0.2878 - val_acc: 0.9047\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2674 - acc: 0.9102 - val_loss: 0.2858 - val_acc: 0.9041ss: 0.2679 - acc: 0\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2674 - acc: 0.9103 - val_loss: 0.2913 - val_acc: 0.9038\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2671 - acc: 0.9100 - val_loss: 0.2914 - val_acc: 0.9042\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2648 - acc: 0.9100 - val_loss: 0.2859 - val_acc: 0.9050\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2667 - acc: 0.9101 - val_loss: 0.2926 - val_acc: 0.9038\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2668 - acc: 0.9101 - val_loss: 0.2908 - val_acc: 0.9045\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2651 - acc: 0.9103 - val_loss: 0.2928 - val_acc: 0.9027\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2649 - acc: 0.9104 - val_loss: 0.2880 - val_acc: 0.9042\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2635 - acc: 0.9104 - val_loss: 0.3089 - val_acc: 0.9017\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2633 - acc: 0.9101 - val_loss: 0.2952 - val_acc: 0.9032\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2633 - acc: 0.9100 - val_loss: 0.2952 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_4.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2627 - acc: 0.9105 - val_loss: 0.2900 - val_acc: 0.9039\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2610 - acc: 0.9112 - val_loss: 0.2948 - val_acc: 0.9028\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2611 - acc: 0.9106 - val_loss: 0.2875 - val_acc: 0.9035\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2618 - acc: 0.9105 - val_loss: 0.2960 - val_acc: 0.9041\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2611 - acc: 0.9102 - val_loss: 0.3002 - val_acc: 0.9030\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2593 - acc: 0.9106 - val_loss: 0.2889 - val_acc: 0.9038\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2588 - acc: 0.9106 - val_loss: 0.2920 - val_acc: 0.9038\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2589 - acc: 0.9106 - val_loss: 0.2964 - val_acc: 0.9041\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2600 - acc: 0.9101 - val_loss: 0.2858 - val_acc: 0.9046\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2578 - acc: 0.9109 - val_loss: 0.2922 - val_acc: 0.9028\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2580 - acc: 0.9113 - val_loss: 0.2953 - val_acc: 0.9028\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2571 - acc: 0.9112 - val_loss: 0.2927 - val_acc: 0.9031\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2578 - acc: 0.9104 - val_loss: 0.2910 - val_acc: 0.9038\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2571 - acc: 0.9104 - val_loss: 0.2910 - val_acc: 0.9035\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2567 - acc: 0.9111 - val_loss: 0.2900 - val_acc: 0.9036\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2564 - acc: 0.9102 - val_loss: 0.2868 - val_acc: 0.9050\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2565 - acc: 0.9099 - val_loss: 0.2958 - val_acc: 0.9028\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2561 - acc: 0.9107 - val_loss: 0.2879 - val_acc: 0.9038\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2544 - acc: 0.9108 - val_loss: 0.2857 - val_acc: 0.9047\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2537 - acc: 0.9114 - val_loss: 0.2899 - val_acc: 0.9038\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2544 - acc: 0.9115 - val_loss: 0.2948 - val_acc: 0.9034\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2551 - acc: 0.9110 - val_loss: 0.2919 - val_acc: 0.9030\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2543 - acc: 0.9111 - val_loss: 0.2892 - val_acc: 0.9034\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2537 - acc: 0.9108 - val_loss: 0.2890 - val_acc: 0.9034\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2525 - acc: 0.9111 - val_loss: 0.2905 - val_acc: 0.9028\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2531 - acc: 0.9117 - val_loss: 0.2897 - val_acc: 0.9032\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2515 - acc: 0.9112 - val_loss: 0.2932 - val_acc: 0.9030loss: 0.2507 - acc:  - ETA: 5s  - ETA:\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2520 - acc: 0.9109 - val_loss: 0.2912 - val_acc: 0.9038\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2525 - acc: 0.9117 - val_loss: 0.2887 - val_acc: 0.9045\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2503 - acc: 0.9114 - val_loss: 0.2936 - val_acc: 0.9030\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2508 - acc: 0.9110 - val_loss: 0.2945 - val_acc: 0.9030\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2505 - acc: 0.9117 - val_loss: 0.2926 - val_acc: 0.9039ss: 0.2507 - acc: 0\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2503 - acc: 0.9115 - val_loss: 0.2889 - val_acc: 0.9047\n",
      "AUC: 0.713427\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 381us/step - loss: 0.3114 - acc: 0.9083 - val_loss: 0.3227 - val_acc: 0.9064\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.3028 - acc: 0.9097 - val_loss: 0.3061 - val_acc: 0.9064\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2965 - acc: 0.9097 - val_loss: 0.3059 - val_acc: 0.9064\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2934 - acc: 0.9097 - val_loss: 0.3031 - val_acc: 0.9064\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2917 - acc: 0.9097 - val_loss: 0.3017 - val_acc: 0.9064\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2912 - acc: 0.9097 - val_loss: 0.3079 - val_acc: 0.9064\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2914 - acc: 0.9097 - val_loss: 0.2932 - val_acc: 0.9064\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2890 - acc: 0.9097 - val_loss: 0.2920 - val_acc: 0.9064\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2890 - acc: 0.9097 - val_loss: 0.2997 - val_acc: 0.9064\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2878 - acc: 0.9097 - val_loss: 0.2921 - val_acc: 0.9064\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2876 - acc: 0.9098 - val_loss: 0.2935 - val_acc: 0.9064\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2865 - acc: 0.9097 - val_loss: 0.2931 - val_acc: 0.9064\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2858 - acc: 0.9096 - val_loss: 0.2915 - val_acc: 0.9064 - loss: \n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2849 - acc: 0.9096 - val_loss: 0.2910 - val_acc: 0.9064\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2840 - acc: 0.9098 - val_loss: 0.2895 - val_acc: 0.9064ETA: 0s - loss: 0.2841 - acc: 0.909\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2826 - acc: 0.9098 - val_loss: 0.2896 - val_acc: 0.9064\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2835 - acc: 0.9095 - val_loss: 0.2940 - val_acc: 0.9065\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2823 - acc: 0.9097 - val_loss: 0.2898 - val_acc: 0.9064\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2819 - acc: 0.9098 - val_loss: 0.2908 - val_acc: 0.9065\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2810 - acc: 0.9097 - val_loss: 0.2906 - val_acc: 0.9065\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2796 - acc: 0.9097 - val_loss: 0.2907 - val_acc: 0.906499 - acc:\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2782 - acc: 0.9099 - val_loss: 0.2891 - val_acc: 0.9062\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2784 - acc: 0.9096 - val_loss: 0.2961 - val_acc: 0.9064\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2778 - acc: 0.9096 - val_loss: 0.2879 - val_acc: 0.9062\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2778 - acc: 0.9096 - val_loss: 0.2916 - val_acc: 0.9062\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2773 - acc: 0.9100 - val_loss: 0.2866 - val_acc: 0.9064\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2781 - acc: 0.9095 - val_loss: 0.2873 - val_acc: 0.9064\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2765 - acc: 0.9101 - val_loss: 0.2890 - val_acc: 0.9064\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2741 - acc: 0.9094 - val_loss: 0.2927 - val_acc: 0.9064\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2744 - acc: 0.9097 - val_loss: 0.2885 - val_acc: 0.9064\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2734 - acc: 0.9099 - val_loss: 0.2908 - val_acc: 0.9065\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2729 - acc: 0.9099 - val_loss: 0.2877 - val_acc: 0.9062\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2727 - acc: 0.9099 - val_loss: 0.2856 - val_acc: 0.9064\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2728 - acc: 0.9096 - val_loss: 0.3031 - val_acc: 0.9066\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2735 - acc: 0.9097 - val_loss: 0.2875 - val_acc: 0.9064.2737 - acc:\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2716 - acc: 0.9099 - val_loss: 0.2977 - val_acc: 0.9058\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2714 - acc: 0.9099 - val_loss: 0.2971 - val_acc: 0.9068 - loss: 0.2707 - ac\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2708 - acc: 0.9099 - val_loss: 0.2925 - val_acc: 0.9062\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2711 - acc: 0.9100 - val_loss: 0.2873 - val_acc: 0.9064\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2699 - acc: 0.9099 - val_loss: 0.2890 - val_acc: 0.9068\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2709 - acc: 0.9100 - val_loss: 0.2870 - val_acc: 0.9062\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2687 - acc: 0.9097 - val_loss: 0.2905 - val_acc: 0.9064\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2681 - acc: 0.9096 - val_loss: 0.2865 - val_acc: 0.9065\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2676 - acc: 0.9099 - val_loss: 0.2871 - val_acc: 0.9065\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2685 - acc: 0.9101 - val_loss: 0.2960 - val_acc: 0.9068\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2663 - acc: 0.9103 - val_loss: 0.2891 - val_acc: 0.9069\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2676 - acc: 0.9104 - val_loss: 0.2910 - val_acc: 0.9059\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2666 - acc: 0.9096 - val_loss: 0.2899 - val_acc: 0.9066\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2664 - acc: 0.9100 - val_loss: 0.2954 - val_acc: 0.9068\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2654 - acc: 0.9095 - val_loss: 0.2963 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_5.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2670 - acc: 0.9105 - val_loss: 0.2885 - val_acc: 0.9066\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2651 - acc: 0.9096 - val_loss: 0.2903 - val_acc: 0.9065\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2653 - acc: 0.9102 - val_loss: 0.2895 - val_acc: 0.9062\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2641 - acc: 0.9106 - val_loss: 0.2878 - val_acc: 0.9062\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2635 - acc: 0.9099 - val_loss: 0.2881 - val_acc: 0.9064\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2650 - acc: 0.9103 - val_loss: 0.2890 - val_acc: 0.9065\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2645 - acc: 0.9099 - val_loss: 0.3033 - val_acc: 0.9049\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2629 - acc: 0.9100 - val_loss: 0.2866 - val_acc: 0.9061\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2640 - acc: 0.9099 - val_loss: 0.2901 - val_acc: 0.9062\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2874 - val_acc: 0.9061\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2604 - acc: 0.9102 - val_loss: 0.2886 - val_acc: 0.9061\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2612 - acc: 0.9105 - val_loss: 0.2887 - val_acc: 0.9062\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2614 - acc: 0.9102 - val_loss: 0.2912 - val_acc: 0.9058\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2607 - acc: 0.9100 - val_loss: 0.2905 - val_acc: 0.9058\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2579 - acc: 0.9106 - val_loss: 0.2895 - val_acc: 0.9059\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2598 - acc: 0.9101 - val_loss: 0.2888 - val_acc: 0.9049\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2593 - acc: 0.9110 - val_loss: 0.2905 - val_acc: 0.9058\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2600 - acc: 0.9104 - val_loss: 0.2941 - val_acc: 0.9051\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2566 - acc: 0.9109 - val_loss: 0.2911 - val_acc: 0.9065\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2588 - acc: 0.9106 - val_loss: 0.2903 - val_acc: 0.9061\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2588 - acc: 0.9110 - val_loss: 0.2890 - val_acc: 0.9057\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2590 - acc: 0.9107 - val_loss: 0.2897 - val_acc: 0.9058 - loss: 0 - ETA: 9s - l\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2575 - acc: 0.9108 - val_loss: 0.2882 - val_acc: 0.9065\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2581 - acc: 0.9107 - val_loss: 0.2891 - val_acc: 0.9054\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2574 - acc: 0.9102 - val_loss: 0.2968 - val_acc: 0.9046\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2563 - acc: 0.9108 - val_loss: 0.2944 - val_acc: 0.9045\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2559 - acc: 0.9109 - val_loss: 0.2909 - val_acc: 0.9047\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2529 - acc: 0.9111 - val_loss: 0.2921 - val_acc: 0.9053\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2556 - acc: 0.9108 - val_loss: 0.2987 - val_acc: 0.9039\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2545 - acc: 0.9111 - val_loss: 0.2929 - val_acc: 0.9053\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2542 - acc: 0.9118 - val_loss: 0.2896 - val_acc: 0.9059\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2538 - acc: 0.9105 - val_loss: 0.2916 - val_acc: 0.9059\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2545 - acc: 0.9115 - val_loss: 0.2903 - val_acc: 0.9049\n",
      "AUC: 0.710977\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 377us/step - loss: 0.3131 - acc: 0.9074 - val_loss: 0.2965 - val_acc: 0.9125\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.3046 - acc: 0.9090 - val_loss: 0.2937 - val_acc: 0.9125\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2979 - acc: 0.9090 - val_loss: 0.2907 - val_acc: 0.9125\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2949 - acc: 0.9090 - val_loss: 0.2933 - val_acc: 0.9125\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2934 - acc: 0.9091 - val_loss: 0.2875 - val_acc: 0.9125\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2926 - acc: 0.9090 - val_loss: 0.2940 - val_acc: 0.9125\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2913 - acc: 0.9090 - val_loss: 0.2852 - val_acc: 0.9125\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2909 - acc: 0.9090 - val_loss: 0.2864 - val_acc: 0.9125\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2896 - acc: 0.9089 - val_loss: 0.2854 - val_acc: 0.9125\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2892 - acc: 0.9090 - val_loss: 0.2934 - val_acc: 0.9123\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2881 - acc: 0.9090 - val_loss: 0.3009 - val_acc: 0.9122\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2877 - acc: 0.9091 - val_loss: 0.2866 - val_acc: 0.9123\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2872 - acc: 0.9088 - val_loss: 0.2841 - val_acc: 0.9122\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2875 - acc: 0.9090 - val_loss: 0.2848 - val_acc: 0.9123\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 27s 413us/step - loss: 0.2847 - acc: 0.9091 - val_loss: 0.2829 - val_acc: 0.9125\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2845 - acc: 0.9090 - val_loss: 0.2869 - val_acc: 0.9126\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2843 - acc: 0.9091 - val_loss: 0.2883 - val_acc: 0.9123\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2822 - acc: 0.9089 - val_loss: 0.2840 - val_acc: 0.9123\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2820 - acc: 0.9089 - val_loss: 0.2796 - val_acc: 0.9125\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2818 - acc: 0.9092 - val_loss: 0.2799 - val_acc: 0.9122\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2814 - acc: 0.9092 - val_loss: 0.2773 - val_acc: 0.9123\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2801 - acc: 0.9091 - val_loss: 0.2855 - val_acc: 0.9120\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2790 - acc: 0.9090 - val_loss: 0.2822 - val_acc: 0.9119\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2793 - acc: 0.9089 - val_loss: 0.2861 - val_acc: 0.9122\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2774 - acc: 0.9092 - val_loss: 0.2929 - val_acc: 0.9118\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2784 - acc: 0.9089 - val_loss: 0.2790 - val_acc: 0.9125\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2774 - acc: 0.9090 - val_loss: 0.2834 - val_acc: 0.9120\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2770 - acc: 0.9090 - val_loss: 0.2812 - val_acc: 0.9116\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2759 - acc: 0.9089 - val_loss: 0.2787 - val_acc: 0.9122o\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2752 - acc: 0.9089 - val_loss: 0.2817 - val_acc: 0.9122\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2754 - acc: 0.9089 - val_loss: 0.2795 - val_acc: 0.9120\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2747 - acc: 0.9091 - val_loss: 0.2801 - val_acc: 0.9120ss: 0.27\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2746 - acc: 0.9091 - val_loss: 0.2804 - val_acc: 0.9123\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2741 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9118\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2733 - acc: 0.9091 - val_loss: 0.2815 - val_acc: 0.9122 4s - loss: 0.2739 - acc: 0.90 - ETA: 4s  - ETA: 2s - loss: 0.2745 - acc: 0.908 - ETA: 1s - loss\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2729 - acc: 0.9090 - val_loss: 0.2858 - val_acc: 0.9123\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2723 - acc: 0.9088 - val_loss: 0.2808 - val_acc: 0.9125\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2711 - acc: 0.9093 - val_loss: 0.2858 - val_acc: 0.9115\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2713 - acc: 0.9089 - val_loss: 0.2937 - val_acc: 0.9115\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2707 - acc: 0.9085 - val_loss: 0.2893 - val_acc: 0.9112\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2709 - acc: 0.9090 - val_loss: 0.2870 - val_acc: 0.9125\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2698 - acc: 0.9097 - val_loss: 0.2841 - val_acc: 0.9127\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2703 - acc: 0.9091 - val_loss: 0.2961 - val_acc: 0.9115\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2693 - acc: 0.9094 - val_loss: 0.2819 - val_acc: 0.9122\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2678 - acc: 0.9097 - val_loss: 0.2867 - val_acc: 0.9122\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2687 - acc: 0.9095 - val_loss: 0.2793 - val_acc: 0.9125\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2678 - acc: 0.9090 - val_loss: 0.2868 - val_acc: 0.9116679 - acc: 0.909\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2692 - acc: 0.9091 - val_loss: 0.2836 - val_acc: 0.9123\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2679 - acc: 0.9092 - val_loss: 0.2808 - val_acc: 0.9125\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2663 - acc: 0.9094 - val_loss: 0.2767 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_6.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2666 - acc: 0.9094 - val_loss: 0.2820 - val_acc: 0.9120\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2654 - acc: 0.9099 - val_loss: 0.2828 - val_acc: 0.9123\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2660 - acc: 0.9091 - val_loss: 0.2812 - val_acc: 0.9111\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2656 - acc: 0.9090 - val_loss: 0.2854 - val_acc: 0.9116\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2656 - acc: 0.9094 - val_loss: 0.2875 - val_acc: 0.9103\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2662 - acc: 0.9098 - val_loss: 0.2812 - val_acc: 0.9120\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2638 - acc: 0.9099 - val_loss: 0.2841 - val_acc: 0.9110\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2632 - acc: 0.9096 - val_loss: 0.2798 - val_acc: 0.9123\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2638 - acc: 0.9096 - val_loss: 0.2797 - val_acc: 0.9116s: 0.2641 - - ETA: 1s - loss: 0\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2639 - acc: 0.9096 - val_loss: 0.2772 - val_acc: 0.9123\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2632 - acc: 0.9092 - val_loss: 0.2892 - val_acc: 0.9108\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2622 - acc: 0.9094 - val_loss: 0.2764 - val_acc: 0.9123\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2611 - acc: 0.9093 - val_loss: 0.2795 - val_acc: 0.9125\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2625 - acc: 0.9093 - val_loss: 0.2905 - val_acc: 0.9115\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2620 - acc: 0.9093 - val_loss: 0.2767 - val_acc: 0.9120\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2634 - acc: 0.9097 - val_loss: 0.2786 - val_acc: 0.9115\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2609 - acc: 0.9100 - val_loss: 0.2822 - val_acc: 0.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2607 - acc: 0.9096 - val_loss: 0.2812 - val_acc: 0.9114\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2608 - acc: 0.9099 - val_loss: 0.2797 - val_acc: 0.9122\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2605 - acc: 0.9101 - val_loss: 0.2822 - val_acc: 0.9112\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2591 - acc: 0.9094 - val_loss: 0.2842 - val_acc: 0.9114\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2591 - acc: 0.9097 - val_loss: 0.2887 - val_acc: 0.9114\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2589 - acc: 0.9099 - val_loss: 0.2873 - val_acc: 0.9115\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2583 - acc: 0.9100 - val_loss: 0.2889 - val_acc: 0.9111\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2598 - acc: 0.9098 - val_loss: 0.2864 - val_acc: 0.9116\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2578 - acc: 0.9106 - val_loss: 0.2908 - val_acc: 0.9112\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2585 - acc: 0.9101 - val_loss: 0.2876 - val_acc: 0.9111\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2569 - acc: 0.9104 - val_loss: 0.2841 - val_acc: 0.9116\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2584 - acc: 0.9094 - val_loss: 0.2857 - val_acc: 0.9115\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2563 - acc: 0.9105 - val_loss: 0.2801 - val_acc: 0.9125\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2552 - acc: 0.9102 - val_loss: 0.2882 - val_acc: 0.9111oss: 0.2553 - acc: 0.910 - ETA: 0s - loss: 0.2552 - \n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2563 - acc: 0.9104 - val_loss: 0.2862 - val_acc: 0.9118\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2567 - acc: 0.9097 - val_loss: 0.2870 - val_acc: 0.9111\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2547 - acc: 0.9099 - val_loss: 0.2859 - val_acc: 0.9108\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2561 - acc: 0.9099 - val_loss: 0.2887 - val_acc: 0.9108ETA: 0s - loss: 0.2559 - acc: \n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2565 - acc: 0.9099 - val_loss: 0.2951 - val_acc: 0.9116\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2551 - acc: 0.9105 - val_loss: 0.2808 - val_acc: 0.9114\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2544 - acc: 0.9101 - val_loss: 0.2859 - val_acc: 0.9112\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2552 - acc: 0.9107 - val_loss: 0.2849 - val_acc: 0.9112\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2560 - acc: 0.9103 - val_loss: 0.2821 - val_acc: 0.9120\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2552 - acc: 0.9103 - val_loss: 0.2838 - val_acc: 0.9112\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2540 - acc: 0.9105 - val_loss: 0.2814 - val_acc: 0.9112ss: 0.2539 - acc: 0.91\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2554 - acc: 0.9098 - val_loss: 0.2843 - val_acc: 0.9114\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2523 - acc: 0.9103 - val_loss: 0.2847 - val_acc: 0.9111\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2526 - acc: 0.9110 - val_loss: 0.2815 - val_acc: 0.9111\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2534 - acc: 0.9105 - val_loss: 0.2845 - val_acc: 0.9102\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2521 - acc: 0.9100 - val_loss: 0.2805 - val_acc: 0.9107: 0s - loss: 0.2526 - \n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2508 - acc: 0.9096 - val_loss: 0.2839 - val_acc: 0.9110\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2526 - acc: 0.9107 - val_loss: 0.2834 - val_acc: 0.9111\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2539 - acc: 0.9102 - val_loss: 0.2806 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_6.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2502 - acc: 0.9114 - val_loss: 0.2835 - val_acc: 0.9114\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2508 - acc: 0.9112 - val_loss: 0.2848 - val_acc: 0.9112\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2494 - acc: 0.9105 - val_loss: 0.2811 - val_acc: 0.9119\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2505 - acc: 0.9110 - val_loss: 0.2866 - val_acc: 0.9100\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2508 - acc: 0.9112 - val_loss: 0.2833 - val_acc: 0.9108\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2499 - acc: 0.9116 - val_loss: 0.2824 - val_acc: 0.9111\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2495 - acc: 0.9110 - val_loss: 0.2903 - val_acc: 0.9102\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2499 - acc: 0.9109 - val_loss: 0.2850 - val_acc: 0.9099\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2496 - acc: 0.9111 - val_loss: 0.2823 - val_acc: 0.9112.2494 - acc: 0.\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2503 - acc: 0.9110 - val_loss: 0.2882 - val_acc: 0.9108\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2499 - acc: 0.9113 - val_loss: 0.2888 - val_acc: 0.9096\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2483 - acc: 0.9107 - val_loss: 0.2855 - val_acc: 0.9100\n",
      "AUC: 0.699106\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 382us/step - loss: 0.3101 - acc: 0.9088 - val_loss: 0.3176 - val_acc: 0.9068\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.3003 - acc: 0.9097 - val_loss: 0.3009 - val_acc: 0.9068\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2934 - acc: 0.9097 - val_loss: 0.2989 - val_acc: 0.9068\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2940 - acc: 0.9097 - val_loss: 0.2985 - val_acc: 0.9068\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2909 - acc: 0.9097 - val_loss: 0.3052 - val_acc: 0.9068\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2910 - acc: 0.9097 - val_loss: 0.2991 - val_acc: 0.9068\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2899 - acc: 0.9096 - val_loss: 0.2954 - val_acc: 0.9068\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2897 - acc: 0.9097 - val_loss: 0.2955 - val_acc: 0.9068\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2875 - acc: 0.9097 - val_loss: 0.2971 - val_acc: 0.9068\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2871 - acc: 0.9097 - val_loss: 0.2927 - val_acc: 0.9068\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2864 - acc: 0.9096 - val_loss: 0.2917 - val_acc: 0.9068\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2855 - acc: 0.9096 - val_loss: 0.2911 - val_acc: 0.9068\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2848 - acc: 0.9097 - val_loss: 0.2972 - val_acc: 0.9068\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2841 - acc: 0.9096 - val_loss: 0.2935 - val_acc: 0.9069\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2829 - acc: 0.9095 - val_loss: 0.2880 - val_acc: 0.9068\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2836 - acc: 0.9095 - val_loss: 0.2880 - val_acc: 0.9068\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2812 - acc: 0.9096 - val_loss: 0.2927 - val_acc: 0.9068\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2806 - acc: 0.9097 - val_loss: 0.2922 - val_acc: 0.9070\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2808 - acc: 0.9099 - val_loss: 0.2883 - val_acc: 0.9068\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2800 - acc: 0.9094 - val_loss: 0.2913 - val_acc: 0.9069\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2798 - acc: 0.9094 - val_loss: 0.2965 - val_acc: 0.9068\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2776 - acc: 0.9098 - val_loss: 0.2869 - val_acc: 0.9068\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2772 - acc: 0.9096 - val_loss: 0.2885 - val_acc: 0.9066\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2768 - acc: 0.9094 - val_loss: 0.2984 - val_acc: 0.9058\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2763 - acc: 0.9096 - val_loss: 0.2875 - val_acc: 0.9062\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2759 - acc: 0.9094 - val_loss: 0.2936 - val_acc: 0.9061\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2755 - acc: 0.9098 - val_loss: 0.2854 - val_acc: 0.9068\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2747 - acc: 0.9096 - val_loss: 0.2854 - val_acc: 0.9066\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2744 - acc: 0.9093 - val_loss: 0.2920 - val_acc: 0.9066\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2737 - acc: 0.9095 - val_loss: 0.2911 - val_acc: 0.9066\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2733 - acc: 0.9098 - val_loss: 0.2915 - val_acc: 0.9069\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2722 - acc: 0.9095 - val_loss: 0.2853 - val_acc: 0.9064\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2717 - acc: 0.9098 - val_loss: 0.2856 - val_acc: 0.9066\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2715 - acc: 0.9093 - val_loss: 0.2895 - val_acc: 0.9070\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2711 - acc: 0.9096 - val_loss: 0.2854 - val_acc: 0.9069\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2700 - acc: 0.9097 - val_loss: 0.2904 - val_acc: 0.9068\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2701 - acc: 0.9098 - val_loss: 0.2896 - val_acc: 0.9073\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2698 - acc: 0.9097 - val_loss: 0.2889 - val_acc: 0.9068\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2685 - acc: 0.9101 - val_loss: 0.2843 - val_acc: 0.9070TA: 2s - loss: 0. - ETA: 1s - loss: 0.267\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2693 - acc: 0.9097 - val_loss: 0.2859 - val_acc: 0.9069\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2679 - acc: 0.9097 - val_loss: 0.2866 - val_acc: 0.9068\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2676 - acc: 0.9098 - val_loss: 0.2867 - val_acc: 0.9069\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2680 - acc: 0.9097 - val_loss: 0.2863 - val_acc: 0.9068\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2669 - acc: 0.9100 - val_loss: 0.2845 - val_acc: 0.9068\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2656 - acc: 0.9096 - val_loss: 0.2869 - val_acc: 0.9065\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2679 - acc: 0.9095 - val_loss: 0.2893 - val_acc: 0.9059\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2659 - acc: 0.9099 - val_loss: 0.2852 - val_acc: 0.9070\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2648 - acc: 0.9104 - val_loss: 0.2891 - val_acc: 0.9065\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2638 - acc: 0.9105 - val_loss: 0.2972 - val_acc: 0.9065\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2641 - acc: 0.9103 - val_loss: 0.2863 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_7.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2646 - acc: 0.9095 - val_loss: 0.2923 - val_acc: 0.9068\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2625 - acc: 0.9099 - val_loss: 0.2865 - val_acc: 0.9069\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2631 - acc: 0.9104 - val_loss: 0.2859 - val_acc: 0.9072\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2626 - acc: 0.9106 - val_loss: 0.2953 - val_acc: 0.9054\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2627 - acc: 0.9096 - val_loss: 0.2858 - val_acc: 0.9068\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2626 - acc: 0.9104 - val_loss: 0.2868 - val_acc: 0.9066\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2622 - acc: 0.9100 - val_loss: 0.2887 - val_acc: 0.9065\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2602 - acc: 0.9099 - val_loss: 0.2864 - val_acc: 0.9062\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2608 - acc: 0.9100 - val_loss: 0.2931 - val_acc: 0.9059\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2601 - acc: 0.9099 - val_loss: 0.2934 - val_acc: 0.9062\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2595 - acc: 0.9110 - val_loss: 0.2865 - val_acc: 0.9069\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2580 - acc: 0.9107 - val_loss: 0.2861 - val_acc: 0.9070 - lo\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2588 - acc: 0.9101 - val_loss: 0.2935 - val_acc: 0.9053\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2594 - acc: 0.9109 - val_loss: 0.2878 - val_acc: 0.9070\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2591 - acc: 0.9101 - val_loss: 0.2910 - val_acc: 0.9066\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2592 - acc: 0.9107 - val_loss: 0.2888 - val_acc: 0.9066\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2581 - acc: 0.9104 - val_loss: 0.2884 - val_acc: 0.9059\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2557 - acc: 0.9108 - val_loss: 0.2902 - val_acc: 0.9055\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2561 - acc: 0.9102 - val_loss: 0.2916 - val_acc: 0.9070\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2576 - acc: 0.9105 - val_loss: 0.2860 - val_acc: 0.9065\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2566 - acc: 0.9106 - val_loss: 0.2858 - val_acc: 0.9062\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2561 - acc: 0.9106 - val_loss: 0.2864 - val_acc: 0.9068\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2568 - acc: 0.9106 - val_loss: 0.2876 - val_acc: 0.9061\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2559 - acc: 0.9103 - val_loss: 0.2901 - val_acc: 0.9072\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2539 - acc: 0.9109 - val_loss: 0.2877 - val_acc: 0.9066ss: 0.25 - ETA: 2s - los - ETA: 0s - loss: 0.2540 - acc: 0.910\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2548 - acc: 0.9103 - val_loss: 0.2905 - val_acc: 0.9068\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2545 - acc: 0.9101 - val_loss: 0.2877 - val_acc: 0.9068\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2522 - acc: 0.9104 - val_loss: 0.2885 - val_acc: 0.9069\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2520 - acc: 0.9107 - val_loss: 0.2886 - val_acc: 0.9073\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2542 - acc: 0.9106 - val_loss: 0.2908 - val_acc: 0.9066\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2535 - acc: 0.9113 - val_loss: 0.2856 - val_acc: 0.9070\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2521 - acc: 0.9112 - val_loss: 0.2914 - val_acc: 0.9068\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2529 - acc: 0.9112 - val_loss: 0.2886 - val_acc: 0.9064\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2507 - acc: 0.9112 - val_loss: 0.2889 - val_acc: 0.9072oss: 0.2501  - ETA: 0s - loss: 0.2504 - acc - ETA: 0s - loss: 0.2508 - acc: 0.91\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2529 - acc: 0.9102 - val_loss: 0.2871 - val_acc: 0.9054\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2504 - acc: 0.9111 - val_loss: 0.2889 - val_acc: 0.9064\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2517 - acc: 0.9104 - val_loss: 0.2869 - val_acc: 0.9061\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2511 - acc: 0.9113 - val_loss: 0.2880 - val_acc: 0.9061\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2490 - acc: 0.9112 - val_loss: 0.2878 - val_acc: 0.9068\n",
      "AUC: 0.713093\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 380us/step - loss: 0.3118 - acc: 0.9076 - val_loss: 0.3128 - val_acc: 0.9087\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.3031 - acc: 0.9094 - val_loss: 0.2995 - val_acc: 0.9087\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2966 - acc: 0.9094 - val_loss: 0.2939 - val_acc: 0.9087\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2942 - acc: 0.9095 - val_loss: 0.2949 - val_acc: 0.9087\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2936 - acc: 0.9094 - val_loss: 0.2927 - val_acc: 0.9087\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2917 - acc: 0.9094 - val_loss: 0.2910 - val_acc: 0.9087\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2913 - acc: 0.9094 - val_loss: 0.2907 - val_acc: 0.9087\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2898 - acc: 0.9095 - val_loss: 0.2938 - val_acc: 0.9087\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2884 - acc: 0.9095 - val_loss: 0.2880 - val_acc: 0.9087\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2879 - acc: 0.9094 - val_loss: 0.2926 - val_acc: 0.9087\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2874 - acc: 0.9095 - val_loss: 0.2860 - val_acc: 0.9087\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2864 - acc: 0.9095 - val_loss: 0.2904 - val_acc: 0.9087\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2859 - acc: 0.9095 - val_loss: 0.2927 - val_acc: 0.9089\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2857 - acc: 0.9094 - val_loss: 0.2917 - val_acc: 0.9087\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2847 - acc: 0.9094 - val_loss: 0.2836 - val_acc: 0.9087 - loss: 0.2846\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2847 - acc: 0.9094 - val_loss: 0.2837 - val_acc: 0.9087\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2833 - acc: 0.9095 - val_loss: 0.2843 - val_acc: 0.9088\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2835 - acc: 0.9093 - val_loss: 0.2862 - val_acc: 0.9091\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2819 - acc: 0.9093 - val_loss: 0.2903 - val_acc: 0.9089\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2820 - acc: 0.9094 - val_loss: 0.2825 - val_acc: 0.9088\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2817 - acc: 0.9093 - val_loss: 0.2823 - val_acc: 0.9088\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2802 - acc: 0.9094 - val_loss: 0.2819 - val_acc: 0.9089\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2806 - acc: 0.9094 - val_loss: 0.2831 - val_acc: 0.9088\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2784 - acc: 0.9094 - val_loss: 0.2957 - val_acc: 0.9095\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2793 - acc: 0.9096 - val_loss: 0.2814 - val_acc: 0.9093\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2789 - acc: 0.9094 - val_loss: 0.2830 - val_acc: 0.9092\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2784 - acc: 0.9093 - val_loss: 0.2804 - val_acc: 0.9091\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2784 - acc: 0.9093 - val_loss: 0.2979 - val_acc: 0.9092\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2773 - acc: 0.9094 - val_loss: 0.2850 - val_acc: 0.9087\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2761 - acc: 0.9094 - val_loss: 0.2848 - val_acc: 0.9091\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2756 - acc: 0.9094 - val_loss: 0.2883 - val_acc: 0.9091\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2754 - acc: 0.9094 - val_loss: 0.2790 - val_acc: 0.9087s: \n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2759 - acc: 0.9096 - val_loss: 0.2797 - val_acc: 0.9088\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2755 - acc: 0.9094 - val_loss: 0.2886 - val_acc: 0.9089\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2738 - acc: 0.9093 - val_loss: 0.2872 - val_acc: 0.9084\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2728 - acc: 0.9092 - val_loss: 0.2942 - val_acc: 0.9088\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2740 - acc: 0.9093 - val_loss: 0.2835 - val_acc: 0.9089\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2714 - acc: 0.9092 - val_loss: 0.2880 - val_acc: 0.9088\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2732 - acc: 0.9090 - val_loss: 0.2802 - val_acc: 0.9084- ETA: 1s - loss: 0. - ETA: 0s - loss: 0.2732 - acc: 0.9\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2714 - acc: 0.9091 - val_loss: 0.2833 - val_acc: 0.9095\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2713 - acc: 0.9094 - val_loss: 0.2823 - val_acc: 0.9088\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2708 - acc: 0.9097 - val_loss: 0.2814 - val_acc: 0.9091\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2705 - acc: 0.9093 - val_loss: 0.2799 - val_acc: 0.9085\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2699 - acc: 0.9096 - val_loss: 0.2942 - val_acc: 0.9088\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2689 - acc: 0.9097 - val_loss: 0.2838 - val_acc: 0.9089\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2687 - acc: 0.9097 - val_loss: 0.3000 - val_acc: 0.9085\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2692 - acc: 0.9096 - val_loss: 0.2800 - val_acc: 0.9091\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2682 - acc: 0.9092 - val_loss: 0.2796 - val_acc: 0.9088\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2676 - acc: 0.9097 - val_loss: 0.2865 - val_acc: 0.9084\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2664 - acc: 0.9094 - val_loss: 0.2822 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_8.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2663 - acc: 0.9097 - val_loss: 0.2808 - val_acc: 0.9083\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2654 - acc: 0.9094 - val_loss: 0.2788 - val_acc: 0.9085\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2666 - acc: 0.9094 - val_loss: 0.2757 - val_acc: 0.9089\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2660 - acc: 0.9094 - val_loss: 0.2799 - val_acc: 0.9089\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2651 - acc: 0.9101 - val_loss: 0.2756 - val_acc: 0.9085\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2636 - acc: 0.9095 - val_loss: 0.2837 - val_acc: 0.9096\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2636 - acc: 0.9098 - val_loss: 0.2794 - val_acc: 0.9100\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2623 - acc: 0.9102 - val_loss: 0.2780 - val_acc: 0.9091\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2623 - acc: 0.9099 - val_loss: 0.2802 - val_acc: 0.9083\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2621 - acc: 0.9099 - val_loss: 0.2807 - val_acc: 0.9089\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2616 - acc: 0.9097 - val_loss: 0.2811 - val_acc: 0.9100\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2617 - acc: 0.9097 - val_loss: 0.2820 - val_acc: 0.9092\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2618 - acc: 0.9096 - val_loss: 0.2850 - val_acc: 0.9089\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2600 - acc: 0.9102 - val_loss: 0.2814 - val_acc: 0.9092\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2606 - acc: 0.9095 - val_loss: 0.2787 - val_acc: 0.9089ETA: 0s - loss: 0.2609 - acc: 0\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2602 - acc: 0.9097 - val_loss: 0.2763 - val_acc: 0.9088\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2582 - acc: 0.9098 - val_loss: 0.2817 - val_acc: 0.9084\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2582 - acc: 0.9105 - val_loss: 0.2790 - val_acc: 0.9095\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2584 - acc: 0.9099 - val_loss: 0.2782 - val_acc: 0.9092\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2577 - acc: 0.9101 - val_loss: 0.2766 - val_acc: 0.9091\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2579 - acc: 0.9097 - val_loss: 0.2799 - val_acc: 0.9096\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2582 - acc: 0.9108 - val_loss: 0.2769 - val_acc: 0.9096\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2565 - acc: 0.9102 - val_loss: 0.2813 - val_acc: 0.9093loss: \n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2574 - acc: 0.9105 - val_loss: 0.2797 - val_acc: 0.9093\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2572 - acc: 0.9103 - val_loss: 0.2817 - val_acc: 0.9095\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2547 - acc: 0.9105 - val_loss: 0.2781 - val_acc: 0.9092\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2554 - acc: 0.9106 - val_loss: 0.2766 - val_acc: 0.9093\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2557 - acc: 0.9097 - val_loss: 0.2808 - val_acc: 0.9087\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2550 - acc: 0.9107 - val_loss: 0.2804 - val_acc: 0.9089\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2561 - acc: 0.9103 - val_loss: 0.2806 - val_acc: 0.9085\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2562 - acc: 0.9103 - val_loss: 0.2846 - val_acc: 0.9084\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2546 - acc: 0.9106 - val_loss: 0.2797 - val_acc: 0.9096\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2534 - acc: 0.9105 - val_loss: 0.2785 - val_acc: 0.9100\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2541 - acc: 0.9100 - val_loss: 0.2792 - val_acc: 0.9095\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2512 - acc: 0.9111 - val_loss: 0.2826 - val_acc: 0.9087\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2514 - acc: 0.9111 - val_loss: 0.2806 - val_acc: 0.9093\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2528 - acc: 0.9111 - val_loss: 0.2768 - val_acc: 0.90920.\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2518 - acc: 0.9116 - val_loss: 0.2832 - val_acc: 0.9093\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2513 - acc: 0.9108 - val_loss: 0.2808 - val_acc: 0.9084\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2509 - acc: 0.9108 - val_loss: 0.2798 - val_acc: 0.9091\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2525 - acc: 0.9100 - val_loss: 0.2783 - val_acc: 0.9100\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2501 - acc: 0.9120 - val_loss: 0.2772 - val_acc: 0.9104\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2516 - acc: 0.9106 - val_loss: 0.2803 - val_acc: 0.9106\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2496 - acc: 0.9110 - val_loss: 0.2790 - val_acc: 0.9097\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2500 - acc: 0.9118 - val_loss: 0.2763 - val_acc: 0.9102\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2482 - acc: 0.9121 - val_loss: 0.2745 - val_acc: 0.9091\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2487 - acc: 0.9112 - val_loss: 0.2779 - val_acc: 0.9087\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2485 - acc: 0.9117 - val_loss: 0.2813 - val_acc: 0.9091\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2479 - acc: 0.9111 - val_loss: 0.2771 - val_acc: 0.9088\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2493 - acc: 0.9110 - val_loss: 0.2762 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_8.hdf5\n",
      "Epoch 101/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2489 - acc: 0.9113 - val_loss: 0.2772 - val_acc: 0.9096\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2466 - acc: 0.9113 - val_loss: 0.2774 - val_acc: 0.9097\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2474 - acc: 0.9118 - val_loss: 0.2764 - val_acc: 0.9099\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2482 - acc: 0.9111 - val_loss: 0.2809 - val_acc: 0.9095\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2480 - acc: 0.9114 - val_loss: 0.2743 - val_acc: 0.9093\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2460 - acc: 0.9117 - val_loss: 0.2765 - val_acc: 0.9096\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2481 - acc: 0.9116 - val_loss: 0.2795 - val_acc: 0.9085 0.2483 - acc: 0\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2454 - acc: 0.9117 - val_loss: 0.2773 - val_acc: 0.9092\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2434 - acc: 0.9120 - val_loss: 0.2764 - val_acc: 0.9096\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2461 - acc: 0.9116 - val_loss: 0.2778 - val_acc: 0.9077\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2455 - acc: 0.9119 - val_loss: 0.2761 - val_acc: 0.9085\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2441 - acc: 0.9124 - val_loss: 0.2787 - val_acc: 0.9077\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2444 - acc: 0.9124 - val_loss: 0.2799 - val_acc: 0.9089\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2440 - acc: 0.9120 - val_loss: 0.2774 - val_acc: 0.9083 ETA: 0s - loss: 0.2441 - \n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2436 - acc: 0.9123 - val_loss: 0.2761 - val_acc: 0.9080\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2442 - acc: 0.9126 - val_loss: 0.2781 - val_acc: 0.9087\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2436 - acc: 0.9117 - val_loss: 0.2780 - val_acc: 0.9089\n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2439 - acc: 0.9130 - val_loss: 0.2766 - val_acc: 0.9087\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2443 - acc: 0.9118 - val_loss: 0.2788 - val_acc: 0.9083\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2431 - acc: 0.9118 - val_loss: 0.2764 - val_acc: 0.9084\n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2418 - acc: 0.9126 - val_loss: 0.2769 - val_acc: 0.9085\n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2440 - acc: 0.9115 - val_loss: 0.2781 - val_acc: 0.9077\n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2424 - acc: 0.9122 - val_loss: 0.2768 - val_acc: 0.90740.2428 -\n",
      "Epoch 124/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2429 - acc: 0.9124 - val_loss: 0.2797 - val_acc: 0.9084s - loss: 0.2424 - acc: 0.912 - ETA: 2s -\n",
      "Epoch 125/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2426 - acc: 0.9118 - val_loss: 0.2786 - val_acc: 0.9074\n",
      "Epoch 126/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2413 - acc: 0.9125 - val_loss: 0.2775 - val_acc: 0.9078\n",
      "Epoch 127/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2412 - acc: 0.9124 - val_loss: 0.2773 - val_acc: 0.9084 - loss: 0.2401 -\n",
      "Epoch 128/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2404 - acc: 0.9127 - val_loss: 0.2772 - val_acc: 0.9077\n",
      "Epoch 129/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2439 - acc: 0.9117 - val_loss: 0.2783 - val_acc: 0.9081\n",
      "Epoch 130/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2402 - acc: 0.9125 - val_loss: 0.2786 - val_acc: 0.9083\n",
      "Epoch 131/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2402 - acc: 0.9128 - val_loss: 0.2779 - val_acc: 0.9076\n",
      "Epoch 132/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2401 - acc: 0.9126 - val_loss: 0.2771 - val_acc: 0.9085\n",
      "Epoch 133/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2394 - acc: 0.9132 - val_loss: 0.2768 - val_acc: 0.9076\n",
      "Epoch 134/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2381 - acc: 0.9133 - val_loss: 0.2753 - val_acc: 0.9092\n",
      "Epoch 135/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2408 - acc: 0.9124 - val_loss: 0.2772 - val_acc: 0.9083\n",
      "Epoch 136/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2382 - acc: 0.9139 - val_loss: 0.2755 - val_acc: 0.9081\n",
      "Epoch 137/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2392 - acc: 0.9128 - val_loss: 0.2768 - val_acc: 0.9084\n",
      "Epoch 138/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2392 - acc: 0.9125 - val_loss: 0.2757 - val_acc: 0.9089\n",
      "Epoch 139/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2388 - acc: 0.9134 - val_loss: 0.2776 - val_acc: 0.9085\n",
      "Epoch 140/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2392 - acc: 0.9128 - val_loss: 0.2770 - val_acc: 0.9085\n",
      "Epoch 141/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2393 - acc: 0.9124 - val_loss: 0.2770 - val_acc: 0.9083\n",
      "Epoch 142/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2364 - acc: 0.9137 - val_loss: 0.2777 - val_acc: 0.9077\n",
      "Epoch 143/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2379 - acc: 0.9135 - val_loss: 0.2771 - val_acc: 0.9070\n",
      "Epoch 144/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2384 - acc: 0.9130 - val_loss: 0.2792 - val_acc: 0.9074\n",
      "Epoch 145/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2368 - acc: 0.9133 - val_loss: 0.2794 - val_acc: 0.9081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2368 - acc: 0.9135 - val_loss: 0.2781 - val_acc: 0.9084\n",
      "Epoch 147/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2383 - acc: 0.9130 - val_loss: 0.2789 - val_acc: 0.9087\n",
      "Epoch 148/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2358 - acc: 0.9144 - val_loss: 0.2805 - val_acc: 0.9077\n",
      "Epoch 149/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2378 - acc: 0.9135 - val_loss: 0.2804 - val_acc: 0.9073s - loss: 0.2370 - ac\n",
      "Epoch 150/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2358 - acc: 0.9139 - val_loss: 0.2811 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00150: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_8.hdf5\n",
      "Epoch 151/1000\n",
      "66414/66414 [==============================] - 24s 365us/step - loss: 0.2360 - acc: 0.9130 - val_loss: 0.2771 - val_acc: 0.9088\n",
      "Epoch 152/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2364 - acc: 0.9143 - val_loss: 0.2787 - val_acc: 0.9074\n",
      "Epoch 153/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2354 - acc: 0.9137 - val_loss: 0.2779 - val_acc: 0.9077\n",
      "Epoch 154/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2372 - acc: 0.9136 - val_loss: 0.2784 - val_acc: 0.9083\n",
      "Epoch 155/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2360 - acc: 0.9134 - val_loss: 0.2788 - val_acc: 0.9080\n",
      "AUC: 0.728365\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 383us/step - loss: 0.3107 - acc: 0.9081 - val_loss: 0.3085 - val_acc: 0.9088\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2995 - acc: 0.9094 - val_loss: 0.3081 - val_acc: 0.9088\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2960 - acc: 0.9094 - val_loss: 0.2948 - val_acc: 0.9088\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2933 - acc: 0.9095 - val_loss: 0.2938 - val_acc: 0.9088\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2925 - acc: 0.9094 - val_loss: 0.2903 - val_acc: 0.9088\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2916 - acc: 0.9094 - val_loss: 0.3095 - val_acc: 0.9088\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2900 - acc: 0.9094 - val_loss: 0.2914 - val_acc: 0.9088: 0.2914 -  - ETA: 8s - loss: 0 - ETA: 7s - loss: 0.2911 - - ETA: 5s -\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2894 - acc: 0.9094 - val_loss: 0.2994 - val_acc: 0.9087\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2887 - acc: 0.9094 - val_loss: 0.2972 - val_acc: 0.9080\n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2872 - acc: 0.9093 - val_loss: 0.2878 - val_acc: 0.90884 - acc: 0.909 - ETA: 1s - loss: 0.287\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2872 - acc: 0.9095 - val_loss: 0.2881 - val_acc: 0.9088\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2864 - acc: 0.9094 - val_loss: 0.2858 - val_acc: 0.9088\n",
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2855 - acc: 0.9096 - val_loss: 0.2891 - val_acc: 0.9087\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2848 - acc: 0.9094 - val_loss: 0.2922 - val_acc: 0.9088\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2839 - acc: 0.9094 - val_loss: 0.2885 - val_acc: 0.9087\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2833 - acc: 0.9094 - val_loss: 0.2903 - val_acc: 0.9088\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2816 - acc: 0.9093 - val_loss: 0.2813 - val_acc: 0.9088\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2819 - acc: 0.9093 - val_loss: 0.2826 - val_acc: 0.9088\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2811 - acc: 0.9096 - val_loss: 0.2803 - val_acc: 0.9088\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2799 - acc: 0.9096 - val_loss: 0.2865 - val_acc: 0.9085\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2806 - acc: 0.9094 - val_loss: 0.2819 - val_acc: 0.9088A: 0s - loss: 0.2806 - acc: 0\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2798 - acc: 0.9096 - val_loss: 0.2830 - val_acc: 0.9088\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2784 - acc: 0.9093 - val_loss: 0.2804 - val_acc: 0.9087\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2775 - acc: 0.9093 - val_loss: 0.2849 - val_acc: 0.9083\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2771 - acc: 0.9095 - val_loss: 0.2831 - val_acc: 0.9083\n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2766 - acc: 0.9092 - val_loss: 0.2971 - val_acc: 0.9078\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2755 - acc: 0.9099 - val_loss: 0.2897 - val_acc: 0.9074\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2751 - acc: 0.9095 - val_loss: 0.2788 - val_acc: 0.9085\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2763 - acc: 0.9097 - val_loss: 0.2850 - val_acc: 0.9087\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2748 - acc: 0.9094 - val_loss: 0.2808 - val_acc: 0.9089\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2740 - acc: 0.9093 - val_loss: 0.2804 - val_acc: 0.9089\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2729 - acc: 0.9095 - val_loss: 0.2845 - val_acc: 0.9087\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2729 - acc: 0.9095 - val_loss: 0.2791 - val_acc: 0.9089\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2724 - acc: 0.9094 - val_loss: 0.2927 - val_acc: 0.9081\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2715 - acc: 0.9092 - val_loss: 0.2889 - val_acc: 0.9076\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2728 - acc: 0.9093 - val_loss: 0.2799 - val_acc: 0.9087\n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2721 - acc: 0.9096 - val_loss: 0.2943 - val_acc: 0.9074\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2708 - acc: 0.9095 - val_loss: 0.2869 - val_acc: 0.9077\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2696 - acc: 0.9098 - val_loss: 0.2803 - val_acc: 0.9085\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2695 - acc: 0.9100 - val_loss: 0.2871 - val_acc: 0.9080\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2705 - acc: 0.9100 - val_loss: 0.2859 - val_acc: 0.9073\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2692 - acc: 0.9094 - val_loss: 0.2800 - val_acc: 0.9070\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2681 - acc: 0.9100 - val_loss: 0.2835 - val_acc: 0.9081\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2675 - acc: 0.9100 - val_loss: 0.2803 - val_acc: 0.9083\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2670 - acc: 0.9092 - val_loss: 0.2875 - val_acc: 0.9078\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2675 - acc: 0.9093 - val_loss: 0.2877 - val_acc: 0.9085\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2670 - acc: 0.9100 - val_loss: 0.2948 - val_acc: 0.9064\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2671 - acc: 0.9099 - val_loss: 0.2851 - val_acc: 0.9068\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2666 - acc: 0.9095 - val_loss: 0.2814 - val_acc: 0.9078\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2648 - acc: 0.9100 - val_loss: 0.2871 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_9.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2643 - acc: 0.9100 - val_loss: 0.2862 - val_acc: 0.9062\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2650 - acc: 0.9101 - val_loss: 0.2844 - val_acc: 0.9061\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2649 - acc: 0.9097 - val_loss: 0.2923 - val_acc: 0.9068\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2639 - acc: 0.9095 - val_loss: 0.2850 - val_acc: 0.9070\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2632 - acc: 0.9094 - val_loss: 0.2837 - val_acc: 0.9062\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2617 - acc: 0.9095 - val_loss: 0.2802 - val_acc: 0.9074\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2636 - acc: 0.9105 - val_loss: 0.2825 - val_acc: 0.9072\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2634 - acc: 0.9101 - val_loss: 0.2892 - val_acc: 0.9072\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2607 - acc: 0.9098 - val_loss: 0.2787 - val_acc: 0.9078\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2624 - acc: 0.9098 - val_loss: 0.2828 - val_acc: 0.9084\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2631 - acc: 0.9097 - val_loss: 0.2792 - val_acc: 0.9083\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2618 - acc: 0.9096 - val_loss: 0.2749 - val_acc: 0.9081\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2599 - acc: 0.9098 - val_loss: 0.2830 - val_acc: 0.9088\n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2591 - acc: 0.9097 - val_loss: 0.2923 - val_acc: 0.9077\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2577 - acc: 0.9109 - val_loss: 0.2848 - val_acc: 0.9078\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2589 - acc: 0.9103 - val_loss: 0.2813 - val_acc: 0.9061\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2592 - acc: 0.9099 - val_loss: 0.2856 - val_acc: 0.9077s: 0.2578 - acc: 0.910 - ETA: 5s - loss: 0 - ETA: 4s - loss: 0.2583 - ac -\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2582 - acc: 0.9106 - val_loss: 0.2865 - val_acc: 0.9065\n",
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2584 - acc: 0.9106 - val_loss: 0.2884 - val_acc: 0.9065\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2567 - acc: 0.9107 - val_loss: 0.2793 - val_acc: 0.9081\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2586 - acc: 0.9100 - val_loss: 0.2873 - val_acc: 0.9076\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2569 - acc: 0.9104 - val_loss: 0.2851 - val_acc: 0.9065\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2575 - acc: 0.9107 - val_loss: 0.2780 - val_acc: 0.9076\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2557 - acc: 0.9099 - val_loss: 0.2847 - val_acc: 0.9081\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2575 - acc: 0.9105 - val_loss: 0.2839 - val_acc: 0.9083\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2556 - acc: 0.9102 - val_loss: 0.2884 - val_acc: 0.9069\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2544 - acc: 0.9097 - val_loss: 0.2837 - val_acc: 0.9080\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2542 - acc: 0.9110 - val_loss: 0.2815 - val_acc: 0.9084\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2547 - acc: 0.9107 - val_loss: 0.2818 - val_acc: 0.9077\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2546 - acc: 0.9105 - val_loss: 0.2815 - val_acc: 0.9085\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2536 - acc: 0.9108 - val_loss: 0.2803 - val_acc: 0.9076s - loss: 0.2537 - acc:\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2536 - acc: 0.9103 - val_loss: 0.2815 - val_acc: 0.9073\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2535 - acc: 0.9106 - val_loss: 0.2808 - val_acc: 0.9072\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2529 - acc: 0.9108 - val_loss: 0.2797 - val_acc: 0.9084\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2529 - acc: 0.9107 - val_loss: 0.2798 - val_acc: 0.9074\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2527 - acc: 0.9102 - val_loss: 0.2812 - val_acc: 0.9081\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2526 - acc: 0.9102 - val_loss: 0.2794 - val_acc: 0.9062\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2501 - acc: 0.9113 - val_loss: 0.2842 - val_acc: 0.9077\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2513 - acc: 0.9107 - val_loss: 0.2770 - val_acc: 0.9066\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2501 - acc: 0.9116 - val_loss: 0.2830 - val_acc: 0.9089\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2518 - acc: 0.9106 - val_loss: 0.2797 - val_acc: 0.9078\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2505 - acc: 0.9111 - val_loss: 0.2829 - val_acc: 0.9061\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2499 - acc: 0.9114 - val_loss: 0.2770 - val_acc: 0.9077\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2486 - acc: 0.9120 - val_loss: 0.2856 - val_acc: 0.9077\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2490 - acc: 0.9109 - val_loss: 0.2738 - val_acc: 0.9093\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2473 - acc: 0.9107 - val_loss: 0.2763 - val_acc: 0.9072\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2482 - acc: 0.9114 - val_loss: 0.2810 - val_acc: 0.9091\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2474 - acc: 0.9116 - val_loss: 0.2808 - val_acc: 0.9083\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2509 - acc: 0.9113 - val_loss: 0.2783 - val_acc: 0.9077\n",
      "Epoch 100/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2463 - acc: 0.9116 - val_loss: 0.2797 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00100: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_9.hdf5\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2472 - acc: 0.9117 - val_loss: 0.2798 - val_acc: 0.9081\n",
      "Epoch 102/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2470 - acc: 0.9118 - val_loss: 0.2789 - val_acc: 0.9073\n",
      "Epoch 103/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2459 - acc: 0.9114 - val_loss: 0.2778 - val_acc: 0.9087\n",
      "Epoch 104/1000\n",
      "66414/66414 [==============================] - 25s 370us/step - loss: 0.2472 - acc: 0.9115 - val_loss: 0.2771 - val_acc: 0.9081\n",
      "Epoch 105/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2468 - acc: 0.9119 - val_loss: 0.2774 - val_acc: 0.9078\n",
      "Epoch 106/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2469 - acc: 0.9119 - val_loss: 0.2777 - val_acc: 0.9085\n",
      "Epoch 107/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2446 - acc: 0.9123 - val_loss: 0.2784 - val_acc: 0.9070\n",
      "Epoch 108/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2462 - acc: 0.9122 - val_loss: 0.2754 - val_acc: 0.9083\n",
      "Epoch 109/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2455 - acc: 0.9113 - val_loss: 0.2775 - val_acc: 0.9080\n",
      "Epoch 110/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2438 - acc: 0.9125 - val_loss: 0.2754 - val_acc: 0.9083\n",
      "Epoch 111/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2448 - acc: 0.9122 - val_loss: 0.2792 - val_acc: 0.9074\n",
      "Epoch 112/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2425 - acc: 0.9117 - val_loss: 0.2803 - val_acc: 0.9076\n",
      "Epoch 113/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2422 - acc: 0.9125 - val_loss: 0.2764 - val_acc: 0.9084\n",
      "Epoch 114/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2438 - acc: 0.9118 - val_loss: 0.2766 - val_acc: 0.9078\n",
      "Epoch 115/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2427 - acc: 0.9123 - val_loss: 0.2793 - val_acc: 0.9069\n",
      "Epoch 116/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2424 - acc: 0.9125 - val_loss: 0.2798 - val_acc: 0.9074\n",
      "Epoch 117/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2423 - acc: 0.9117 - val_loss: 0.2812 - val_acc: 0.9073\n",
      "Epoch 118/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2427 - acc: 0.9120 - val_loss: 0.2821 - val_acc: 0.9066\n",
      "Epoch 119/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2414 - acc: 0.9129 - val_loss: 0.2785 - val_acc: 0.9078\n",
      "Epoch 120/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2405 - acc: 0.9132 - val_loss: 0.2787 - val_acc: 0.9077\n",
      "Epoch 121/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2410 - acc: 0.9130 - val_loss: 0.2809 - val_acc: 0.9069\n",
      "Epoch 122/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2421 - acc: 0.9122 - val_loss: 0.2784 - val_acc: 0.9080\n",
      "Epoch 123/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2415 - acc: 0.9123 - val_loss: 0.2796 - val_acc: 0.9077\n",
      "Epoch 124/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2404 - acc: 0.9131 - val_loss: 0.2792 - val_acc: 0.9076\n",
      "Epoch 125/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2397 - acc: 0.9122 - val_loss: 0.2820 - val_acc: 0.9074\n",
      "Epoch 126/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2400 - acc: 0.9125 - val_loss: 0.2780 - val_acc: 0.9084\n",
      "Epoch 127/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2411 - acc: 0.9122 - val_loss: 0.2804 - val_acc: 0.9076\n",
      "Epoch 128/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2374 - acc: 0.9133 - val_loss: 0.2784 - val_acc: 0.9070\n",
      "Epoch 129/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2397 - acc: 0.9125 - val_loss: 0.2823 - val_acc: 0.90680\n",
      "Epoch 130/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2417 - acc: 0.9118 - val_loss: 0.2843 - val_acc: 0.9074\n",
      "Epoch 131/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2395 - acc: 0.9127 - val_loss: 0.2781 - val_acc: 0.9081\n",
      "Epoch 132/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2386 - acc: 0.9129 - val_loss: 0.2790 - val_acc: 0.9076\n",
      "Epoch 133/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2371 - acc: 0.9144 - val_loss: 0.2845 - val_acc: 0.9065\n",
      "Epoch 134/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2375 - acc: 0.9133 - val_loss: 0.2772 - val_acc: 0.9088\n",
      "Epoch 135/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2399 - acc: 0.9132 - val_loss: 0.2789 - val_acc: 0.9069\n",
      "Epoch 136/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2382 - acc: 0.9137 - val_loss: 0.2817 - val_acc: 0.9069\n",
      "Epoch 137/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2356 - acc: 0.9136 - val_loss: 0.2806 - val_acc: 0.9069\n",
      "Epoch 138/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2400 - acc: 0.9125 - val_loss: 0.2805 - val_acc: 0.9059\n",
      "Epoch 139/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2382 - acc: 0.9127 - val_loss: 0.2779 - val_acc: 0.9070\n",
      "Epoch 140/1000\n",
      "66414/66414 [==============================] - 24s 369us/step - loss: 0.2382 - acc: 0.9133 - val_loss: 0.2795 - val_acc: 0.9066\n",
      "Epoch 141/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2361 - acc: 0.9138 - val_loss: 0.2804 - val_acc: 0.9061\n",
      "Epoch 142/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2376 - acc: 0.9126 - val_loss: 0.2774 - val_acc: 0.9074\n",
      "Epoch 143/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2372 - acc: 0.9146 - val_loss: 0.2781 - val_acc: 0.9077\n",
      "Epoch 144/1000\n",
      "66414/66414 [==============================] - 25s 369us/step - loss: 0.2353 - acc: 0.9137 - val_loss: 0.2782 - val_acc: 0.9070\n",
      "Epoch 145/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2360 - acc: 0.9138 - val_loss: 0.2787 - val_acc: 0.9070\n",
      "AUC: 0.736651\n",
      "Train on 66414 samples, validate on 7379 samples\n",
      "Epoch 1/1000\n",
      "66414/66414 [==============================] - 25s 384us/step - loss: 0.3144 - acc: 0.9076 - val_loss: 0.2931 - val_acc: 0.9162\n",
      "Epoch 2/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.3046 - acc: 0.9086 - val_loss: 0.2837 - val_acc: 0.9162\n",
      "Epoch 3/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2979 - acc: 0.9086 - val_loss: 0.2908 - val_acc: 0.9162\n",
      "Epoch 4/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2940 - acc: 0.9086 - val_loss: 0.2850 - val_acc: 0.9162\n",
      "Epoch 5/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2934 - acc: 0.9086 - val_loss: 0.2794 - val_acc: 0.9162\n",
      "Epoch 6/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2927 - acc: 0.9086 - val_loss: 0.2777 - val_acc: 0.9162\n",
      "Epoch 7/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2909 - acc: 0.9085 - val_loss: 0.2797 - val_acc: 0.9162\n",
      "Epoch 8/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2896 - acc: 0.9085 - val_loss: 0.2922 - val_acc: 0.9161\n",
      "Epoch 9/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2884 - acc: 0.9085 - val_loss: 0.2765 - val_acc: 0.9162.2864 - a - ETA: 6s - loss: 0.2874 - acc: 0 - ETA: 6s \n",
      "Epoch 10/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2873 - acc: 0.9085 - val_loss: 0.2785 - val_acc: 0.9162\n",
      "Epoch 11/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2869 - acc: 0.9086 - val_loss: 0.2870 - val_acc: 0.9160\n",
      "Epoch 12/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2852 - acc: 0.9086 - val_loss: 0.2839 - val_acc: 0.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2852 - acc: 0.9086 - val_loss: 0.2787 - val_acc: 0.9162.2853 - ac\n",
      "Epoch 14/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2827 - acc: 0.9086 - val_loss: 0.2726 - val_acc: 0.9162\n",
      "Epoch 15/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2825 - acc: 0.9085 - val_loss: 0.2704 - val_acc: 0.9162\n",
      "Epoch 16/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2813 - acc: 0.9087 - val_loss: 0.2741 - val_acc: 0.9164\n",
      "Epoch 17/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2810 - acc: 0.9087 - val_loss: 0.2782 - val_acc: 0.9162\n",
      "Epoch 18/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2799 - acc: 0.9088 - val_loss: 0.2765 - val_acc: 0.9164\n",
      "Epoch 19/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2794 - acc: 0.9083 - val_loss: 0.2731 - val_acc: 0.9168\n",
      "Epoch 20/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2782 - acc: 0.9081 - val_loss: 0.2747 - val_acc: 0.9165\n",
      "Epoch 21/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2790 - acc: 0.9083 - val_loss: 0.2789 - val_acc: 0.9164\n",
      "Epoch 22/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2766 - acc: 0.9086 - val_loss: 0.2698 - val_acc: 0.9162\n",
      "Epoch 23/1000\n",
      "66414/66414 [==============================] - 24s 368us/step - loss: 0.2782 - acc: 0.9087 - val_loss: 0.2745 - val_acc: 0.9164\n",
      "Epoch 24/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2764 - acc: 0.9087 - val_loss: 0.2710 - val_acc: 0.9158\n",
      "Epoch 25/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2759 - acc: 0.9083 - val_loss: 0.2727 - val_acc: 0.9157s - loss: 0.2763 - \n",
      "Epoch 26/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2741 - acc: 0.9089 - val_loss: 0.2803 - val_acc: 0.9153\n",
      "Epoch 27/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2757 - acc: 0.9086 - val_loss: 0.2754 - val_acc: 0.9161\n",
      "Epoch 28/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2741 - acc: 0.9086 - val_loss: 0.2723 - val_acc: 0.9165\n",
      "Epoch 29/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2738 - acc: 0.9087 - val_loss: 0.2671 - val_acc: 0.9161\n",
      "Epoch 30/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2729 - acc: 0.9087 - val_loss: 0.2756 - val_acc: 0.9165\n",
      "Epoch 31/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2734 - acc: 0.9089 - val_loss: 0.2687 - val_acc: 0.9165\n",
      "Epoch 32/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2729 - acc: 0.9083 - val_loss: 0.2776 - val_acc: 0.9158\n",
      "Epoch 33/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2704 - acc: 0.9092 - val_loss: 0.2824 - val_acc: 0.9156- acc: 0.90\n",
      "Epoch 34/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2716 - acc: 0.9085 - val_loss: 0.2775 - val_acc: 0.9150\n",
      "Epoch 35/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2715 - acc: 0.9087 - val_loss: 0.2696 - val_acc: 0.9164\n",
      "Epoch 36/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2706 - acc: 0.9086 - val_loss: 0.2696 - val_acc: 0.9157ss: 0.2707 - acc: \n",
      "Epoch 37/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2705 - acc: 0.9089 - val_loss: 0.2700 - val_acc: 0.9160\n",
      "Epoch 38/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2687 - acc: 0.9089 - val_loss: 0.2776 - val_acc: 0.9156\n",
      "Epoch 39/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2693 - acc: 0.9080 - val_loss: 0.2853 - val_acc: 0.9161\n",
      "Epoch 40/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2681 - acc: 0.9085 - val_loss: 0.2797 - val_acc: 0.9150\n",
      "Epoch 41/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2677 - acc: 0.9087 - val_loss: 0.2792 - val_acc: 0.9156\n",
      "Epoch 42/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2677 - acc: 0.9091 - val_loss: 0.2664 - val_acc: 0.9157\n",
      "Epoch 43/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2670 - acc: 0.9089 - val_loss: 0.2689 - val_acc: 0.9162\n",
      "Epoch 44/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2659 - acc: 0.9083 - val_loss: 0.2723 - val_acc: 0.9164\n",
      "Epoch 45/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2658 - acc: 0.9094 - val_loss: 0.2757 - val_acc: 0.9154\n",
      "Epoch 46/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2653 - acc: 0.9090 - val_loss: 0.2689 - val_acc: 0.9160\n",
      "Epoch 47/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2666 - acc: 0.9087 - val_loss: 0.2706 - val_acc: 0.9162\n",
      "Epoch 48/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2645 - acc: 0.9091 - val_loss: 0.2793 - val_acc: 0.9148\n",
      "Epoch 49/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2647 - acc: 0.9091 - val_loss: 0.2661 - val_acc: 0.9160\n",
      "Epoch 50/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2621 - acc: 0.9093 - val_loss: 0.2720 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00050: saving model to C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_CKSAAP_gap4_10.hdf5\n",
      "Epoch 51/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2639 - acc: 0.9094 - val_loss: 0.2701 - val_acc: 0.9158\n",
      "Epoch 52/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2631 - acc: 0.9086 - val_loss: 0.2978 - val_acc: 0.9122\n",
      "Epoch 53/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2627 - acc: 0.9091 - val_loss: 0.2755 - val_acc: 0.9152\n",
      "Epoch 54/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2638 - acc: 0.9093 - val_loss: 0.2699 - val_acc: 0.9154\n",
      "Epoch 55/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2606 - acc: 0.9090 - val_loss: 0.2770 - val_acc: 0.9152\n",
      "Epoch 56/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2624 - acc: 0.9089 - val_loss: 0.2880 - val_acc: 0.9160: 4s - loss: 0.2617 - a\n",
      "Epoch 57/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2610 - acc: 0.9096 - val_loss: 0.2679 - val_acc: 0.9164\n",
      "Epoch 58/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2600 - acc: 0.9095 - val_loss: 0.2715 - val_acc: 0.9161\n",
      "Epoch 59/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2596 - acc: 0.9097 - val_loss: 0.2766 - val_acc: 0.9145\n",
      "Epoch 60/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2595 - acc: 0.9096 - val_loss: 0.2734 - val_acc: 0.9157\n",
      "Epoch 61/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2602 - acc: 0.9098 - val_loss: 0.2690 - val_acc: 0.9160\n",
      "Epoch 62/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2596 - acc: 0.9094 - val_loss: 0.2743 - val_acc: 0.9161\n",
      "Epoch 63/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2586 - acc: 0.9098 - val_loss: 0.2714 - val_acc: 0.9165s: 0.2580 - acc:  - ETA: 1s - loss: \n",
      "Epoch 64/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2595 - acc: 0.9094 - val_loss: 0.2676 - val_acc: 0.9162\n",
      "Epoch 65/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2591 - acc: 0.9096 - val_loss: 0.2743 - val_acc: 0.9161TA: 8s - loss:  - ET\n",
      "Epoch 66/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2584 - acc: 0.9096 - val_loss: 0.2725 - val_acc: 0.9162\n",
      "Epoch 67/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2565 - acc: 0.9094 - val_loss: 0.2752 - val_acc: 0.9161\n",
      "Epoch 68/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2565 - acc: 0.9095 - val_loss: 0.2731 - val_acc: 0.9152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2563 - acc: 0.9099 - val_loss: 0.2696 - val_acc: 0.9162\n",
      "Epoch 70/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2556 - acc: 0.9097 - val_loss: 0.2689 - val_acc: 0.9164\n",
      "Epoch 71/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2578 - acc: 0.9093 - val_loss: 0.2664 - val_acc: 0.9158\n",
      "Epoch 72/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2563 - acc: 0.9095 - val_loss: 0.2693 - val_acc: 0.9161\n",
      "Epoch 73/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2541 - acc: 0.9101 - val_loss: 0.2747 - val_acc: 0.9138\n",
      "Epoch 74/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2539 - acc: 0.9101 - val_loss: 0.2742 - val_acc: 0.9150\n",
      "Epoch 75/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2524 - acc: 0.9098 - val_loss: 0.2677 - val_acc: 0.9161\n",
      "Epoch 76/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2537 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9161\n",
      "Epoch 77/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2544 - acc: 0.9100 - val_loss: 0.2702 - val_acc: 0.9153543 - acc:\n",
      "Epoch 78/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2535 - acc: 0.9104 - val_loss: 0.2687 - val_acc: 0.9149\n",
      "Epoch 79/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2539 - acc: 0.9102 - val_loss: 0.2753 - val_acc: 0.9142\n",
      "Epoch 80/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2550 - acc: 0.9096 - val_loss: 0.2761 - val_acc: 0.9142\n",
      "Epoch 81/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2524 - acc: 0.9100 - val_loss: 0.2733 - val_acc: 0.9130\n",
      "Epoch 82/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2545 - acc: 0.9102 - val_loss: 0.2742 - val_acc: 0.9142\n",
      "Epoch 83/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2517 - acc: 0.9096 - val_loss: 0.2778 - val_acc: 0.9135\n",
      "Epoch 84/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2522 - acc: 0.9105 - val_loss: 0.2731 - val_acc: 0.9141\n",
      "Epoch 85/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2515 - acc: 0.9102 - val_loss: 0.2706 - val_acc: 0.9145\n",
      "Epoch 86/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2506 - acc: 0.9111 - val_loss: 0.2735 - val_acc: 0.9141\n",
      "Epoch 87/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2525 - acc: 0.9099 - val_loss: 0.2741 - val_acc: 0.9130\n",
      "Epoch 88/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2515 - acc: 0.9107 - val_loss: 0.2775 - val_acc: 0.9152\n",
      "Epoch 89/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2505 - acc: 0.9102 - val_loss: 0.2800 - val_acc: 0.9123\n",
      "Epoch 90/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2502 - acc: 0.9105 - val_loss: 0.2761 - val_acc: 0.9129- loss: 0.2499 - acc\n",
      "Epoch 91/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2509 - acc: 0.9104 - val_loss: 0.2692 - val_acc: 0.9141\n",
      "Epoch 92/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2494 - acc: 0.9110 - val_loss: 0.2715 - val_acc: 0.9139\n",
      "Epoch 93/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2498 - acc: 0.9105 - val_loss: 0.2697 - val_acc: 0.9150\n",
      "Epoch 94/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2508 - acc: 0.9102 - val_loss: 0.2704 - val_acc: 0.9154\n",
      "Epoch 95/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2505 - acc: 0.9104 - val_loss: 0.2752 - val_acc: 0.9134\n",
      "Epoch 96/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2482 - acc: 0.9105 - val_loss: 0.2750 - val_acc: 0.9145\n",
      "Epoch 97/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2471 - acc: 0.9108 - val_loss: 0.2726 - val_acc: 0.9142\n",
      "Epoch 98/1000\n",
      "66414/66414 [==============================] - 24s 366us/step - loss: 0.2469 - acc: 0.9112 - val_loss: 0.2777 - val_acc: 0.9115\n",
      "Epoch 99/1000\n",
      "66414/66414 [==============================] - 24s 367us/step - loss: 0.2468 - acc: 0.9113 - val_loss: 0.2757 - val_acc: 0.9133\n",
      "AUC: 0.705442\n",
      "[0.7060520791342606, 0.6905258673111352, 0.7150617256489535, 0.7134270086436569, 0.7109766114569412, 0.6991057399923394, 0.7130927782199623, 0.7283651643996575, 0.7366510840129419, 0.7054423834776744]\n",
      "CV AUC: 0.711870\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 5种特征 CNN\n",
    "# 重新训练CNN word Embedding\n",
    "\n",
    "name = 'CKSAAP'\n",
    "gap = '_gap4'\n",
    "auc_mean=[]\n",
    "# path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Train.txt'\n",
    "# path_test =  'C:/Users/Crow/Desktop/human_data_12.12/Independent.txt'\n",
    "# x_train,y_train = pep(path_train,29-2)\n",
    "# x_test,y_test = pep(path_test,29-2)\n",
    "\n",
    "path_train = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_CV/'+ name +'/Train_29_'+ name + gap +'.txt'\n",
    "path_test = 'C:/Users/Crow/Desktop/human_data_12.12/Step_11_IND/'+ name +'/Test_29_'+ name + gap +'.txt'\n",
    "\n",
    "train = read_svm(path_train)\n",
    "test = read_svm(path_test)\n",
    "\n",
    "\n",
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_test = test[0]\n",
    "y_test = test[1]\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2) \n",
    "x_test = np.expand_dims(x_test, axis=2) \n",
    "\n",
    "shape = x_train.shape[1:]\n",
    "\n",
    "kf = KFold(n_splits = 10,random_state=5,shuffle=True)\n",
    "j = 1 \n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_train3, x_test3 = x_train[train_index], x_train[test_index]\n",
    "    y_train3, y_test3 = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "#     model = create_cnn_model5(input_length=29)\n",
    "    \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "#     callbacks_list = [early_stopping]\n",
    "#     model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 20, batch_size = 256,shuffle=True,\n",
    "#          callbacks=callbacks_list, verbose=1)\n",
    "    model = create_cnn_model3(shape=shape,dropout=0.6)\n",
    "    \n",
    "    #filepath='C:/Users/Crow/Desktop/result/re_CNN3/model/'+ str(j) +'checkpoint-{val_loss:.2f}-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5'\n",
    "    filepath='C:/Users/Crow/Desktop/new_result/CNN/model/29_kfold_CNN_'+ name + gap+'_'+ str(j) +'.hdf5'\n",
    "    #filepath=\"C:/Users/Crow/Desktop/result/re_CNN/model/weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False,mode='auto', period=50)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    callbacks_list = [early_stopping,checkpoint]\n",
    "    model.fit(x_train3, y_train3, validation_data = (x_test3, y_test3), epochs = 1000, batch_size = 256,\n",
    "              shuffle=True,callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    test_pred_proba = model.predict(x_test3)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test3,test_pred_proba,pos_label=1)\n",
    "    #print(\"ACC:  %f \"  %accuracy_score(y_test3,test_pred))\n",
    "    print(\"AUC: %f\" % auc(fpr, tpr))\n",
    "    auc_mean.append(auc(fpr, tpr))\n",
    "    #print(\"MCC: %f \" %matthews_corrcoef(y_test3,test_pred))\n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_result_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(test_pred_proba)):\n",
    "        fw.write(str(test_pred_proba[t][0]))\n",
    "        fw.write('\\t')\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open('C:/Users/Crow/Desktop/new_result/CNN/29_kfold_CNN_'+ name + gap+'_test_'+ str(j) +'.txt','w')\n",
    "    for t in range(0,len(y_test3)):\n",
    "        fw.write(str(y_test3[t]))\n",
    "        fw.write('\\n')\n",
    "    fw.close()\n",
    "    \n",
    "    if j == 10:\n",
    "        print(auc_mean)\n",
    "        print(print(\"CV AUC: %f\" % mean(auc_mean)))\n",
    "#         model.save('C:/Users/Crow/Desktop/result/re_CNN/model/CNN_kfold_'+ name + gap +'.h5') \n",
    "        \n",
    "#         test_pred_proba = model.predict(x_test)\n",
    "#         fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "#         print(\"总AUC: %f\" % auc(fpr, tpr))\n",
    "#         fw = open('C:/Users/Crow/Desktop/result/re_CNN/29_kfold_CNN_'+ name + gap +'_result.txt','w')\n",
    "#         for t in range(0,len(test_pred_proba)):\n",
    "#             fw.write(str(test_pred_proba[t][0]))\n",
    "#             fw.write('\\t')\n",
    "#             fw.write(str(y_test[t]))\n",
    "#             fw.write('\\n') \n",
    "#         fw.close()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6942366965152929,\n",
       " 0.6731511797644351,\n",
       " 0.6740070511822408,\n",
       " 0.6852779419701371,\n",
       " 0.6717783844231022,\n",
       " 0.6790888093807175,\n",
       " 0.6747679110780535,\n",
       " 0.6863164032333371,\n",
       " 0.6880980594876558,\n",
       " 0.6575320860312022]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.917464 \n",
      "AUC: 0.662739\n"
     ]
    }
   ],
   "source": [
    "model = load_model('C:/Users/Crow/Desktop/result/re_CNN3/model/3checkpoint-0.29-50e-val_acc_0.91.hdf5')\n",
    "\n",
    "test_pred_proba = model.predict(x_test)\n",
    "test_pred = model.predict_classes(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,test_pred_proba,pos_label=1)\n",
    "print(\"ACC:  %f \"  %accuracy_score(y_test,test_pred))\n",
    "print(\"AUC: %f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,0.11,0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
